episode_reward_max,episode_reward_min,episode_reward_mean,episode_len_mean,episodes_this_iter,num_healthy_workers,timesteps_total,agent_timesteps_total,done,episodes_total,training_iteration,experiment_id,date,timestamp,time_this_iter_s,time_total_s,pid,hostname,node_ip,time_since_restore,timesteps_since_restore,iterations_since_restore,hist_stats/episode_reward,hist_stats/episode_lengths,timers/sample_time_ms,timers/sample_throughput,timers/load_time_ms,timers/load_throughput,timers/learn_time_ms,timers/learn_throughput,timers/update_time_ms,info/num_steps_sampled,info/num_agent_steps_sampled,info/num_steps_trained,info/num_agent_steps_trained,perf/cpu_util_percent,perf/ram_util_percent,info/learner/default_policy/learner_stats/allreduce_latency,info/learner/default_policy/learner_stats/cur_kl_coeff,info/learner/default_policy/learner_stats/cur_lr,info/learner/default_policy/learner_stats/total_loss,info/learner/default_policy/learner_stats/policy_loss,info/learner/default_policy/learner_stats/vf_loss,info/learner/default_policy/learner_stats/vf_explained_var,info/learner/default_policy/learner_stats/kl,info/learner/default_policy/learner_stats/entropy,info/learner/default_policy/learner_stats/entropy_coeff
nan,nan,nan,nan,0,2,4000,4000,False,0,1,6f2c4e01112f4aa1947beeab190d33b5,2021-09-20_01-30-06,1632126606,22.5686457157135,22.5686457157135,5588,028b450fc55a,172.17.0.2,22.5686457157135,0,1,[],[],14228.633,281.123,0.057,70197556.485,8334.063,479.958,1.341,4000,4000,4000,4000,28.939393939393938,15.693939393939393,0.0,0.20000000000000004,5.0000000000000016e-05,341987055.65591395,-0.04499992020528323,341987055.8623656,[6.164915e-07],0.01447529272027376,4.1446147862301075,0.0
