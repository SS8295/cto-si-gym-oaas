{"episode_reward_max": -36.6, "episode_reward_min": -216.19999999999973, "episode_reward_mean": -91.51278195488719, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-56.0, -94.69999999999995, -105.89999999999995, -97.99999999999997, -139.79999999999993, -187.1999999999998, -44.5, -216.19999999999973, -108.69999999999992, -78.99999999999999, -113.79999999999995, -79.29999999999997, -60.300000000000004, -102.79999999999998, -83.89999999999998, -143.49999999999983, -89.19999999999997, -87.39999999999992, -97.29999999999994, -54.800000000000004, -86.69999999999999, -97.09999999999998, -39.10000000000001, -62.300000000000026, -74.5, -52.2, -87.89999999999999, -166.19999999999976, -63.89999999999996, -89.39999999999999, -98.09999999999998, -108.29999999999993, -101.19999999999996, -81.39999999999998, -66.89999999999999, -63.0, -72.49999999999999, -70.60000000000001, -73.4, -53.60000000000001, -101.29999999999998, -60.00000000000001, -111.69999999999993, -98.39999999999999, -84.29999999999997, -93.10000000000001, -67.60000000000001, -59.900000000000006, -156.19999999999982, -64.30000000000001, -69.90000000000002, -132.99999999999994, -45.7, -96.99999999999994, -90.79999999999998, -80.09999999999998, -83.6, -52.0, -71.30000000000001, -77.1, -58.10000000000001, -133.0999999999999, -53.100000000000016, -66.30000000000001, -89.69999999999997, -103.59999999999988, -95.29999999999993, -79.0, -111.39999999999992, -83.2, -45.2, -102.39999999999996, -60.70000000000001, -55.599999999999994, -158.6999999999998, -130.79999999999995, -79.8, -78.8, -59.500000000000014, -116.59999999999992, -76.39999999999998, -75.9, -114.09999999999995, -87.09999999999998, -100.69999999999997, -67.89999999999999, -81.59999999999997, -77.7, -69.39999999999998, -68.9, -74.00000000000001, -110.49999999999994, -79.59999999999998, -84.09999999999997, -73.9, -48.50000000000001, -99.29999999999998, -69.6, -98.09999999999998, -84.09999999999997, -92.19999999999999, -138.7999999999999, -92.29999999999998, -109.8999999999999, -37.0, -102.79999999999998, -84.3, -79.8, -84.9, -131.79999999999993, -109.69999999999996, -85.19999999999999, -40.1, -94.89999999999998, -82.50000000000001, -97.19999999999999, -108.39999999999998, -73.8, -131.5999999999999, -108.69999999999999, -37.0, -64.2, -114.79999999999998, -109.99999999999993, -72.70000000000002, -83.69999999999999, -58.80000000000001, -37.7, -113.19999999999996, -36.6, -77.19999999999999, -50.10000000000001, -74.9, -83.69999999999996, -69.4, -61.10000000000001, -100.29999999999993, -103.19999999999996, -95.19999999999997, -69.1, -86.6, -61.39999999999998, -94.59999999999998, -113.19999999999992, -57.30000000000001, -90.89999999999993, -135.19999999999993, -75.80000000000001, -87.19999999999997, -80.49999999999996, -80.59999999999995, -51.7, -70.09999999999998, -116.59999999999994, -40.400000000000006, -105.59999999999995, -193.69999999999982, -97.19999999999996, -57.300000000000004, -68.39999999999999, -98.99999999999997, -74.0, -85.09999999999995, -77.8, -80.89999999999998, -88.19999999999995, -45.900000000000006, -133.99999999999986, -94.39999999999999, -80.1, -147.09999999999982, -91.09999999999997, -150.09999999999988, -80.79999999999998, -126.09999999999991, -73.19999999999999, -100.69999999999996, -98.79999999999993, -61.00000000000001, -80.59999999999997, -47.30000000000001, -89.29999999999995, -59.7, -196.29999999999976, -66.39999999999998, -50.6, -81.99999999999997, -95.49999999999996, -93.39999999999998, -83.09999999999997, -116.19999999999993, -80.2, -68.4, -99.89999999999995, -122.09999999999992, -60.09999999999999, -96.39999999999998, -79.29999999999995, -79.3, -74.49999999999996, -69.29999999999995, -93.59999999999998, -151.39999999999986, -118.59999999999995, -112.29999999999994, -100.89999999999995, -65.5, -43.300000000000004, -116.8999999999999, -84.19999999999999, -141.29999999999987, -146.4999999999999, -76.19999999999999, -110.59999999999995, -129.29999999999984, -104.19999999999996, -69.8, -74.2, -170.89999999999984, -57.599999999999994, -110.49999999999996, -72.8, -88.49999999999997, -89.49999999999997, -89.1, -76.39999999999998, -170.9999999999998, -95.49999999999997, -100.09999999999998, -73.09999999999998, -126.99999999999991, -111.19999999999997, -74.6, -156.09999999999985, -102.39999999999999, -142.9999999999999, -99.59999999999995, -62.599999999999994, -72.2, -123.19999999999986, -91.1, -136.7999999999999, -77.6, -117.09999999999991, -102.19999999999999, -118.79999999999991, -146.79999999999984, -129.39999999999995, -181.4999999999998, -99.59999999999995, -96.69999999999999, -102.99999999999991, -83.5, -74.10000000000001, -87.79999999999995, -131.19999999999996, -134.39999999999986, -55.9, -89.79999999999998, -63.50000000000001, -119.49999999999993, -157.09999999999982, -60.6, -175.59999999999982, -38.400000000000006, -73.2], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13867829335683113, "mean_inference_ms": 1.1688143178738695, "mean_action_processing_ms": 0.0521053021577285, "mean_env_wait_ms": 2.5869270731722454, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 4000, "agent_timesteps_total": 4000, "timers": {"sample_time_ms": 8038.983, "sample_throughput": 497.575, "load_time_ms": 0.082, "load_throughput": 48913166.181, "learn_time_ms": 8503.319, "learn_throughput": 470.405, "update_time_ms": 1.401}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 3284.0628159389703, "policy_loss": -0.028236806524857397, "vf_loss": 3284.088023721018, "vf_explained_var": [-0.00960489921271801], "kl": 0.015121351619546952, "entropy": 2.7574840732800063, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 4000, "num_agent_steps_sampled": 4000, "num_steps_trained": 4000, "num_agent_steps_trained": 4000}, "done": false, "episodes_total": 266, "training_iteration": 1, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-10-48", "timestamp": 1632517848, "time_this_iter_s": 16.55247139930725, "time_total_s": 16.55247139930725, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 16.55247139930725, "timesteps_since_restore": 0, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 35.416666666666664, "ram_util_percent": 15.633333333333335}}
{"episode_reward_max": -26.900000000000002, "episode_reward_min": -221.29999999999973, "episode_reward_mean": -92.39999999999996, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-66.80000000000001, -66.50000000000003, -100.49999999999993, -73.6, -82.89999999999998, -131.9999999999999, -73.79999999999997, -112.5999999999999, -86.19999999999999, -106.39999999999992, -95.39999999999998, -99.09999999999992, -94.59999999999995, -86.39999999999998, -66.2, -115.19999999999995, -77.70000000000002, -62.7, -80.99999999999994, -44.7, -129.39999999999986, -83.69999999999993, -212.09999999999968, -123.49999999999989, -87.69999999999999, -64.69999999999999, -87.99999999999999, -73.5, -54.800000000000004, -84.1, -111.2999999999999, -63.400000000000006, -77.1, -93.09999999999998, -107.49999999999997, -95.3, -102.99999999999996, -90.1, -48.8, -86.69999999999999, -98.49999999999994, -82.09999999999998, -89.9, -53.8, -96.4999999999999, -109.79999999999993, -100.79999999999995, -104.59999999999998, -68.2, -66.1, -100.89999999999996, -64.39999999999999, -91.29999999999998, -112.49999999999991, -81.9, -98.19999999999996, -153.9999999999998, -103.29999999999997, -88.49999999999997, -160.99999999999986, -120.29999999999994, -182.39999999999978, -96.99999999999999, -51.20000000000001, -105.79999999999997, -66.80000000000001, -67.0, -92.99999999999997, -82.99999999999999, -67.79999999999998, -143.59999999999994, -58.00000000000001, -108.69999999999996, -119.8999999999999, -92.19999999999996, -56.499999999999986, -52.10000000000001, -72.99999999999999, -65.30000000000001, -99.09999999999997, -66.7, -63.20000000000001, -75.19999999999999, -57.50000000000001, -86.6, -126.19999999999989, -50.500000000000014, -79.5, -86.49999999999997, -87.19999999999995, -119.49999999999993, -69.2, -64.9, -111.29999999999997, -92.99999999999997, -110.19999999999995, -101.89999999999998, -59.10000000000001, -83.29999999999998, -110.39999999999995, -53.4, -110.99999999999993, -142.19999999999987, -158.9999999999999, -89.09999999999997, -69.49999999999997, -76.59999999999998, -110.99999999999994, -63.09999999999997, -81.3, -71.4, -43.900000000000006, -155.29999999999987, -74.5, -83.69999999999997, -102.49999999999996, -186.99999999999974, -72.39999999999998, -78.7, -130.59999999999988, -94.99999999999999, -106.79999999999998, -209.1999999999997, -87.19999999999996, -121.29999999999994, -54.2, -159.79999999999987, -134.39999999999992, -48.100000000000016, -94.69999999999999, -103.79999999999993, -85.7, -141.59999999999985, -71.7, -73.19999999999999, -140.39999999999984, -74.29999999999998, -221.29999999999973, -79.70000000000002, -93.79999999999998, -94.89999999999998, -109.99999999999993, -115.19999999999995, -73.79999999999998, -96.79999999999997, -35.900000000000006, -62.899999999999984, -137.5999999999999, -55.00000000000001, -88.79999999999997, -47.70000000000001, -100.49999999999996, -93.10000000000001, -78.1, -175.49999999999977, -72.00000000000001, -110.99999999999987, -88.59999999999998, -72.9, -125.49999999999996, -51.7, -56.9, -110.19999999999992, -54.1, -53.400000000000006, -77.50000000000001, -84.39999999999998, -159.3999999999998, -85.89999999999999, -56.89999999999999, -156.4999999999998, -72.19999999999996, -80.8, -103.29999999999995, -60.49999999999999, -102.89999999999998, -60.3, -117.59999999999994, -62.5, -102.59999999999997, -62.699999999999996, -83.79999999999997, -100.29999999999997, -73.6, -100.09999999999998, -105.99999999999996, -77.49999999999999, -64.00000000000001, -136.69999999999993, -56.70000000000001, -26.900000000000002, -86.7, -75.59999999999998, -119.49999999999996, -116.29999999999993, -72.7, -68.80000000000001, -120.8999999999999, -109.19999999999999, -83.99999999999999, -55.50000000000001, -99.59999999999998, -132.59999999999994, -65.10000000000001, -193.3999999999998, -82.19999999999999, -69.8, -74.39999999999999, -62.89999999999998, -58.500000000000014, -77.79999999999998, -99.1, -100.89999999999996, -106.59999999999998, -126.39999999999995, -56.099999999999994, -149.7999999999999, -81.5, -138.0999999999999, -61.20000000000001, -69.00000000000001, -83.89999999999998, -81.59999999999998, -112.89999999999993, -62.900000000000006, -106.59999999999988, -45.800000000000004, -94.99999999999994, -66.7, -79.9, -108.99999999999994, -109.49999999999996, -102.39999999999995, -119.89999999999996, -155.69999999999987, -143.5999999999999, -57.70000000000001, -52.4, -140.89999999999986, -76.89999999999998, -78.99999999999999, -55.900000000000006, -70.99999999999997, -84.79999999999998, -127.9999999999999, -109.29999999999993, -85.69999999999993, -64.2, -51.800000000000004, -93.1999999999999, -35.40000000000001, -88.29999999999997, -129.09999999999988, -80.3, -100.49999999999997, -113.19999999999995, -89.99999999999997, -56.00000000000001, -78.1, -83.99999999999999, -109.09999999999995, -82.1, -147.4999999999999, -71.79999999999997, -134.5999999999999, -118.89999999999996], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13767087855836033, "mean_inference_ms": 1.1992828752421882, "mean_action_processing_ms": 0.05362403896325113, "mean_env_wait_ms": 2.4762400327042267, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 8000, "agent_timesteps_total": 8000, "timers": {"sample_time_ms": 7858.621, "sample_throughput": 508.995, "load_time_ms": 0.063, "load_throughput": 63191020.716, "learn_time_ms": 8332.119, "learn_throughput": 480.07, "update_time_ms": 1.421}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 2632.4680608933973, "policy_loss": -0.03954532051368827, "vf_loss": 2632.504659673219, "vf_explained_var": [-0.06634531915187836], "kl": 0.014678021952249673, "entropy": 2.728952949021452, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 8000, "num_agent_steps_sampled": 8000, "num_steps_trained": 8000, "num_agent_steps_trained": 8000}, "done": false, "episodes_total": 532, "training_iteration": 2, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-11-03", "timestamp": 1632517863, "time_this_iter_s": 15.848618507385254, "time_total_s": 32.401089906692505, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 32.401089906692505, "timesteps_since_restore": 0, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 34.90869565217392, "ram_util_percent": 15.752173913043482}}
{"episode_reward_max": -29.7, "episode_reward_min": -214.69999999999973, "episode_reward_mean": -84.86455223880593, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 268, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-70.80000000000001, -76.39999999999999, -69.89999999999999, -51.999999999999986, -89.09999999999998, -59.400000000000006, -54.400000000000006, -93.19999999999996, -64.30000000000001, -52.400000000000006, -105.49999999999997, -88.19999999999995, -100.69999999999996, -71.8, -90.09999999999998, -62.5, -121.19999999999993, -70.9, -70.4, -49.20000000000001, -47.6, -74.3, -91.8, -79.4, -62.50000000000001, -84.99999999999994, -214.69999999999973, -88.0, -105.99999999999997, -68.29999999999998, -61.20000000000002, -135.29999999999993, -44.6, -108.09999999999994, -92.69999999999996, -93.19999999999996, -96.89999999999996, -102.09999999999995, -118.29999999999993, -102.09999999999998, -85.49999999999994, -155.59999999999985, -73.50000000000001, -46.60000000000001, -63.2, -115.89999999999989, -68.39999999999998, -66.4, -47.80000000000001, -57.8, -110.59999999999992, -121.1999999999999, -79.30000000000001, -83.19999999999999, -112.49999999999991, -57.00000000000001, -91.49999999999996, -96.79999999999993, -70.6, -88.00000000000001, -83.69999999999997, -111.49999999999994, -73.49999999999999, -104.09999999999997, -129.19999999999993, -65.40000000000002, -47.3, -70.19999999999999, -59.5, -90.69999999999999, -41.800000000000004, -46.400000000000006, -84.59999999999998, -107.99999999999997, -87.49999999999994, -104.59999999999992, -92.8, -75.09999999999995, -82.09999999999998, -67.39999999999999, -66.59999999999998, -45.800000000000004, -181.29999999999978, -54.50000000000001, -57.59999999999999, -100.99999999999996, -89.39999999999998, -46.20000000000001, -64.50000000000001, -108.89999999999996, -78.2, -81.9, -115.29999999999993, -71.6, -110.89999999999992, -84.49999999999999, -51.800000000000004, -77.8, -92.99999999999997, -59.50000000000001, -88.79999999999997, -78.5, -77.19999999999997, -91.49999999999997, -72.0, -47.2, -76.1, -91.0, -47.60000000000001, -51.60000000000001, -89.99999999999997, -42.6, -92.39999999999999, -65.6, -119.29999999999993, -53.6, -91.19999999999996, -72.69999999999997, -87.89999999999998, -69.40000000000002, -117.19999999999996, -71.10000000000001, -74.29999999999998, -78.1, -58.10000000000001, -84.60000000000001, -51.400000000000006, -83.79999999999997, -98.29999999999994, -94.79999999999998, -78.39999999999996, -69.0, -86.5, -115.79999999999993, -123.09999999999995, -113.29999999999995, -75.4, -65.2, -128.89999999999986, -89.1, -110.99999999999994, -111.29999999999993, -89.49999999999996, -106.59999999999997, -158.09999999999985, -65.70000000000002, -139.99999999999991, -124.29999999999991, -83.0, -80.2, -62.499999999999986, -126.79999999999995, -92.89999999999996, -112.99999999999993, -72.5, -54.7, -65.99999999999999, -84.0, -89.29999999999995, -110.29999999999995, -80.69999999999999, -89.29999999999995, -56.00000000000001, -47.099999999999994, -113.29999999999991, -96.39999999999995, -67.5, -107.39999999999995, -71.19999999999999, -69.30000000000001, -104.69999999999996, -195.79999999999976, -82.30000000000001, -66.69999999999997, -44.400000000000006, -105.39999999999998, -82.49999999999997, -101.09999999999998, -170.99999999999983, -65.7, -65.59999999999998, -133.19999999999993, -94.19999999999995, -65.39999999999999, -52.400000000000006, -62.7, -167.1999999999998, -61.90000000000001, -106.29999999999991, -99.39999999999995, -88.00000000000001, -85.60000000000001, -93.5, -58.2, -69.60000000000001, -85.99999999999999, -74.4, -92.69999999999997, -76.30000000000001, -86.49999999999997, -80.0, -117.49999999999994, -90.1, -117.69999999999993, -103.09999999999995, -58.500000000000014, -48.79999999999999, -123.39999999999989, -41.800000000000004, -76.99999999999999, -83.10000000000001, -101.39999999999996, -65.3, -95.49999999999997, -59.400000000000006, -118.09999999999994, -85.2, -52.300000000000004, -53.80000000000001, -99.40000000000002, -66.2, -105.89999999999996, -83.8, -112.79999999999993, -41.7, -101.19999999999999, -161.39999999999984, -35.00000000000001, -89.19999999999997, -60.500000000000014, -95.99999999999996, -88.89999999999999, -152.9999999999999, -148.49999999999986, -90.29999999999998, -78.1, -67.1, -67.39999999999995, -60.7, -51.400000000000006, -56.300000000000004, -68.30000000000001, -84.59999999999995, -57.6, -74.1, -58.29999999999999, -176.19999999999982, -90.8, -67.5, -122.1999999999999, -70.5, -60.500000000000014, -80.79999999999998, -72.1, -85.49999999999999, -60.900000000000006, -44.20000000000001, -45.00000000000001, -91.29999999999997, -104.59999999999994, -66.69999999999997, -84.4, -145.59999999999982, -29.7, -51.6, -93.29999999999998, -115.69999999999993, -72.1], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13682290407602557, "mean_inference_ms": 1.2067615975937909, "mean_action_processing_ms": 0.05400546330885973, "mean_env_wait_ms": 2.4177881702346182, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 12000, "agent_timesteps_total": 12000, "timers": {"sample_time_ms": 7745.326, "sample_throughput": 516.44, "load_time_ms": 0.057, "load_throughput": 70099788.301, "learn_time_ms": 7880.261, "learn_throughput": 507.597, "update_time_ms": 1.379}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 1783.403572984921, "policy_loss": -0.041741685536239415, "vf_loss": 1783.4423478977656, "vf_explained_var": [-0.19980213046073914], "kl": 0.014844639582663605, "entropy": 2.696836829698214, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 12000, "num_agent_steps_sampled": 12000, "num_steps_trained": 12000, "num_agent_steps_trained": 12000}, "done": false, "episodes_total": 800, "training_iteration": 3, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-11-18", "timestamp": 1632517878, "time_this_iter_s": 14.504679203033447, "time_total_s": 46.90576910972595, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 46.90576910972595, "timesteps_since_restore": 0, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 34.49047619047619, "ram_util_percent": 15.800000000000002}}
{"episode_reward_max": -27.400000000000002, "episode_reward_min": -217.99999999999972, "episode_reward_mean": -83.30939849624058, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-102.79999999999997, -84.69999999999997, -81.2, -61.099999999999994, -97.1, -115.5999999999999, -47.400000000000006, -132.09999999999994, -64.5, -54.10000000000001, -75.70000000000002, -55.00000000000001, -66.4, -93.09999999999997, -84.1, -90.49999999999999, -45.60000000000001, -111.59999999999997, -63.499999999999986, -66.80000000000001, -109.89999999999995, -125.6999999999999, -44.199999999999996, -74.69999999999999, -117.89999999999995, -94.09999999999994, -69.50000000000001, -100.69999999999999, -60.3, -64.0, -78.6, -147.6999999999999, -67.5, -84.39999999999999, -73.09999999999998, -69.9, -67.1, -34.50000000000001, -74.39999999999999, -74.60000000000001, -49.10000000000001, -92.09999999999992, -61.4, -79.80000000000001, -129.79999999999993, -74.90000000000002, -55.60000000000001, -109.89999999999995, -78.59999999999998, -69.4, -92.29999999999995, -68.1, -48.30000000000001, -64.4, -82.39999999999998, -129.8999999999999, -60.7, -77.10000000000001, -49.20000000000001, -141.9999999999999, -69.89999999999999, -67.2, -92.39999999999998, -66.70000000000002, -77.10000000000001, -73.5, -142.0999999999999, -70.6, -66.09999999999998, -85.19999999999999, -102.49999999999997, -63.7, -58.400000000000006, -120.59999999999994, -99.19999999999997, -98.59999999999998, -45.7, -93.39999999999998, -93.19999999999995, -69.10000000000001, -98.09999999999998, -98.2, -122.09999999999994, -101.89999999999998, -73.70000000000002, -122.49999999999994, -48.2, -83.39999999999999, -89.89999999999999, -52.00000000000001, -139.19999999999993, -97.49999999999994, -94.6, -63.50000000000001, -68.0, -55.7, -55.70000000000002, -73.49999999999997, -149.59999999999982, -65.89999999999999, -107.39999999999999, -105.29999999999995, -89.09999999999995, -70.2, -84.49999999999997, -83.39999999999996, -66.69999999999999, -55.2, -162.69999999999982, -109.59999999999997, -90.59999999999998, -66.69999999999999, -45.20000000000001, -64.89999999999998, -89.5, -131.99999999999994, -71.79999999999998, -47.19999999999999, -119.59999999999998, -105.09999999999995, -58.9, -76.50000000000001, -78.09999999999998, -144.9999999999999, -131.99999999999994, -77.09999999999998, -95.09999999999997, -82.49999999999997, -67.2, -127.09999999999987, -147.09999999999982, -110.79999999999993, -124.79999999999995, -65.60000000000001, -50.50000000000001, -92.29999999999997, -61.20000000000001, -112.59999999999991, -73.2, -90.89999999999999, -124.09999999999988, -65.7, -217.99999999999972, -82.19999999999996, -145.19999999999993, -64.2, -73.19999999999999, -47.000000000000014, -70.8, -63.60000000000001, -62.7, -82.3, -128.7999999999999, -44.50000000000001, -85.0, -70.1, -78.8, -71.30000000000001, -92.89999999999998, -104.1, -58.1, -57.10000000000001, -61.100000000000016, -86.49999999999999, -59.000000000000014, -73.10000000000001, -68.80000000000001, -84.6, -82.9, -142.59999999999985, -122.69999999999992, -71.19999999999999, -70.60000000000001, -83.59999999999997, -123.79999999999987, -70.2, -53.20000000000001, -71.80000000000001, -58.39999999999999, -69.7, -72.5, -114.99999999999993, -104.79999999999994, -49.600000000000016, -62.4, -64.4, -65.4, -70.1, -48.900000000000006, -101.89999999999999, -64.9, -72.09999999999998, -102.1, -72.4, -54.59999999999999, -75.8, -99.39999999999999, -94.20000000000002, -146.69999999999985, -66.9, -161.59999999999982, -105.79999999999993, -63.699999999999996, -135.5999999999999, -86.69999999999997, -66.0, -42.400000000000006, -103.19999999999996, -118.39999999999992, -56.00000000000001, -57.10000000000001, -86.69999999999999, -84.6, -60.60000000000001, -88.49999999999997, -92.6, -52.900000000000006, -103.09999999999994, -102.89999999999995, -80.2, -88.29999999999997, -145.09999999999982, -100.89999999999998, -48.400000000000006, -94.19999999999996, -79.89999999999999, -45.800000000000004, -135.89999999999984, -80.0, -50.30000000000001, -90.69999999999999, -42.900000000000006, -92.09999999999998, -80.2, -74.3, -93.09999999999997, -80.29999999999998, -96.29999999999998, -54.499999999999986, -53.900000000000006, -90.09999999999998, -55.00000000000001, -113.79999999999993, -143.49999999999986, -52.400000000000006, -83.59999999999997, -52.70000000000002, -52.500000000000014, -45.80000000000001, -81.0, -87.29999999999994, -141.0999999999999, -64.6, -48.800000000000004, -85.19999999999996, -76.69999999999997, -81.39999999999999, -27.400000000000002, -79.6, -77.49999999999997, -34.50000000000001, -36.300000000000004, -54.0, -74.19999999999999, -130.6999999999999, -82.99999999999999], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13576172512928378, "mean_inference_ms": 1.2028752051507097, "mean_action_processing_ms": 0.05390113360463732, "mean_env_wait_ms": 2.3814079359522053, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 16000, "agent_timesteps_total": 16000, "timers": {"sample_time_ms": 7663.099, "sample_throughput": 521.982, "load_time_ms": 0.054, "load_throughput": 73989927.233, "learn_time_ms": 7664.641, "learn_throughput": 521.877, "update_time_ms": 1.381}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 1522.0500244140626, "policy_loss": -0.045569043869893716, "vf_loss": 1522.0923001853369, "vf_explained_var": [-0.28858324885368347], "kl": 0.01646000266730378, "entropy": 2.656545050938924, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 16000, "num_agent_steps_sampled": 16000, "num_steps_trained": 16000, "num_agent_steps_trained": 16000}, "done": false, "episodes_total": 1066, "training_iteration": 4, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-11-33", "timestamp": 1632517893, "time_this_iter_s": 14.444608449935913, "time_total_s": 61.350377559661865, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 61.350377559661865, "timesteps_since_restore": 0, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 32.955, "ram_util_percent": 15.800000000000002}}
{"episode_reward_max": -34.2, "episode_reward_min": -165.79999999999978, "episode_reward_mean": -78.29924812030075, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-60.00000000000001, -81.3, -40.2, -102.59999999999991, -66.19999999999999, -86.79999999999997, -59.500000000000014, -56.00000000000001, -129.49999999999991, -69.80000000000001, -60.49999999999999, -104.39999999999998, -48.800000000000004, -71.79999999999998, -76.30000000000003, -69.5, -112.89999999999993, -50.60000000000001, -70.19999999999999, -53.30000000000001, -78.0, -98.79999999999998, -102.19999999999997, -133.1999999999999, -76.10000000000001, -48.10000000000001, -102.89999999999998, -76.4, -125.99999999999986, -119.69999999999986, -85.09999999999998, -58.10000000000001, -113.39999999999989, -72.4, -74.60000000000001, -71.3, -100.39999999999998, -59.50000000000002, -72.5, -84.10000000000001, -68.6, -63.80000000000001, -74.79999999999998, -60.400000000000006, -77.0, -65.60000000000001, -112.99999999999999, -56.2, -120.49999999999994, -85.60000000000002, -109.69999999999997, -53.7, -49.8, -83.29999999999995, -131.69999999999993, -65.89999999999999, -90.99999999999999, -100.79999999999995, -50.400000000000006, -102.69999999999997, -89.29999999999995, -75.29999999999998, -73.5, -76.79999999999998, -73.5, -66.1, -88.8, -115.39999999999993, -88.6, -68.9, -47.900000000000006, -68.5, -78.6, -103.10000000000001, -76.3, -72.1, -86.69999999999996, -87.7, -93.1, -39.800000000000004, -48.400000000000006, -134.0999999999999, -88.79999999999995, -145.19999999999993, -70.19999999999999, -66.0, -77.19999999999999, -80.49999999999999, -44.000000000000014, -47.5, -94.6, -79.49999999999999, -97.29999999999993, -56.800000000000004, -61.09999999999999, -74.29999999999998, -68.2, -45.09999999999999, -88.20000000000002, -50.80000000000001, -79.4, -113.29999999999994, -34.2, -84.79999999999997, -45.70000000000001, -66.60000000000001, -81.29999999999997, -77.10000000000001, -81.60000000000002, -75.19999999999999, -141.99999999999994, -73.1, -111.49999999999997, -102.79999999999997, -165.69999999999985, -84.69999999999999, -69.4, -85.09999999999998, -131.39999999999992, -76.59999999999998, -127.79999999999986, -67.6, -50.59999999999999, -60.7, -63.400000000000006, -56.50000000000001, -59.60000000000001, -58.70000000000002, -96.69999999999999, -73.0, -63.6, -74.8, -64.9, -67.8, -44.50000000000001, -87.69999999999997, -67.2, -80.0, -53.30000000000001, -73.9, -112.69999999999993, -69.80000000000001, -57.20000000000002, -83.59999999999998, -84.89999999999995, -36.900000000000006, -72.3, -140.79999999999987, -35.3, -139.69999999999987, -126.89999999999986, -59.400000000000006, -71.7, -55.099999999999994, -102.19999999999996, -72.1, -83.49999999999999, -119.79999999999994, -98.69999999999996, -70.49999999999996, -76.29999999999998, -96.59999999999998, -105.89999999999995, -80.69999999999997, -48.800000000000004, -58.4, -63.8, -91.09999999999998, -78.10000000000002, -93.50000000000001, -69.39999999999999, -71.89999999999999, -78.1, -82.9, -54.70000000000002, -78.59999999999998, -85.10000000000002, -69.19999999999999, -63.900000000000006, -85.0, -69.7, -109.09999999999988, -113.09999999999995, -79.30000000000001, -79.6, -97.99999999999997, -93.50000000000001, -73.99999999999999, -165.79999999999978, -78.1, -47.50000000000001, -67.9, -94.29999999999995, -86.89999999999996, -46.900000000000006, -68.39999999999999, -68.9, -75.39999999999999, -85.19999999999997, -83.99999999999996, -48.0, -53.300000000000004, -84.69999999999999, -81.19999999999999, -65.2, -51.0, -45.7, -64.5, -34.400000000000006, -77.70000000000002, -47.50000000000001, -62.30000000000002, -63.999999999999986, -85.09999999999995, -58.7, -133.59999999999988, -60.00000000000002, -92.89999999999996, -72.4, -75.49999999999996, -54.999999999999986, -105.79999999999995, -56.100000000000016, -77.70000000000002, -84.3, -74.19999999999999, -88.99999999999999, -91.6, -73.79999999999998, -40.7, -97.79999999999995, -75.30000000000001, -67.99999999999999, -102.29999999999995, -85.49999999999996, -126.89999999999992, -90.80000000000001, -70.69999999999999, -47.80000000000001, -67.90000000000002, -40.5, -120.19999999999993, -58.5, -71.29999999999998, -40.0, -94.2, -86.3, -77.50000000000001, -68.9, -83.00000000000001, -80.4, -54.0, -71.60000000000001, -91.99999999999999, -38.800000000000004, -76.69999999999999, -83.89999999999999, -92.99999999999996, -50.30000000000001, -76.7, -91.89999999999996, -48.800000000000004, -61.9, -90.79999999999994, -42.300000000000004, -75.39999999999998], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13512554746570019, "mean_inference_ms": 1.2007985350108483, "mean_action_processing_ms": 0.053859176593784704, "mean_env_wait_ms": 2.3569514806026723, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 20000, "agent_timesteps_total": 20000, "timers": {"sample_time_ms": 7614.414, "sample_throughput": 525.319, "load_time_ms": 0.057, "load_throughput": 69963369.475, "learn_time_ms": 7552.657, "learn_throughput": 529.615, "update_time_ms": 1.399}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 1059.0875714045699, "policy_loss": -0.04494778769070743, "vf_loss": 1059.1286366452453, "vf_explained_var": [-0.287060409784317], "kl": 0.01941571173981923, "entropy": 2.6191445407047067, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 20000, "num_agent_steps_sampled": 20000, "num_steps_trained": 20000, "num_agent_steps_trained": 20000}, "done": false, "episodes_total": 1332, "training_iteration": 5, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-11-47", "timestamp": 1632517907, "time_this_iter_s": 14.53377079963684, "time_total_s": 75.8841483592987, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 75.8841483592987, "timesteps_since_restore": 0, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 34.285714285714285, "ram_util_percent": 15.800000000000002}}
{"episode_reward_max": -30.8, "episode_reward_min": -155.49999999999986, "episode_reward_mean": -74.62798507462685, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 268, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.5, -113.09999999999997, -64.30000000000001, -54.7, -75.2, -77.99999999999999, -87.49999999999999, -49.0, -62.2, -68.3, -48.699999999999996, -91.79999999999998, -80.39999999999999, -70.10000000000001, -68.5, -81.49999999999999, -39.400000000000006, -47.5, -94.79999999999998, -56.600000000000016, -41.30000000000001, -45.00000000000001, -69.70000000000002, -80.89999999999996, -155.49999999999986, -47.00000000000001, -90.8, -42.90000000000001, -137.4999999999999, -69.5, -93.99999999999999, -75.9, -83.6, -43.399999999999984, -69.80000000000001, -59.0, -52.99999999999999, -99.59999999999998, -91.89999999999996, -60.2, -70.9, -109.39999999999996, -69.70000000000002, -66.0, -115.69999999999996, -108.0, -54.800000000000004, -49.90000000000001, -108.49999999999994, -65.60000000000001, -79.40000000000002, -72.3, -75.3, -67.89999999999999, -66.30000000000001, -73.9, -69.5, -90.49999999999999, -42.5, -73.39999999999999, -60.10000000000001, -60.800000000000004, -130.0999999999999, -83.69999999999999, -51.49999999999999, -68.49999999999999, -95.59999999999995, -149.09999999999985, -73.39999999999998, -107.39999999999999, -114.39999999999995, -41.0, -139.29999999999993, -80.89999999999998, -133.4999999999999, -58.2, -50.400000000000006, -78.69999999999997, -108.49999999999997, -79.99999999999999, -77.60000000000001, -97.1, -96.0, -113.59999999999997, -68.49999999999997, -41.199999999999996, -69.2, -97.99999999999996, -68.20000000000002, -49.99999999999999, -59.30000000000001, -105.79999999999995, -102.79999999999994, -102.29999999999997, -57.00000000000001, -85.30000000000001, -76.0, -71.40000000000002, -84.9, -86.19999999999999, -45.60000000000001, -66.70000000000002, -55.19999999999999, -76.79999999999998, -109.09999999999992, -80.49999999999999, -103.0, -90.19999999999996, -97.79999999999997, -59.2, -60.800000000000004, -79.0, -65.2, -71.1, -56.30000000000001, -70.80000000000001, -126.19999999999992, -54.10000000000001, -68.9, -86.6, -74.1, -52.50000000000001, -65.6, -32.0, -38.7, -58.40000000000002, -67.19999999999999, -100.09999999999997, -39.8, -68.1, -64.9, -82.49999999999999, -35.8, -56.000000000000014, -85.9, -81.89999999999999, -64.7, -141.89999999999992, -87.3, -68.9, -89.29999999999998, -60.000000000000014, -109.49999999999993, -65.50000000000001, -58.3, -57.4, -41.900000000000006, -58.3, -92.19999999999995, -87.49999999999996, -82.79999999999998, -66.29999999999997, -84.8, -54.60000000000001, -53.900000000000006, -65.1, -100.8, -77.6, -30.8, -53.50000000000001, -66.5, -71.79999999999998, -106.79999999999997, -87.8, -60.900000000000006, -46.50000000000001, -98.09999999999995, -98.29999999999995, -62.4, -61.900000000000006, -73.10000000000001, -83.40000000000002, -86.39999999999998, -78.2, -74.39999999999999, -45.6, -78.7, -59.00000000000001, -79.19999999999997, -74.6, -50.49999999999999, -98.59999999999997, -105.39999999999995, -46.8, -62.7, -126.49999999999993, -50.7, -62.09999999999999, -61.20000000000002, -76.79999999999998, -41.6, -84.59999999999997, -90.29999999999997, -89.69999999999996, -33.9, -79.70000000000002, -80.4, -69.9, -77.4, -75.69999999999999, -65.39999999999998, -73.50000000000001, -85.1, -67.1, -95.99999999999994, -132.7999999999998, -72.49999999999999, -91.19999999999999, -85.29999999999997, -39.00000000000001, -66.2, -138.89999999999992, -59.69999999999999, -77.7, -87.39999999999999, -64.60000000000001, -71.30000000000003, -93.59999999999995, -104.59999999999988, -52.900000000000006, -71.3, -65.2, -52.30000000000001, -65.00000000000001, -84.29999999999998, -78.59999999999998, -46.900000000000006, -54.00000000000001, -32.900000000000006, -87.09999999999998, -95.50000000000001, -52.6, -51.8, -61.10000000000001, -67.80000000000001, -71.89999999999999, -47.00000000000001, -62.699999999999996, -65.9, -46.50000000000001, -57.59999999999999, -84.99999999999994, -147.09999999999988, -82.79999999999998, -79.49999999999997, -50.30000000000001, -38.400000000000006, -62.900000000000006, -74.89999999999999, -53.0, -126.89999999999992, -55.10000000000001, -43.7, -60.70000000000001, -85.79999999999998, -79.19999999999999, -68.00000000000001, -55.20000000000002, -107.09999999999988, -57.60000000000001, -89.89999999999999, -86.29999999999998, -78.69999999999999, -128.0999999999999, -53.50000000000001, -64.0, -71.79999999999998, -46.800000000000004], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1347728316341477, "mean_inference_ms": 1.2012221258726232, "mean_action_processing_ms": 0.05384810059659233, "mean_env_wait_ms": 2.339723129866868, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 24000, "agent_timesteps_total": 24000, "timers": {"sample_time_ms": 7578.263, "sample_throughput": 527.825, "load_time_ms": 0.055, "load_throughput": 72838853.835, "learn_time_ms": 7550.076, "learn_throughput": 529.796, "update_time_ms": 1.392}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 837.4822361443632, "policy_loss": -0.040154124988913936, "vf_loss": 837.5190992786038, "vf_explained_var": [-0.16106019914150238], "kl": 0.0164479692718517, "entropy": 2.556300146861743, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 24000, "num_agent_steps_sampled": 24000, "num_steps_trained": 24000, "num_agent_steps_trained": 24000}, "done": false, "episodes_total": 1600, "training_iteration": 6, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-12-02", "timestamp": 1632517922, "time_this_iter_s": 14.944292783737183, "time_total_s": 90.82844114303589, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 90.82844114303589, "timesteps_since_restore": 0, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 35.154545454545456, "ram_util_percent": 15.800000000000004}}
{"episode_reward_max": -22.500000000000004, "episode_reward_min": -164.69999999999985, "episode_reward_mean": -72.85676691729323, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-93.49999999999994, -103.99999999999993, -65.00000000000001, -78.29999999999995, -60.599999999999994, -87.49999999999999, -63.7, -47.7, -77.79999999999998, -70.6, -43.50000000000001, -62.0, -69.9, -58.80000000000001, -59.7, -65.70000000000002, -50.60000000000001, -64.10000000000001, -75.99999999999999, -67.50000000000001, -94.79999999999998, -77.69999999999996, -42.9, -91.89999999999996, -66.39999999999999, -67.5, -81.7, -80.0, -96.89999999999998, -63.89999999999999, -63.20000000000002, -38.9, -122.69999999999995, -94.99999999999999, -85.89999999999999, -67.89999999999999, -73.39999999999999, -49.70000000000001, -68.0, -64.10000000000001, -74.4, -96.69999999999992, -45.5, -97.29999999999995, -102.79999999999994, -70.5, -101.69999999999997, -47.099999999999994, -92.6, -80.99999999999997, -84.50000000000001, -24.700000000000003, -72.6, -69.1, -54.1, -61.0, -74.59999999999998, -66.40000000000002, -57.20000000000002, -74.5, -48.9, -91.49999999999997, -42.80000000000001, -30.200000000000003, -33.9, -70.1, -64.60000000000001, -71.0, -68.80000000000001, -60.00000000000001, -40.400000000000006, -83.00000000000001, -89.69999999999999, -43.800000000000004, -93.79999999999995, -82.8, -128.19999999999993, -22.500000000000004, -61.400000000000006, -39.400000000000006, -54.30000000000001, -73.5, -79.30000000000001, -102.69999999999996, -99.9999999999999, -62.99999999999999, -69.9, -65.39999999999998, -78.9, -84.90000000000002, -68.0, -56.7, -98.39999999999996, -65.80000000000001, -164.69999999999985, -69.80000000000001, -81.39999999999998, -55.6, -72.4, -146.19999999999985, -77.29999999999998, -144.4999999999999, -89.29999999999998, -96.09999999999995, -138.29999999999984, -73.9, -115.49999999999993, -79.19999999999999, -60.80000000000001, -49.40000000000001, -64.60000000000001, -49.20000000000001, -48.2, -40.400000000000006, -85.09999999999998, -112.19999999999993, -38.6, -83.3, -67.2, -93.49999999999994, -78.89999999999998, -71.80000000000003, -59.1, -67.1, -65.70000000000002, -80.49999999999999, -57.00000000000001, -41.400000000000006, -40.300000000000004, -100.69999999999997, -82.39999999999999, -90.7, -93.19999999999996, -120.39999999999992, -72.89999999999999, -74.10000000000002, -76.5, -47.199999999999996, -87.7, -54.2, -84.8, -97.9, -92.19999999999996, -43.900000000000006, -66.9, -72.09999999999997, -46.8, -81.09999999999997, -61.900000000000006, -92.09999999999998, -110.49999999999991, -81.59999999999998, -82.10000000000002, -76.3, -68.80000000000001, -78.1, -96.49999999999997, -53.399999999999984, -78.49999999999997, -62.099999999999994, -86.49999999999999, -62.300000000000004, -61.00000000000001, -65.80000000000001, -72.19999999999997, -71.19999999999999, -70.70000000000002, -69.69999999999999, -63.699999999999996, -71.5, -44.900000000000006, -68.5, -72.49999999999999, -66.39999999999999, -43.5, -42.300000000000004, -93.59999999999995, -53.400000000000006, -88.9, -111.99999999999994, -47.0, -93.1, -50.9, -50.59999999999999, -65.10000000000001, -100.49999999999996, -58.29999999999998, -65.0, -64.7, -77.2, -71.3, -155.29999999999984, -66.89999999999998, -115.79999999999993, -58.2, -76.80000000000001, -57.2, -90.29999999999997, -78.9, -144.4999999999999, -43.0, -54.1, -30.400000000000006, -33.20000000000001, -76.80000000000001, -69.10000000000001, -95.59999999999997, -49.00000000000001, -82.4, -70.2, -74.8, -73.39999999999999, -143.49999999999983, -44.5, -74.10000000000001, -59.800000000000004, -36.1, -115.19999999999993, -76.49999999999999, -45.6, -68.89999999999999, -80.09999999999995, -74.5, -58.299999999999976, -89.79999999999997, -52.0, -71.69999999999999, -56.500000000000014, -42.900000000000006, -82.09999999999998, -91.49999999999997, -69.80000000000001, -64.5, -55.20000000000001, -44.7, -137.19999999999985, -60.4, -52.80000000000001, -108.99999999999997, -65.80000000000001, -57.20000000000001, -76.70000000000002, -42.5, -82.69999999999999, -119.39999999999992, -104.09999999999994, -96.49999999999997, -52.300000000000004, -88.69999999999999, -89.89999999999998, -47.300000000000004, -132.59999999999988, -65.50000000000001, -44.900000000000006, -25.400000000000002, -43.1, -53.100000000000016, -41.00000000000001, -66.50000000000001, -48.7, -92.8999999999999, -72.60000000000001, -56.70000000000001, -60.2, -82.19999999999999, -73.0], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13472885585207572, "mean_inference_ms": 1.2047868159471022, "mean_action_processing_ms": 0.05398853430875021, "mean_env_wait_ms": 2.331640079918696, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 28000, "agent_timesteps_total": 28000, "timers": {"sample_time_ms": 7572.97, "sample_throughput": 528.194, "load_time_ms": 0.053, "load_throughput": 75089841.432, "learn_time_ms": 7498.797, "learn_throughput": 533.419, "update_time_ms": 1.378}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 736.9026353733514, "policy_loss": -0.04708999365027393, "vf_loss": 736.945899093792, "vf_explained_var": [-0.04531102254986763], "kl": 0.0191174089409813, "entropy": 2.4978687724759503, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 28000, "num_agent_steps_sampled": 28000, "num_steps_trained": 28000, "num_agent_steps_trained": 28000}, "done": false, "episodes_total": 1866, "training_iteration": 7, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-12-17", "timestamp": 1632517937, "time_this_iter_s": 14.742771863937378, "time_total_s": 105.57121300697327, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 105.57121300697327, "timesteps_since_restore": 0, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 34.28095238095238, "ram_util_percent": 15.800000000000002}}
{"episode_reward_max": -28.400000000000002, "episode_reward_min": -150.79999999999984, "episode_reward_mean": -67.67631578947369, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-62.099999999999994, -44.20000000000001, -57.100000000000016, -61.699999999999996, -53.20000000000002, -70.29999999999998, -57.100000000000016, -67.2, -65.2, -94.79999999999998, -43.80000000000001, -119.19999999999986, -46.00000000000001, -72.2, -74.3, -43.6, -101.29999999999993, -65.30000000000001, -48.6, -55.699999999999996, -71.8, -38.7, -59.30000000000001, -85.30000000000001, -60.00000000000001, -89.59999999999995, -47.10000000000001, -73.80000000000003, -76.00000000000001, -68.30000000000001, -59.300000000000004, -126.59999999999994, -74.69999999999999, -85.99999999999997, -55.600000000000016, -71.10000000000001, -87.39999999999999, -57.6, -47.300000000000004, -72.0, -74.30000000000001, -47.8, -71.6, -62.2, -100.09999999999995, -50.199999999999996, -60.10000000000002, -124.49999999999991, -47.2, -82.0, -48.60000000000001, -86.7, -72.80000000000001, -112.09999999999995, -57.10000000000001, -28.400000000000002, -34.6, -52.70000000000001, -65.59999999999998, -78.79999999999998, -80.00000000000001, -55.20000000000001, -68.39999999999998, -61.99999999999999, -82.49999999999994, -67.60000000000001, -65.99999999999999, -97.29999999999998, -75.39999999999999, -69.59999999999998, -74.3, -68.0, -53.300000000000004, -68.0, -53.20000000000002, -118.99999999999989, -51.1, -150.79999999999984, -48.5, -46.7, -82.89999999999998, -128.1999999999999, -91.09999999999997, -69.10000000000001, -85.39999999999999, -41.49999999999999, -72.4, -83.8, -53.800000000000004, -57.9, -86.09999999999998, -92.40000000000002, -51.199999999999996, -48.10000000000001, -54.80000000000001, -57.6, -41.9, -108.99999999999994, -72.6, -52.9, -28.700000000000003, -72.00000000000001, -83.69999999999999, -61.100000000000016, -100.09999999999998, -59.50000000000001, -95.49999999999999, -66.89999999999999, -66.4, -67.90000000000002, -35.5, -45.800000000000004, -76.49999999999997, -42.70000000000001, -60.10000000000001, -73.10000000000001, -38.2, -41.00000000000001, -36.6, -69.4, -47.0, -57.2, -51.4, -73.1, -66.5, -81.5, -82.5, -61.60000000000001, -74.30000000000001, -57.000000000000014, -41.300000000000004, -44.500000000000014, -122.29999999999993, -36.900000000000006, -69.6, -65.60000000000001, -52.70000000000001, -62.39999999999999, -72.30000000000001, -66.30000000000001, -74.10000000000002, -70.4, -51.900000000000006, -75.2, -63.20000000000002, -84.4, -81.80000000000001, -53.10000000000001, -84.60000000000001, -64.70000000000002, -71.79999999999998, -59.600000000000016, -74.60000000000001, -71.4, -92.49999999999999, -78.19999999999999, -66.4, -66.4, -71.79999999999998, -65.6, -82.40000000000002, -59.7, -75.79999999999998, -68.89999999999999, -71.80000000000003, -60.7, -39.400000000000006, -42.2, -84.79999999999998, -82.69999999999999, -86.79999999999998, -49.80000000000001, -62.30000000000001, -119.89999999999996, -73.7, -48.50000000000001, -46.90000000000002, -87.19999999999993, -97.10000000000001, -148.39999999999984, -81.8, -56.50000000000001, -64.2, -71.00000000000001, -82.09999999999998, -73.30000000000003, -53.000000000000014, -66.10000000000001, -57.600000000000016, -94.0, -58.900000000000006, -37.300000000000004, -62.8, -51.80000000000001, -66.4, -51.900000000000006, -40.900000000000006, -62.900000000000006, -79.19999999999999, -34.4, -72.60000000000001, -52.1, -52.2, -47.300000000000004, -96.6, -58.00000000000001, -70.5, -80.09999999999998, -75.10000000000002, -89.19999999999997, -90.29999999999991, -43.599999999999994, -64.1, -72.0, -60.5, -79.3, -78.99999999999997, -87.99999999999999, -45.00000000000001, -66.4, -49.400000000000006, -72.3, -41.00000000000001, -65.80000000000001, -85.3, -49.900000000000006, -70.69999999999999, -78.0, -55.7, -56.4, -76.5, -46.1, -58.800000000000004, -65.50000000000001, -58.7, -71.50000000000001, -50.50000000000001, -63.800000000000004, -78.1, -59.400000000000006, -73.19999999999999, -52.60000000000001, -47.400000000000006, -55.80000000000001, -65.1, -60.80000000000001, -100.49999999999997, -85.69999999999996, -64.60000000000001, -53.900000000000006, -135.39999999999984, -52.9, -62.100000000000016, -75.8, -33.9, -84.6, -60.89999999999999, -67.30000000000001, -71.60000000000001, -63.40000000000001, -86.79999999999997, -57.30000000000001, -64.2, -62.000000000000014, -53.1, -54.80000000000001], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1362026739802914, "mean_inference_ms": 1.2209208546098445, "mean_action_processing_ms": 0.05477705222950467, "mean_env_wait_ms": 2.33296262242706, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 32000, "agent_timesteps_total": 32000, "timers": {"sample_time_ms": 7609.898, "sample_throughput": 525.631, "load_time_ms": 0.054, "load_throughput": 74194432.283, "learn_time_ms": 7473.688, "learn_throughput": 535.211, "update_time_ms": 1.399}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 556.4911375312395, "policy_loss": -0.0425219704952812, "vf_loss": 556.530386352539, "vf_explained_var": [0.007758741267025471], "kl": 0.016356829442311885, "entropy": 2.4170009633546234, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 32000, "num_agent_steps_sampled": 32000, "num_steps_trained": 32000, "num_agent_steps_trained": 32000}, "done": false, "episodes_total": 2132, "training_iteration": 8, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-12-32", "timestamp": 1632517952, "time_this_iter_s": 15.175917863845825, "time_total_s": 120.74713087081909, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 120.74713087081909, "timesteps_since_restore": 0, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 33.32857142857143, "ram_util_percent": 15.800000000000002}}
{"episode_reward_max": -32.6, "episode_reward_min": -149.4999999999999, "episode_reward_mean": -64.20447761194029, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 268, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-61.90000000000001, -41.400000000000006, -90.89999999999999, -84.1, -81.19999999999999, -72.3, -67.7, -58.400000000000006, -58.8, -49.300000000000004, -59.70000000000001, -72.5, -53.20000000000001, -58.00000000000001, -48.6, -53.7, -77.89999999999998, -74.09999999999995, -40.60000000000001, -38.70000000000001, -58.29999999999998, -55.2, -64.4, -87.69999999999999, -49.10000000000001, -69.89999999999998, -66.20000000000002, -50.900000000000006, -50.9, -70.10000000000001, -43.00000000000001, -43.40000000000001, -68.5, -94.39999999999998, -56.699999999999996, -61.5, -60.900000000000006, -64.10000000000002, -50.800000000000004, -52.20000000000002, -64.0, -76.9, -59.2, -104.99999999999993, -66.9, -98.49999999999999, -79.40000000000002, -70.00000000000001, -58.500000000000014, -50.60000000000001, -53.600000000000016, -55.3, -50.2, -36.400000000000006, -80.69999999999997, -82.49999999999999, -41.7, -43.00000000000001, -54.7, -62.900000000000006, -47.20000000000001, -52.90000000000001, -65.2, -44.900000000000006, -46.500000000000014, -54.499999999999986, -82.8, -48.3, -149.4999999999999, -36.6, -81.9, -75.0, -59.900000000000006, -100.79999999999995, -47.7, -71.5, -58.600000000000016, -96.69999999999996, -39.2, -32.8, -68.40000000000002, -49.7, -52.6, -68.1, -47.400000000000006, -87.49999999999994, -58.8, -67.6, -67.2, -61.70000000000001, -50.00000000000001, -66.89999999999996, -65.79999999999998, -48.0, -56.10000000000001, -53.70000000000001, -51.400000000000006, -43.7, -85.09999999999998, -101.39999999999996, -70.80000000000001, -52.1, -66.7, -37.1, -67.6, -57.30000000000001, -89.39999999999999, -49.90000000000001, -64.9, -58.7, -53.400000000000006, -60.80000000000001, -42.50000000000001, -49.400000000000006, -66.60000000000001, -86.7, -47.10000000000001, -64.49999999999999, -73.3, -58.60000000000001, -41.800000000000004, -78.29999999999995, -54.00000000000001, -68.7, -58.2, -47.800000000000004, -40.10000000000001, -56.500000000000014, -105.89999999999992, -58.699999999999996, -143.19999999999987, -61.500000000000014, -80.19999999999996, -79.4, -45.7, -75.2, -60.80000000000001, -59.20000000000001, -64.90000000000002, -71.30000000000001, -66.5, -64.0, -63.30000000000001, -64.4, -65.89999999999999, -47.900000000000006, -61.600000000000016, -93.99999999999999, -53.10000000000001, -49.50000000000001, -55.099999999999994, -44.2, -50.00000000000001, -54.0, -64.0, -39.70000000000001, -40.7, -54.900000000000006, -66.70000000000002, -79.6, -97.39999999999995, -94.19999999999996, -98.69999999999997, -39.00000000000001, -79.49999999999997, -65.00000000000001, -71.39999999999999, -43.900000000000006, -53.000000000000014, -59.60000000000001, -89.19999999999999, -43.9, -83.89999999999998, -43.2, -78.79999999999997, -63.800000000000004, -64.4, -63.0, -44.50000000000001, -72.80000000000001, -64.70000000000002, -42.900000000000006, -53.899999999999984, -65.60000000000001, -57.8, -56.9, -66.00000000000001, -44.400000000000006, -82.1, -58.70000000000001, -102.0, -66.4, -88.5, -109.99999999999996, -70.20000000000002, -63.9, -80.5, -86.49999999999999, -65.9, -74.2, -64.90000000000002, -65.0, -45.0, -45.10000000000001, -36.3, -51.20000000000001, -111.59999999999994, -101.19999999999997, -54.00000000000001, -32.6, -101.19999999999996, -38.50000000000001, -55.600000000000016, -72.20000000000002, -48.30000000000001, -117.99999999999993, -80.8, -53.999999999999986, -112.79999999999993, -65.39999999999999, -71.30000000000001, -65.1, -85.49999999999994, -39.50000000000001, -50.5, -42.900000000000006, -63.0, -80.5, -55.39999999999997, -75.0, -45.7, -106.19999999999997, -46.7, -54.9, -44.6, -64.4, -95.19999999999999, -57.400000000000006, -65.0, -60.90000000000001, -58.5, -53.80000000000001, -74.4, -74.7, -50.10000000000001, -52.50000000000001, -39.10000000000001, -59.7, -57.500000000000014, -80.29999999999998, -42.7, -36.4, -46.10000000000001, -70.0, -40.300000000000004, -62.099999999999994, -39.2, -91.7, -59.00000000000001, -42.10000000000001, -78.49999999999999, -65.1, -56.900000000000006, -99.39999999999998, -116.8999999999999, -120.39999999999985, -60.50000000000001, -62.5], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13613888942018548, "mean_inference_ms": 1.2236683906816679, "mean_action_processing_ms": 0.05487827226642927, "mean_env_wait_ms": 2.3245575706016144, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 36000, "agent_timesteps_total": 36000, "timers": {"sample_time_ms": 7598.119, "sample_throughput": 526.446, "load_time_ms": 0.054, "load_throughput": 73908440.529, "learn_time_ms": 7446.473, "learn_throughput": 537.167, "update_time_ms": 1.393}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 506.6380305136404, "policy_loss": -0.0431533938614271, "vf_loss": 506.677929523427, "vf_explained_var": [0.02219061367213726], "kl": 0.01628518126328334, "entropy": 2.3602031959000453, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 36000, "num_agent_steps_sampled": 36000, "num_steps_trained": 36000, "num_agent_steps_trained": 36000}, "done": false, "episodes_total": 2400, "training_iteration": 9, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-12-47", "timestamp": 1632517967, "time_this_iter_s": 14.742475509643555, "time_total_s": 135.48960638046265, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 135.48960638046265, "timesteps_since_restore": 0, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 34.65238095238095, "ram_util_percent": 15.800000000000002}}
{"episode_reward_max": -28.1, "episode_reward_min": -147.79999999999984, "episode_reward_mean": -62.280451127819546, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-62.30000000000001, -60.2, -39.800000000000004, -57.10000000000001, -55.50000000000001, -65.9, -56.400000000000006, -45.5, -51.59999999999999, -65.1, -45.2, -59.400000000000006, -72.89999999999998, -46.500000000000014, -70.60000000000001, -76.4, -44.30000000000001, -57.59999999999999, -76.6, -40.900000000000006, -56.60000000000001, -67.70000000000002, -36.6, -67.10000000000001, -76.4, -82.39999999999999, -93.7, -101.3, -79.1, -60.90000000000001, -89.59999999999997, -59.20000000000001, -36.4, -72.0, -35.10000000000001, -52.900000000000006, -59.40000000000001, -41.4, -51.00000000000001, -111.8999999999999, -47.699999999999996, -67.9, -45.10000000000001, -58.000000000000014, -70.9, -42.7, -49.6, -58.40000000000001, -43.400000000000006, -55.199999999999996, -54.2, -47.3, -100.00000000000001, -70.79999999999998, -42.50000000000001, -48.50000000000001, -64.30000000000001, -82.1, -71.9, -70.6, -110.99999999999989, -52.599999999999994, -38.0, -63.400000000000006, -50.20000000000002, -73.5, -30.3, -48.800000000000004, -79.4, -82.80000000000001, -53.5, -67.80000000000001, -62.8, -45.900000000000006, -67.0, -64.0, -72.3, -86.6, -54.20000000000001, -68.89999999999999, -72.4, -38.5, -52.2, -50.00000000000001, -51.89999999999999, -51.50000000000001, -40.2, -50.70000000000001, -53.900000000000006, -42.5, -40.00000000000001, -52.2, -88.6, -81.8, -68.19999999999999, -51.2, -74.60000000000001, -28.1, -49.60000000000001, -95.39999999999999, -40.2, -104.69999999999993, -56.300000000000004, -51.900000000000006, -69.60000000000001, -76.6, -53.5, -65.10000000000001, -61.300000000000004, -82.79999999999995, -61.900000000000006, -98.69999999999999, -55.10000000000001, -40.300000000000004, -44.20000000000001, -48.80000000000001, -44.0, -52.2, -53.800000000000004, -77.40000000000002, -28.6, -73.3, -71.5, -33.800000000000004, -107.19999999999996, -71.99999999999999, -51.70000000000002, -87.0, -71.2, -67.0, -64.5, -69.4, -85.7, -42.00000000000001, -78.39999999999999, -83.0, -71.30000000000003, -81.99999999999999, -56.300000000000004, -43.400000000000006, -90.30000000000001, -51.00000000000001, -75.8, -70.69999999999996, -62.6, -64.80000000000001, -57.60000000000001, -54.400000000000006, -42.2, -75.39999999999998, -63.5, -86.1, -51.70000000000001, -69.0, -68.49999999999997, -42.2, -39.400000000000006, -34.300000000000004, -75.30000000000001, -74.3, -92.19999999999999, -39.300000000000004, -29.6, -59.5, -64.69999999999999, -64.7, -50.60000000000001, -67.3, -70.50000000000001, -47.20000000000001, -51.60000000000001, -57.600000000000016, -58.900000000000006, -47.80000000000001, -53.000000000000014, -48.80000000000001, -78.40000000000002, -54.10000000000001, -55.500000000000014, -70.49999999999999, -56.10000000000001, -64.7, -48.2, -65.0, -46.800000000000004, -50.8, -102.89999999999995, -83.59999999999998, -43.90000000000001, -93.69999999999995, -44.70000000000001, -92.29999999999997, -38.6, -63.49999999999999, -78.39999999999999, -64.6, -47.20000000000001, -36.7, -50.6, -45.300000000000004, -60.90000000000001, -80.69999999999999, -135.99999999999986, -123.69999999999995, -55.8, -49.90000000000001, -44.50000000000001, -70.99999999999999, -94.69999999999997, -77.80000000000001, -54.70000000000002, -53.099999999999994, -42.0, -55.70000000000001, -46.9, -43.50000000000001, -43.00000000000001, -54.400000000000006, -83.60000000000002, -49.80000000000001, -67.10000000000001, -53.500000000000014, -64.39999999999999, -57.500000000000014, -31.5, -67.5, -120.59999999999992, -60.800000000000004, -71.1, -74.7, -65.30000000000001, -72.10000000000001, -39.900000000000006, -72.4, -78.10000000000001, -67.80000000000003, -46.800000000000004, -58.900000000000006, -60.10000000000001, -64.9, -147.79999999999984, -62.599999999999994, -57.2, -58.900000000000006, -89.29999999999998, -50.50000000000001, -41.7, -40.60000000000001, -55.39999999999999, -58.7, -76.0, -62.0, -96.69999999999996, -99.29999999999998, -49.2, -31.400000000000002, -60.3, -38.80000000000001, -65.10000000000001, -60.900000000000006, -34.5, -83.39999999999998, -52.20000000000002, -73.8, -52.3, -67.0], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13768559699952318, "mean_inference_ms": 1.2357066937741217, "mean_action_processing_ms": 0.0553796556101913, "mean_env_wait_ms": 2.3237836044446563, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 40000, "agent_timesteps_total": 40000, "timers": {"sample_time_ms": 7631.088, "sample_throughput": 524.172, "load_time_ms": 0.054, "load_throughput": 73843380.282, "learn_time_ms": 7491.827, "learn_throughput": 533.915, "update_time_ms": 1.41}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 452.0150266585811, "policy_loss": -0.04308756312796025, "vf_loss": 452.0550272295552, "vf_explained_var": [0.022769339382648468], "kl": 0.015441581219053806, "entropy": 2.269893927727976, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 40000, "num_agent_steps_sampled": 40000, "num_steps_trained": 40000, "num_agent_steps_trained": 40000}, "done": false, "episodes_total": 2666, "training_iteration": 10, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-13-03", "timestamp": 1632517983, "time_this_iter_s": 15.837538242340088, "time_total_s": 151.32714462280273, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 151.32714462280273, "timesteps_since_restore": 0, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 36.81739130434782, "ram_util_percent": 15.843478260869569}}
{"episode_reward_max": -24.200000000000003, "episode_reward_min": -136.69999999999987, "episode_reward_mean": -60.728571428571435, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-47.60000000000001, -47.900000000000006, -63.39999999999999, -75.9, -63.5, -53.7, -63.7, -53.1, -52.5, -83.2, -53.00000000000001, -51.10000000000001, -68.50000000000001, -44.1, -33.6, -63.50000000000001, -55.0, -85.79999999999997, -54.60000000000001, -55.000000000000014, -64.8, -79.80000000000003, -51.3, -28.8, -33.3, -67.30000000000001, -71.30000000000003, -62.7, -51.40000000000001, -48.6, -63.5, -41.4, -40.7, -70.80000000000001, -49.000000000000014, -62.40000000000002, -46.1, -86.8, -126.09999999999994, -35.5, -64.10000000000001, -97.19999999999993, -52.30000000000001, -90.3, -60.1, -37.5, -60.800000000000004, -52.800000000000004, -51.50000000000001, -81.19999999999997, -110.5, -45.500000000000014, -49.6, -73.80000000000001, -66.30000000000001, -64.19999999999999, -68.1, -48.900000000000006, -34.7, -70.7, -69.1, -56.500000000000014, -54.00000000000001, -56.900000000000006, -75.60000000000001, -66.9, -48.50000000000001, -41.2, -50.400000000000006, -67.39999999999999, -47.900000000000006, -43.50000000000001, -48.099999999999994, -68.60000000000001, -45.8, -72.1, -47.0, -66.8, -57.30000000000001, -62.90000000000001, -109.79999999999994, -76.69999999999997, -87.2, -85.3, -67.10000000000001, -52.70000000000002, -42.900000000000006, -66.30000000000001, -74.40000000000002, -44.300000000000004, -102.69999999999999, -42.2, -64.0, -76.4, -48.1, -47.6, -58.5, -56.89999999999999, -39.5, -66.0, -50.50000000000001, -80.89999999999998, -67.49999999999999, -74.09999999999998, -67.5, -72.69999999999999, -57.40000000000001, -57.50000000000001, -91.19999999999999, -74.60000000000001, -101.59999999999992, -68.1, -68.4, -41.800000000000004, -44.000000000000014, -65.89999999999999, -39.50000000000001, -64.00000000000001, -42.1, -24.200000000000003, -61.90000000000001, -53.400000000000006, -62.00000000000001, -92.5, -40.7, -51.400000000000006, -35.50000000000001, -68.70000000000002, -40.10000000000001, -45.300000000000004, -71.8, -42.100000000000016, -76.10000000000001, -46.900000000000006, -54.10000000000001, -48.10000000000001, -63.10000000000001, -47.599999999999994, -77.2, -62.60000000000001, -68.50000000000001, -80.99999999999996, -82.19999999999997, -45.300000000000004, -46.800000000000004, -77.1, -68.9, -109.19999999999996, -66.6, -49.90000000000001, -57.30000000000001, -42.800000000000004, -49.20000000000002, -54.500000000000014, -60.300000000000004, -42.800000000000004, -61.80000000000001, -73.20000000000002, -41.300000000000004, -35.20000000000001, -44.10000000000001, -49.400000000000006, -43.1, -48.7, -56.2, -115.29999999999995, -59.30000000000001, -108.49999999999994, -41.2, -112.09999999999991, -47.199999999999996, -55.50000000000001, -74.9, -71.79999999999997, -50.800000000000004, -74.40000000000002, -40.599999999999994, -56.40000000000001, -63.6, -47.800000000000004, -43.400000000000006, -60.500000000000014, -50.0, -69.39999999999999, -47.2, -38.199999999999996, -59.60000000000001, -49.50000000000001, -53.30000000000001, -46.49999999999999, -97.19999999999996, -104.89999999999993, -53.2, -62.80000000000001, -66.7, -61.80000000000001, -41.5, -53.20000000000001, -66.50000000000001, -38.9, -68.30000000000001, -34.400000000000006, -64.2, -39.10000000000001, -63.50000000000001, -72.69999999999999, -40.1, -58.00000000000001, -119.99999999999994, -59.0, -65.30000000000001, -56.099999999999994, -66.40000000000002, -84.99999999999997, -52.50000000000001, -51.80000000000001, -86.69999999999999, -50.60000000000001, -57.90000000000001, -69.30000000000001, -63.09999999999999, -59.2, -44.900000000000006, -59.19999999999998, -61.50000000000001, -63.10000000000001, -48.5, -43.4, -60.2, -47.0, -65.20000000000002, -53.400000000000006, -75.89999999999999, -35.800000000000004, -41.30000000000001, -55.10000000000001, -92.0, -68.9, -57.1, -67.00000000000001, -73.89999999999998, -77.89999999999995, -55.8, -46.599999999999994, -50.90000000000001, -56.70000000000001, -58.300000000000004, -47.10000000000001, -45.30000000000001, -53.6, -72.50000000000001, -54.10000000000001, -51.40000000000001, -40.1, -51.000000000000014, -63.8, -68.0, -136.69999999999987, -60.80000000000001, -54.900000000000006, -76.60000000000001, -40.900000000000006, -62.199999999999996, -52.800000000000004, -45.10000000000001, -114.89999999999993], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13675132039882754, "mean_inference_ms": 1.2288881612850273, "mean_action_processing_ms": 0.055074193283545035, "mean_env_wait_ms": 2.3104911890632867, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 44000, "agent_timesteps_total": 44000, "timers": {"sample_time_ms": 7539.839, "sample_throughput": 530.515, "load_time_ms": 0.05, "load_throughput": 79362421.949, "learn_time_ms": 7389.604, "learn_throughput": 541.301, "update_time_ms": 1.511}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 422.8010560394615, "policy_loss": -0.05538581610727374, "vf_loss": 422.85331722792756, "vf_explained_var": [0.03209589049220085], "kl": 0.015621201319403729, "entropy": 2.1954179320284117, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 44000, "num_agent_steps_sampled": 44000, "num_steps_trained": 44000, "num_agent_steps_trained": 44000}, "done": false, "episodes_total": 2932, "training_iteration": 11, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-13-17", "timestamp": 1632517997, "time_this_iter_s": 14.621112823486328, "time_total_s": 165.94825744628906, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 165.94825744628906, "timesteps_since_restore": 0, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 34.84761904761904, "ram_util_percent": 15.800000000000002}}
{"episode_reward_max": -29.5, "episode_reward_min": -115.29999999999994, "episode_reward_mean": -56.99365671641792, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 268, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-93.59999999999994, -29.6, -62.80000000000001, -64.19999999999999, -64.70000000000002, -51.00000000000001, -50.10000000000001, -50.900000000000006, -57.4, -58.900000000000006, -40.2, -56.90000000000001, -48.60000000000001, -49.900000000000006, -57.20000000000001, -44.800000000000004, -71.1, -63.6, -56.500000000000014, -96.1, -55.2, -52.900000000000006, -68.19999999999999, -39.5, -50.4, -37.699999999999996, -39.5, -48.60000000000001, -59.90000000000002, -69.0, -76.79999999999998, -108.39999999999992, -55.1, -45.60000000000001, -39.50000000000001, -48.2, -69.4, -44.5, -49.5, -52.400000000000006, -41.800000000000004, -46.20000000000001, -52.70000000000001, -72.50000000000001, -48.400000000000006, -66.20000000000002, -49.699999999999996, -54.10000000000001, -45.400000000000006, -53.400000000000006, -45.1, -92.89999999999998, -79.19999999999999, -43.50000000000001, -57.70000000000001, -41.800000000000004, -32.7, -40.6, -60.70000000000002, -41.7, -55.7, -55.60000000000001, -58.10000000000001, -43.199999999999996, -79.5, -49.90000000000001, -69.0, -30.700000000000006, -37.00000000000001, -42.400000000000006, -71.29999999999998, -62.39999999999999, -61.400000000000006, -48.60000000000001, -59.5, -48.5, -51.50000000000001, -36.00000000000001, -65.1, -42.900000000000006, -40.60000000000001, -50.500000000000014, -66.0, -77.39999999999999, -49.20000000000001, -56.900000000000006, -97.59999999999994, -62.3, -48.8, -58.000000000000014, -53.0, -54.30000000000001, -60.000000000000014, -62.70000000000002, -67.19999999999999, -48.70000000000001, -50.30000000000002, -71.0, -53.50000000000001, -47.2, -72.00000000000001, -67.9, -49.10000000000001, -42.1, -52.30000000000001, -62.20000000000001, -50.00000000000001, -45.10000000000001, -40.300000000000004, -70.0, -81.39999999999998, -62.29999999999999, -42.10000000000001, -38.900000000000006, -47.60000000000001, -62.00000000000001, -59.900000000000006, -59.100000000000016, -57.00000000000001, -114.49999999999997, -37.2, -48.40000000000001, -61.2, -49.199999999999996, -87.09999999999994, -56.2, -40.2, -52.199999999999996, -60.10000000000001, -29.5, -70.20000000000002, -77.00000000000001, -67.80000000000001, -50.599999999999994, -55.7, -56.40000000000001, -35.800000000000004, -52.00000000000001, -53.900000000000006, -71.5, -48.60000000000001, -60.10000000000001, -40.0, -93.70000000000002, -49.800000000000004, -77.3, -58.7, -78.5, -40.400000000000006, -93.19999999999999, -63.900000000000006, -56.300000000000004, -42.2, -59.0, -43.00000000000001, -69.2, -52.900000000000006, -57.7, -61.90000000000001, -54.90000000000002, -51.7, -50.6, -71.7, -39.900000000000006, -48.400000000000006, -43.4, -56.400000000000006, -42.400000000000006, -58.7, -47.5, -69.30000000000001, -63.10000000000001, -57.60000000000001, -40.9, -33.099999999999994, -52.80000000000001, -64.7, -57.900000000000006, -44.90000000000001, -46.20000000000001, -35.7, -70.19999999999999, -115.29999999999994, -79.60000000000001, -41.60000000000001, -68.9, -60.1, -51.40000000000001, -48.8, -78.39999999999999, -56.500000000000014, -50.00000000000001, -50.000000000000014, -88.80000000000001, -79.69999999999997, -48.300000000000004, -61.7, -69.30000000000001, -38.599999999999994, -48.800000000000004, -63.0, -64.30000000000001, -45.0, -33.1, -57.39999999999999, -45.5, -39.70000000000001, -46.40000000000001, -84.69999999999999, -47.300000000000004, -60.8, -43.0, -63.89999999999999, -63.40000000000001, -58.500000000000014, -74.7, -45.50000000000001, -80.50000000000001, -73.7, -51.30000000000001, -42.00000000000001, -55.30000000000001, -66.09999999999998, -69.69999999999997, -53.300000000000004, -47.00000000000001, -48.800000000000004, -34.5, -59.599999999999994, -90.69999999999999, -61.9, -48.70000000000001, -60.80000000000001, -44.6, -65.60000000000001, -36.1, -67.9, -45.800000000000004, -63.199999999999996, -60.1, -55.800000000000004, -37.8, -70.49999999999999, -81.7, -66.2, -63.7, -37.10000000000001, -61.50000000000001, -91.49999999999999, -45.40000000000001, -59.60000000000001, -67.10000000000001, -82.10000000000001, -78.7, -56.50000000000001, -64.80000000000001, -70.69999999999997, -50.000000000000014, -55.5, -34.0, -58.3, -36.800000000000004, -59.599999999999994, -50.10000000000001, -40.5, -65.80000000000001, -54.00000000000001, -55.20000000000001], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13705053099403433, "mean_inference_ms": 1.2326061286050518, "mean_action_processing_ms": 0.05528933902287661, "mean_env_wait_ms": 2.3035249443462678, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 48000, "agent_timesteps_total": 48000, "timers": {"sample_time_ms": 7521.898, "sample_throughput": 531.781, "load_time_ms": 0.05, "load_throughput": 79626084.48, "learn_time_ms": 7459.05, "learn_throughput": 536.261, "update_time_ms": 1.508}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 348.1144051828692, "policy_loss": -0.04084935117042273, "vf_loss": 348.1523983534946, "vf_explained_var": [0.018662700429558754], "kl": 0.01427559513494022, "entropy": 2.1128257587391843, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 48000, "num_agent_steps_sampled": 48000, "num_steps_trained": 48000, "num_agent_steps_trained": 48000}, "done": false, "episodes_total": 3200, "training_iteration": 12, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-13-34", "timestamp": 1632518014, "time_this_iter_s": 16.364099979400635, "time_total_s": 182.3123574256897, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 182.3123574256897, "timesteps_since_restore": 0, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 36.68260869565217, "ram_util_percent": 15.85652173913044}}
{"episode_reward_max": -23.3, "episode_reward_min": -108.19999999999999, "episode_reward_mean": -55.346992481203, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-62.29999999999999, -49.2, -47.60000000000001, -65.80000000000001, -46.2, -59.20000000000001, -58.099999999999994, -51.900000000000006, -50.7, -67.80000000000001, -63.300000000000004, -50.2, -54.2, -51.49999999999999, -52.000000000000014, -36.5, -71.4, -54.00000000000001, -64.4, -72.0, -51.300000000000004, -82.89999999999998, -41.20000000000001, -52.900000000000006, -47.800000000000004, -23.3, -70.70000000000002, -66.80000000000001, -64.2, -53.600000000000016, -37.9, -53.0, -40.800000000000004, -53.5, -58.10000000000001, -69.4, -35.9, -58.90000000000001, -52.800000000000004, -33.5, -41.300000000000004, -63.70000000000002, -42.5, -68.2, -53.0, -50.900000000000006, -30.7, -55.900000000000006, -41.30000000000001, -71.80000000000001, -73.9, -39.9, -52.900000000000006, -49.400000000000006, -37.30000000000001, -60.900000000000006, -52.00000000000001, -50.00000000000001, -78.80000000000001, -45.9, -51.50000000000001, -50.900000000000006, -33.2, -80.70000000000002, -65.30000000000001, -42.50000000000001, -64.0, -46.7, -41.800000000000004, -43.00000000000001, -28.199999999999996, -39.00000000000001, -49.800000000000004, -37.2, -80.00000000000001, -61.50000000000001, -42.3, -51.800000000000004, -47.90000000000001, -37.900000000000006, -77.80000000000001, -45.7, -64.4, -85.19999999999999, -61.70000000000001, -48.00000000000001, -44.0, -62.400000000000006, -56.10000000000001, -34.1, -67.60000000000001, -68.00000000000001, -35.900000000000006, -53.70000000000001, -37.400000000000006, -45.10000000000001, -24.500000000000004, -61.900000000000006, -65.1, -48.7, -55.10000000000001, -39.4, -56.1, -75.9, -86.6, -58.50000000000002, -46.3, -55.800000000000004, -69.4, -54.00000000000001, -56.900000000000006, -59.800000000000004, -49.7, -54.10000000000001, -52.100000000000016, -36.900000000000006, -60.900000000000006, -53.90000000000001, -47.20000000000001, -94.89999999999995, -55.1, -65.09999999999998, -68.6, -53.0, -60.2, -50.300000000000004, -39.400000000000006, -56.5, -89.59999999999998, -55.500000000000014, -48.900000000000006, -40.7, -37.0, -45.50000000000001, -33.6, -59.0, -44.6, -43.400000000000006, -43.50000000000001, -57.900000000000006, -57.6, -54.900000000000006, -56.2, -56.800000000000004, -47.60000000000001, -45.10000000000001, -83.3, -43.20000000000001, -65.4, -63.00000000000001, -41.8, -59.10000000000001, -47.50000000000001, -40.00000000000001, -63.6, -43.60000000000001, -57.800000000000004, -46.5, -67.9, -68.8, -58.50000000000001, -59.10000000000001, -41.800000000000004, -98.39999999999995, -56.80000000000001, -65.7, -74.39999999999999, -71.50000000000001, -55.60000000000001, -44.20000000000001, -52.60000000000001, -86.0, -55.39999999999999, -50.1, -68.8, -37.6, -44.60000000000001, -54.699999999999996, -50.400000000000006, -73.10000000000001, -58.20000000000001, -52.49999999999999, -53.80000000000001, -85.09999999999998, -61.400000000000006, -78.4, -50.60000000000002, -42.7, -65.10000000000002, -51.99999999999999, -56.800000000000004, -85.79999999999997, -51.70000000000002, -45.900000000000006, -60.50000000000001, -53.900000000000006, -74.1, -45.50000000000001, -51.5, -58.80000000000001, -42.199999999999996, -67.70000000000002, -66.50000000000001, -30.2, -38.300000000000004, -69.40000000000002, -49.10000000000001, -70.2, -54.1, -72.0, -36.800000000000004, -48.8, -57.60000000000001, -95.3, -60.400000000000006, -64.10000000000002, -59.60000000000001, -37.60000000000001, -40.400000000000006, -69.1, -61.99999999999999, -71.10000000000001, -56.400000000000006, -38.7, -48.300000000000004, -40.7, -61.00000000000001, -51.400000000000006, -53.300000000000004, -54.80000000000001, -42.7, -69.10000000000001, -58.6, -52.300000000000004, -42.400000000000006, -29.1, -49.300000000000004, -39.10000000000001, -69.2, -52.40000000000001, -72.00000000000001, -53.000000000000014, -72.19999999999999, -76.59999999999998, -45.4, -37.8, -61.60000000000001, -66.60000000000002, -72.69999999999997, -49.90000000000001, -38.900000000000006, -61.30000000000001, -55.5, -48.30000000000001, -58.90000000000001, -70.50000000000001, -39.50000000000001, -108.19999999999999, -56.8, -38.0, -42.800000000000004, -94.4, -42.30000000000001, -67.0, -53.60000000000001, -43.400000000000006], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13725541471577637, "mean_inference_ms": 1.2348084526609255, "mean_action_processing_ms": 0.05538454147848844, "mean_env_wait_ms": 2.2960551302871597, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 52000, "agent_timesteps_total": 52000, "timers": {"sample_time_ms": 7513.029, "sample_throughput": 532.408, "load_time_ms": 0.05, "load_throughput": 79550573.732, "learn_time_ms": 7636.673, "learn_throughput": 523.788, "update_time_ms": 1.591}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 319.6538589149393, "policy_loss": -0.045667050123935744, "vf_loss": 319.69615422730806, "vf_explained_var": [0.04115208610892296], "kl": 0.01685155329359531, "entropy": 2.0541421941531604, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 52000, "num_agent_steps_sampled": 52000, "num_steps_trained": 52000, "num_agent_steps_trained": 52000}, "done": false, "episodes_total": 3466, "training_iteration": 13, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-13-50", "timestamp": 1632518030, "time_this_iter_s": 16.193819761276245, "time_total_s": 198.50617718696594, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 198.50617718696594, "timesteps_since_restore": 0, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 37.770833333333336, "ram_util_percent": 15.845833333333333}}
{"episode_reward_max": -26.200000000000003, "episode_reward_min": -111.29999999999995, "episode_reward_mean": -55.41842105263159, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-41.300000000000004, -54.900000000000006, -87.60000000000002, -44.6, -63.400000000000006, -69.1, -48.0, -74.79999999999998, -87.29999999999997, -54.8, -49.400000000000006, -60.19999999999999, -39.7, -56.89999999999999, -43.80000000000001, -111.29999999999995, -51.5, -49.80000000000001, -56.80000000000001, -78.2, -76.5, -59.70000000000001, -79.5, -55.70000000000001, -39.0, -61.20000000000001, -75.99999999999999, -66.79999999999998, -60.30000000000001, -85.60000000000001, -53.300000000000004, -59.20000000000001, -60.29999999999999, -60.900000000000006, -60.500000000000014, -57.000000000000014, -57.900000000000006, -40.50000000000001, -47.10000000000001, -64.7, -53.10000000000001, -35.5, -58.1, -50.300000000000004, -57.90000000000002, -56.30000000000001, -54.60000000000001, -40.7, -56.80000000000001, -61.1, -68.1, -48.70000000000002, -74.4, -34.60000000000001, -84.89999999999996, -47.6, -55.10000000000001, -36.60000000000001, -60.300000000000004, -38.2, -50.5, -46.300000000000004, -58.1, -54.400000000000006, -49.400000000000006, -57.800000000000004, -30.2, -58.000000000000014, -36.1, -55.300000000000004, -54.1, -63.79999999999998, -42.10000000000001, -47.7, -52.8, -69.9, -62.100000000000016, -62.000000000000014, -63.10000000000001, -53.69999999999999, -101.79999999999995, -73.0, -38.900000000000006, -61.900000000000006, -32.1, -50.49999999999999, -39.3, -75.0, -43.00000000000001, -42.6, -49.400000000000006, -61.500000000000014, -46.30000000000001, -45.90000000000001, -60.200000000000024, -55.000000000000014, -44.1, -52.4, -42.6, -53.9, -56.60000000000001, -53.50000000000002, -32.800000000000004, -56.2, -47.00000000000001, -53.900000000000006, -51.60000000000001, -51.000000000000014, -36.4, -60.500000000000014, -43.7, -67.4, -75.10000000000001, -54.70000000000001, -57.00000000000001, -55.7, -56.7, -50.5, -54.7, -81.40000000000002, -56.10000000000001, -64.40000000000002, -48.10000000000001, -55.8, -79.20000000000002, -67.89999999999998, -79.5, -82.4, -38.50000000000001, -62.9, -41.6, -41.300000000000004, -43.800000000000004, -50.400000000000006, -42.300000000000004, -71.79999999999998, -58.600000000000016, -59.3, -61.40000000000001, -62.000000000000014, -63.00000000000001, -26.200000000000003, -50.300000000000004, -38.7, -70.79999999999998, -52.10000000000001, -36.20000000000001, -56.8, -45.500000000000014, -50.900000000000006, -43.10000000000001, -51.70000000000001, -46.10000000000001, -46.10000000000001, -36.70000000000001, -56.10000000000001, -48.0, -64.9, -61.70000000000001, -55.900000000000006, -57.900000000000006, -74.8, -72.0, -62.80000000000001, -56.70000000000001, -66.80000000000001, -59.699999999999996, -64.39999999999999, -49.400000000000006, -61.900000000000006, -69.1, -40.800000000000004, -34.1, -65.9, -59.400000000000006, -33.2, -60.20000000000001, -52.400000000000006, -72.89999999999999, -53.3, -44.00000000000001, -63.4, -50.9, -58.1, -67.2, -49.2, -56.10000000000001, -47.70000000000001, -43.900000000000006, -45.800000000000004, -50.10000000000001, -39.400000000000006, -53.2, -43.0, -45.40000000000001, -46.400000000000006, -54.20000000000001, -58.499999999999986, -69.5, -65.10000000000001, -62.000000000000014, -72.19999999999997, -58.50000000000001, -73.89999999999999, -46.0, -40.6, -57.900000000000006, -51.7, -65.8, -58.7, -59.80000000000001, -37.400000000000006, -33.2, -31.1, -48.2, -45.7, -70.10000000000001, -54.400000000000006, -29.3, -37.5, -49.800000000000004, -82.60000000000001, -35.9, -47.9, -49.60000000000001, -58.20000000000002, -32.400000000000006, -51.5, -42.40000000000001, -58.500000000000014, -78.9, -44.7, -50.0, -59.900000000000006, -27.900000000000002, -67.49999999999997, -65.50000000000001, -51.50000000000001, -57.800000000000004, -50.400000000000006, -46.8, -58.00000000000002, -52.0, -51.90000000000001, -56.80000000000001, -48.10000000000001, -45.400000000000006, -48.80000000000001, -63.09999999999998, -63.8, -59.2, -56.0, -62.30000000000001, -57.3, -87.39999999999996, -48.00000000000001, -51.0, -58.9, -75.3, -42.3, -53.4, -72.0, -53.1, -47.6, -92.99999999999997, -54.8], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13727123603399835, "mean_inference_ms": 1.2370985808753445, "mean_action_processing_ms": 0.055504715411579, "mean_env_wait_ms": 2.2921663561674834, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 56000, "agent_timesteps_total": 56000, "timers": {"sample_time_ms": 7524.167, "sample_throughput": 531.62, "load_time_ms": 0.05, "load_throughput": 79550573.732, "learn_time_ms": 7702.698, "learn_throughput": 519.299, "update_time_ms": 1.588}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 309.0998532367009, "policy_loss": -0.04930482640692223, "vf_loss": 309.1461124379148, "vf_explained_var": [0.033098991960287094], "kl": 0.01522835127147244, "entropy": 1.9823429442221119, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 56000, "num_agent_steps_sampled": 56000, "num_steps_trained": 56000, "num_agent_steps_trained": 56000}, "done": false, "episodes_total": 3732, "training_iteration": 14, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-14-05", "timestamp": 1632518045, "time_this_iter_s": 15.215020179748535, "time_total_s": 213.72119736671448, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 213.72119736671448, "timesteps_since_restore": 0, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 34.15238095238095, "ram_util_percent": 15.800000000000002}}
{"episode_reward_max": -24.5, "episode_reward_min": -140.89999999999986, "episode_reward_mean": -53.46940298507463, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 268, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-47.00000000000001, -44.900000000000006, -140.89999999999986, -40.00000000000001, -58.30000000000001, -45.400000000000006, -51.900000000000006, -43.9, -38.50000000000001, -75.70000000000002, -46.9, -75.70000000000002, -56.80000000000001, -45.400000000000006, -68.89999999999999, -50.500000000000014, -50.40000000000002, -84.79999999999997, -54.2, -63.000000000000014, -86.99999999999997, -40.7, -45.7, -43.60000000000001, -40.2, -59.40000000000001, -53.900000000000006, -48.90000000000001, -65.0, -86.39999999999998, -31.100000000000005, -35.300000000000004, -64.7, -60.600000000000016, -61.00000000000001, -70.69999999999999, -44.500000000000014, -52.4, -51.6, -60.49999999999999, -33.2, -71.3, -85.09999999999998, -55.7, -73.5, -24.5, -35.7, -41.300000000000004, -64.60000000000001, -72.5, -45.900000000000006, -46.3, -82.6, -48.800000000000004, -48.800000000000004, -45.8, -32.50000000000001, -37.6, -36.7, -43.60000000000001, -58.100000000000016, -62.7, -38.90000000000001, -60.60000000000001, -43.10000000000001, -74.89999999999999, -47.300000000000004, -34.1, -45.800000000000004, -90.79999999999998, -42.7, -49.90000000000001, -34.800000000000004, -58.600000000000016, -62.40000000000001, -71.69999999999999, -44.1, -53.80000000000001, -58.0, -60.1, -40.1, -48.100000000000016, -41.90000000000001, -50.800000000000004, -42.60000000000001, -51.00000000000001, -54.199999999999996, -43.6, -58.50000000000001, -32.900000000000006, -67.9, -52.5, -43.70000000000001, -51.80000000000001, -46.00000000000001, -69.9, -46.6, -44.7, -83.10000000000002, -50.0, -48.800000000000004, -67.89999999999999, -53.90000000000001, -55.8, -40.7, -64.2, -90.29999999999997, -68.2, -42.800000000000004, -49.300000000000004, -54.5, -59.00000000000001, -40.60000000000001, -45.50000000000001, -56.900000000000006, -36.4, -39.1, -54.600000000000016, -43.900000000000006, -39.10000000000001, -41.7, -88.5, -44.1, -43.6, -76.6, -48.9, -76.89999999999998, -37.800000000000004, -42.800000000000004, -70.39999999999999, -45.7, -44.10000000000001, -42.6, -64.80000000000001, -61.70000000000001, -64.0, -52.30000000000001, -110.60000000000001, -47.50000000000001, -47.900000000000006, -40.7, -51.7, -63.90000000000002, -40.099999999999994, -56.800000000000004, -88.99999999999994, -72.69999999999999, -48.99999999999999, -42.00000000000001, -72.10000000000001, -66.8, -69.19999999999999, -87.89999999999999, -40.0, -42.00000000000001, -55.1, -53.30000000000001, -63.10000000000001, -51.50000000000001, -49.000000000000014, -32.1, -68.39999999999999, -81.30000000000001, -60.8, -57.4, -53.900000000000006, -47.69999999999999, -43.400000000000006, -45.40000000000001, -71.89999999999998, -51.90000000000001, -47.400000000000006, -51.800000000000004, -72.79999999999995, -51.6, -47.199999999999996, -40.10000000000001, -73.60000000000001, -41.7, -55.20000000000001, -58.8, -34.900000000000006, -80.29999999999998, -35.800000000000004, -79.1, -35.1, -60.59999999999999, -51.10000000000001, -33.7, -30.0, -42.0, -47.2, -60.900000000000006, -46.60000000000001, -55.2, -60.80000000000001, -60.80000000000001, -35.6, -29.1, -51.50000000000001, -60.10000000000002, -70.99999999999999, -34.9, -50.80000000000001, -42.599999999999994, -52.70000000000002, -68.2, -40.30000000000001, -57.7, -90.99999999999997, -51.099999999999994, -56.300000000000004, -68.0, -55.7, -56.5, -49.900000000000006, -47.500000000000014, -70.00000000000001, -43.800000000000004, -52.7, -66.99999999999999, -45.300000000000004, -35.800000000000004, -40.4, -46.800000000000004, -43.8, -65.09999999999998, -42.9, -34.2, -60.49999999999999, -34.3, -46.400000000000006, -51.6, -32.4, -58.699999999999996, -64.2, -41.8, -45.800000000000004, -43.1, -57.400000000000006, -40.60000000000001, -44.30000000000001, -61.20000000000001, -52.60000000000001, -43.1, -84.29999999999998, -45.8, -38.800000000000004, -39.60000000000001, -35.5, -30.800000000000004, -39.3, -42.3, -69.10000000000001, -37.0, -56.099999999999994, -42.00000000000001, -70.10000000000001, -53.300000000000004, -40.20000000000001, -55.4, -42.6, -53.20000000000002, -52.400000000000006, -48.800000000000004, -52.699999999999996, -59.20000000000001, -52.000000000000014], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13718382604384177, "mean_inference_ms": 1.2364906730828602, "mean_action_processing_ms": 0.055501593823774814, "mean_env_wait_ms": 2.285160492596668, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 60000, "agent_timesteps_total": 60000, "timers": {"sample_time_ms": 7513.092, "sample_throughput": 532.404, "load_time_ms": 0.048, "load_throughput": 82605691.777, "learn_time_ms": 7728.317, "learn_throughput": 517.577, "update_time_ms": 1.576}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 316.4154430430423, "policy_loss": -0.045279533751509206, "vf_loss": 316.4576629966818, "vf_explained_var": [0.05665062367916107], "kl": 0.015302636912822755, "entropy": 1.8916248356142351, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 60000, "num_agent_steps_sampled": 60000, "num_steps_trained": 60000, "num_agent_steps_trained": 60000}, "done": false, "episodes_total": 4000, "training_iteration": 15, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-14-20", "timestamp": 1632518060, "time_this_iter_s": 14.680485963821411, "time_total_s": 228.4016833305359, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 228.4016833305359, "timesteps_since_restore": 0, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 34.09523809523809, "ram_util_percent": 15.800000000000002}}
{"episode_reward_max": -25.1, "episode_reward_min": -116.49999999999997, "episode_reward_mean": -51.472556390977445, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-59.000000000000014, -52.400000000000006, -36.3, -38.800000000000004, -25.1, -66.70000000000002, -31.600000000000005, -64.30000000000001, -44.8, -55.30000000000002, -39.7, -38.7, -63.50000000000001, -42.0, -44.8, -50.5, -49.900000000000006, -89.49999999999994, -38.0, -45.60000000000001, -46.300000000000004, -57.80000000000001, -78.59999999999997, -41.400000000000006, -39.00000000000001, -36.300000000000004, -40.5, -60.80000000000001, -43.400000000000006, -61.6, -55.60000000000001, -53.7, -45.400000000000006, -37.1, -47.7, -64.9, -48.4, -30.700000000000003, -43.6, -37.2, -59.90000000000001, -46.5, -51.60000000000001, -46.00000000000001, -51.60000000000001, -60.19999999999999, -43.8, -62.100000000000016, -68.0, -66.60000000000001, -41.0, -53.900000000000006, -48.2, -52.50000000000001, -69.19999999999999, -39.3, -32.00000000000001, -58.80000000000001, -43.199999999999996, -48.10000000000001, -68.8, -31.200000000000003, -60.3, -41.0, -61.7, -64.0, -40.2, -70.2, -55.4, -60.20000000000001, -36.50000000000001, -63.60000000000001, -75.9, -52.7, -56.80000000000001, -42.90000000000001, -46.3, -53.300000000000004, -95.19999999999996, -65.3, -53.40000000000001, -54.699999999999996, -58.599999999999994, -35.0, -62.9, -60.10000000000001, -41.30000000000001, -34.60000000000001, -53.79999999999999, -68.9, -47.50000000000001, -37.900000000000006, -39.10000000000001, -63.800000000000004, -77.2, -56.70000000000001, -35.300000000000004, -61.10000000000001, -52.300000000000004, -34.400000000000006, -58.400000000000006, -42.20000000000001, -64.10000000000001, -49.60000000000001, -52.599999999999994, -57.10000000000001, -46.2, -45.60000000000001, -36.699999999999996, -27.700000000000003, -46.1, -45.90000000000001, -34.800000000000004, -44.5, -37.6, -43.400000000000006, -40.400000000000006, -36.7, -45.6, -46.0, -74.7, -77.10000000000001, -32.1, -55.60000000000001, -55.10000000000001, -65.20000000000002, -77.39999999999999, -79.1, -38.40000000000001, -36.800000000000004, -73.4, -62.500000000000014, -51.900000000000006, -51.6, -47.300000000000004, -25.200000000000003, -71.29999999999995, -52.10000000000001, -35.6, -69.2, -47.5, -54.00000000000001, -59.70000000000001, -52.60000000000001, -66.5, -58.699999999999996, -50.400000000000006, -37.400000000000006, -31.9, -33.39999999999999, -85.2, -49.50000000000001, -33.5, -38.70000000000001, -49.6, -53.10000000000001, -48.60000000000001, -37.9, -52.300000000000004, -39.900000000000006, -27.000000000000004, -34.2, -75.39999999999999, -67.49999999999999, -49.30000000000001, -59.99999999999999, -44.10000000000001, -42.20000000000001, -57.900000000000006, -52.6, -71.30000000000001, -63.70000000000002, -81.8, -70.60000000000001, -42.5, -116.49999999999997, -56.5, -36.300000000000004, -73.69999999999999, -76.29999999999998, -33.2, -64.6, -41.2, -42.0, -40.1, -59.80000000000001, -51.900000000000006, -44.800000000000004, -42.300000000000004, -27.1, -65.4, -46.10000000000001, -42.7, -55.70000000000001, -38.90000000000001, -65.4, -44.60000000000001, -61.000000000000014, -43.800000000000004, -46.50000000000001, -51.5, -42.0, -43.7, -39.1, -56.7, -44.10000000000001, -51.30000000000001, -45.7, -51.99999999999999, -55.80000000000001, -54.900000000000006, -43.80000000000001, -52.5, -37.0, -48.800000000000004, -62.80000000000002, -70.4, -54.000000000000014, -57.500000000000014, -58.39999999999999, -59.7, -36.5, -33.9, -61.900000000000006, -34.099999999999994, -43.300000000000004, -32.20000000000001, -58.50000000000001, -61.80000000000001, -52.199999999999996, -50.600000000000016, -55.6, -32.900000000000006, -38.400000000000006, -42.7, -42.5, -29.000000000000004, -47.0, -40.7, -55.40000000000001, -55.800000000000004, -43.300000000000004, -41.900000000000006, -66.90000000000002, -50.300000000000004, -53.5, -40.10000000000001, -68.10000000000002, -57.10000000000001, -49.50000000000001, -52.800000000000004, -54.80000000000001, -49.199999999999996, -67.49999999999999, -79.39999999999999, -48.9, -75.7, -54.39999999999998, -55.19999999999999, -54.600000000000016, -38.40000000000001, -47.900000000000006, -50.199999999999996, -56.0, -78.00000000000001, -42.50000000000001], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13725123797791858, "mean_inference_ms": 1.2380596377067965, "mean_action_processing_ms": 0.05555851735687565, "mean_env_wait_ms": 2.2806449292738034, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 64000, "agent_timesteps_total": 64000, "timers": {"sample_time_ms": 7520.73, "sample_throughput": 531.863, "load_time_ms": 0.049, "load_throughput": 82443321.867, "learn_time_ms": 7706.332, "learn_throughput": 519.054, "update_time_ms": 1.598}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 276.9497514786259, "policy_loss": -0.04081201826632824, "vf_loss": 276.98772797943445, "vf_explained_var": [0.05563453584909439], "kl": 0.014180830546022958, "entropy": 1.8264192276103521, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 64000, "num_agent_steps_sampled": 64000, "num_steps_trained": 64000, "num_agent_steps_trained": 64000}, "done": false, "episodes_total": 4266, "training_iteration": 16, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-14-35", "timestamp": 1632518075, "time_this_iter_s": 14.80068325996399, "time_total_s": 243.20236659049988, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 243.20236659049988, "timesteps_since_restore": 0, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 34.85454545454545, "ram_util_percent": 15.800000000000004}}
{"episode_reward_max": -26.6, "episode_reward_min": -96.89999999999995, "episode_reward_mean": -49.75488721804512, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-42.20000000000001, -56.6, -71.2, -37.5, -39.50000000000001, -37.1, -49.400000000000006, -46.300000000000004, -44.7, -36.0, -38.6, -55.1, -47.30000000000001, -41.70000000000001, -41.199999999999996, -34.20000000000001, -54.800000000000004, -84.59999999999995, -27.900000000000006, -31.600000000000005, -60.7, -52.80000000000001, -57.00000000000001, -46.900000000000006, -66.50000000000001, -45.9, -47.4, -45.5, -42.2, -40.6, -68.10000000000002, -56.300000000000004, -44.800000000000004, -47.80000000000001, -53.30000000000001, -56.10000000000001, -35.4, -49.900000000000006, -60.50000000000001, -50.0, -43.8, -53.300000000000004, -44.2, -74.20000000000002, -36.900000000000006, -42.300000000000004, -75.9, -64.5, -58.4, -51.2, -64.1, -44.3, -66.4, -65.19999999999999, -39.50000000000001, -54.1, -59.10000000000001, -47.300000000000004, -52.70000000000002, -36.699999999999996, -48.0, -55.000000000000014, -42.300000000000004, -46.00000000000001, -67.40000000000002, -59.1, -49.500000000000014, -42.80000000000001, -53.70000000000001, -84.09999999999998, -48.300000000000004, -96.89999999999995, -54.000000000000014, -63.39999999999999, -73.30000000000001, -45.900000000000006, -38.6, -61.9, -73.1, -50.2, -60.900000000000006, -50.0, -38.20000000000001, -51.00000000000001, -36.5, -47.900000000000006, -82.99999999999997, -36.0, -60.0, -39.900000000000006, -44.800000000000004, -39.400000000000006, -54.00000000000001, -40.900000000000006, -29.8, -59.10000000000001, -53.3, -34.5, -32.1, -30.5, -54.90000000000001, -46.900000000000006, -55.90000000000001, -43.400000000000006, -40.800000000000004, -46.800000000000004, -46.50000000000001, -43.60000000000001, -43.300000000000004, -56.8, -44.10000000000001, -70.1, -49.800000000000004, -35.3, -44.7, -73.19999999999997, -62.3, -38.900000000000006, -47.30000000000001, -62.10000000000001, -58.9, -35.7, -61.6, -45.800000000000004, -58.00000000000001, -38.2, -51.9, -44.7, -36.2, -53.30000000000001, -84.0, -63.000000000000014, -58.800000000000004, -41.29999999999999, -44.000000000000014, -33.60000000000001, -45.2, -52.300000000000004, -56.40000000000001, -53.0, -59.80000000000001, -51.100000000000016, -59.7, -50.30000000000001, -46.6, -45.20000000000001, -51.00000000000001, -64.5, -49.10000000000001, -63.00000000000001, -58.40000000000001, -41.7, -31.1, -63.29999999999998, -62.4, -32.99999999999999, -59.90000000000002, -87.4, -76.40000000000002, -58.6, -41.7, -40.50000000000001, -48.300000000000004, -48.90000000000001, -52.60000000000001, -69.50000000000001, -28.2, -44.1, -42.800000000000004, -47.300000000000004, -60.49999999999999, -46.699999999999996, -29.599999999999998, -40.599999999999994, -51.80000000000001, -59.00000000000001, -56.90000000000001, -34.7, -47.60000000000001, -50.6, -42.9, -58.7, -47.9, -55.50000000000001, -49.9, -45.099999999999994, -60.50000000000002, -42.1, -31.900000000000006, -65.59999999999998, -41.60000000000001, -40.300000000000004, -38.2, -45.0, -58.6, -52.0, -53.6, -39.5, -31.9, -45.3, -49.20000000000002, -30.000000000000007, -49.70000000000001, -41.70000000000002, -42.4, -77.30000000000001, -52.90000000000001, -44.7, -46.900000000000006, -34.5, -78.30000000000001, -39.800000000000004, -69.60000000000001, -87.7, -48.60000000000001, -58.900000000000006, -38.50000000000001, -41.4, -36.400000000000006, -55.0, -63.900000000000006, -40.800000000000004, -48.40000000000001, -52.10000000000001, -40.400000000000006, -57.2, -47.800000000000004, -39.4, -61.0, -47.2, -49.00000000000001, -46.2, -33.300000000000004, -36.2, -37.2, -31.5, -35.0, -43.400000000000006, -50.20000000000001, -39.50000000000001, -45.00000000000001, -71.59999999999998, -38.00000000000001, -47.9, -51.4, -56.9, -37.800000000000004, -40.90000000000001, -47.2, -47.7, -34.7, -39.400000000000006, -38.0, -33.6, -43.70000000000001, -51.50000000000001, -65.70000000000002, -61.599999999999994, -57.70000000000001, -26.6, -52.300000000000004, -52.5, -40.300000000000004, -42.2, -39.300000000000004, -30.400000000000002], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13723504469326742, "mean_inference_ms": 1.2385314403044883, "mean_action_processing_ms": 0.055586466743386444, "mean_env_wait_ms": 2.2750232350191317, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 68000, "agent_timesteps_total": 68000, "timers": {"sample_time_ms": 7504.904, "sample_throughput": 532.985, "load_time_ms": 0.048, "load_throughput": 82524426.955, "learn_time_ms": 7738.828, "learn_throughput": 516.874, "update_time_ms": 1.604}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 255.2143063781082, "policy_loss": -0.037044275144455574, "vf_loss": 255.24883969214656, "vf_explained_var": [0.03831380233168602], "kl": 0.012559340754625302, "entropy": 1.773182378533066, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 68000, "num_agent_steps_sampled": 68000, "num_steps_trained": 68000, "num_agent_steps_trained": 68000}, "done": false, "episodes_total": 4532, "training_iteration": 17, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-14-50", "timestamp": 1632518090, "time_this_iter_s": 14.909167051315308, "time_total_s": 258.1115336418152, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 258.1115336418152, "timesteps_since_restore": 0, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 34.4, "ram_util_percent": 15.800000000000002}}
{"episode_reward_max": -22.4, "episode_reward_min": -81.9, "episode_reward_mean": -49.355970149253736, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 268, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-37.1, -45.2, -40.3, -39.7, -50.5, -56.50000000000001, -35.2, -50.7, -42.6, -42.3, -57.70000000000002, -39.7, -68.90000000000002, -37.50000000000001, -72.10000000000001, -50.4, -32.00000000000001, -57.10000000000001, -40.30000000000001, -44.5, -59.3, -38.2, -77.89999999999996, -75.4, -45.2, -36.00000000000001, -53.6, -59.6, -45.400000000000006, -53.60000000000001, -52.2, -56.30000000000001, -47.400000000000006, -45.6, -54.70000000000002, -45.100000000000016, -46.50000000000001, -41.0, -44.1, -53.2, -67.9, -47.6, -38.60000000000001, -38.6, -47.2, -41.1, -51.400000000000006, -74.39999999999999, -48.900000000000006, -33.5, -68.8, -70.69999999999997, -34.7, -36.5, -61.70000000000001, -34.2, -39.5, -81.9, -43.90000000000001, -52.70000000000001, -66.69999999999999, -60.500000000000014, -33.400000000000006, -34.9, -45.2, -47.7, -63.4, -58.7, -41.30000000000001, -31.6, -56.2, -63.80000000000001, -38.900000000000006, -67.2, -40.900000000000006, -59.300000000000004, -50.00000000000001, -35.00000000000001, -48.2, -55.60000000000001, -42.60000000000001, -35.0, -37.400000000000006, -49.0, -72.9, -26.9, -42.50000000000001, -51.30000000000001, -42.8, -39.300000000000004, -46.3, -65.4, -47.300000000000004, -67.0, -43.900000000000006, -49.10000000000001, -32.50000000000001, -48.900000000000006, -59.80000000000001, -58.39999999999999, -36.00000000000001, -46.7, -59.5, -43.0, -67.7, -57.400000000000006, -22.4, -46.3, -26.5, -37.900000000000006, -69.1, -34.900000000000006, -52.90000000000001, -52.6, -41.1, -63.70000000000001, -49.60000000000001, -39.3, -43.800000000000004, -58.4, -51.900000000000006, -52.300000000000004, -62.099999999999994, -41.0, -47.6, -57.0, -57.09999999999998, -44.6, -43.6, -49.0, -64.6, -48.0, -26.6, -38.80000000000001, -42.00000000000001, -39.3, -67.4, -50.60000000000001, -41.4, -48.70000000000001, -40.2, -39.699999999999996, -47.2, -47.00000000000001, -25.9, -38.300000000000004, -59.50000000000001, -46.400000000000006, -45.00000000000001, -46.60000000000001, -37.2, -79.7, -49.10000000000001, -40.7, -56.300000000000004, -53.10000000000001, -63.000000000000014, -55.7, -49.7, -36.8, -36.8, -40.60000000000001, -49.699999999999996, -38.6, -28.899999999999995, -52.400000000000006, -39.7, -50.70000000000001, -36.90000000000001, -30.3, -46.9, -37.0, -50.70000000000001, -72.3, -73.4, -53.90000000000002, -50.30000000000001, -50.400000000000006, -41.400000000000006, -40.099999999999994, -36.400000000000006, -57.800000000000004, -53.6, -45.400000000000006, -53.7, -55.300000000000004, -46.300000000000004, -41.80000000000001, -65.4, -65.19999999999999, -58.60000000000001, -52.2, -41.80000000000001, -43.7, -56.900000000000006, -74.09999999999998, -62.30000000000001, -36.400000000000006, -29.0, -59.90000000000002, -49.30000000000001, -58.70000000000001, -39.2, -30.5, -37.40000000000001, -40.50000000000001, -67.0, -41.6, -48.2, -70.80000000000001, -68.10000000000002, -62.70000000000002, -57.800000000000004, -57.50000000000001, -49.000000000000014, -46.800000000000004, -42.5, -54.60000000000001, -43.70000000000001, -38.0, -25.8, -42.8, -46.70000000000001, -57.400000000000006, -57.10000000000001, -52.800000000000004, -56.00000000000001, -45.300000000000004, -62.80000000000002, -52.9, -56.400000000000006, -48.30000000000001, -40.199999999999996, -35.1, -53.20000000000001, -49.00000000000001, -77.3, -47.0, -45.50000000000001, -35.5, -44.2, -42.8, -56.70000000000001, -60.80000000000001, -51.70000000000001, -59.2, -54.90000000000001, -35.7, -46.900000000000006, -77.90000000000002, -51.70000000000001, -51.2, -70.89999999999998, -50.30000000000001, -69.89999999999999, -65.5, -41.60000000000001, -59.8, -32.7, -36.9, -32.2, -35.10000000000001, -57.20000000000002, -42.00000000000001, -54.800000000000004, -52.2, -74.19999999999997, -49.90000000000002], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1375072217842582, "mean_inference_ms": 1.2419028519385427, "mean_action_processing_ms": 0.055710738448479985, "mean_env_wait_ms": 2.2749706015434934, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 72000, "agent_timesteps_total": 72000, "timers": {"sample_time_ms": 7484.049, "sample_throughput": 534.47, "load_time_ms": 0.047, "load_throughput": 84605224.407, "learn_time_ms": 7804.932, "learn_throughput": 512.496, "update_time_ms": 1.607}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 239.47663209976687, "policy_loss": -0.04227403088082229, "vf_loss": 239.5156489874727, "vf_explained_var": [0.057011764496564865], "kl": 0.016280699853611177, "entropy": 1.6803610246668579, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 72000, "num_agent_steps_sampled": 72000, "num_steps_trained": 72000, "num_agent_steps_trained": 72000}, "done": false, "episodes_total": 4800, "training_iteration": 18, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-15-06", "timestamp": 1632518106, "time_this_iter_s": 15.630116701126099, "time_total_s": 273.7416503429413, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 273.7416503429413, "timesteps_since_restore": 0, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 35.94090909090909, "ram_util_percent": 15.849999999999996}}
{"episode_reward_max": -27.400000000000002, "episode_reward_min": -81.30000000000001, "episode_reward_mean": -48.575563909774445, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-31.1, -51.9, -40.80000000000001, -38.60000000000001, -45.2, -41.0, -65.3, -42.1, -37.00000000000001, -54.20000000000001, -36.2, -40.4, -32.4, -51.099999999999994, -40.400000000000006, -45.00000000000001, -52.20000000000001, -46.400000000000006, -61.2, -48.70000000000001, -61.70000000000001, -41.800000000000004, -38.800000000000004, -36.300000000000004, -48.70000000000001, -46.70000000000001, -35.800000000000004, -53.60000000000001, -38.3, -50.5, -41.5, -42.9, -49.2, -45.699999999999996, -48.400000000000006, -59.199999999999996, -49.400000000000006, -36.2, -34.199999999999996, -46.900000000000006, -45.2, -35.7, -59.10000000000001, -67.39999999999999, -42.60000000000001, -57.300000000000004, -32.5, -50.50000000000001, -45.70000000000001, -55.00000000000001, -51.1, -53.00000000000001, -37.800000000000004, -69.7, -50.7, -33.0, -36.2, -34.60000000000001, -54.900000000000006, -53.60000000000001, -37.900000000000006, -59.6, -52.800000000000004, -57.2, -49.90000000000001, -41.900000000000006, -54.199999999999996, -50.00000000000001, -39.800000000000004, -42.3, -72.8, -44.20000000000001, -41.500000000000014, -48.5, -52.20000000000001, -46.800000000000004, -40.0, -58.40000000000001, -55.0, -51.00000000000001, -51.6, -63.7, -62.499999999999986, -51.400000000000006, -69.4, -43.2, -52.300000000000004, -57.10000000000001, -55.90000000000002, -38.2, -50.40000000000001, -42.900000000000006, -64.60000000000001, -50.30000000000001, -48.3, -42.400000000000006, -49.399999999999984, -44.400000000000006, -31.4, -55.100000000000016, -52.2, -51.80000000000001, -46.5, -41.900000000000006, -62.900000000000006, -57.599999999999994, -72.0, -41.300000000000004, -30.900000000000002, -73.6, -42.20000000000001, -29.6, -36.5, -62.30000000000001, -53.400000000000006, -32.4, -46.300000000000004, -37.70000000000001, -44.00000000000001, -76.99999999999999, -40.20000000000001, -55.900000000000006, -53.300000000000004, -47.1, -67.30000000000001, -54.00000000000001, -51.80000000000001, -59.4, -49.2, -33.6, -43.10000000000001, -51.80000000000001, -43.4, -56.30000000000001, -47.400000000000006, -30.200000000000003, -48.300000000000004, -62.6, -40.6, -49.7, -52.00000000000001, -58.2, -69.3, -36.20000000000001, -32.400000000000006, -47.7, -41.300000000000004, -50.800000000000004, -34.300000000000004, -29.20000000000001, -51.80000000000001, -56.90000000000001, -46.5, -65.0, -34.0, -50.7, -56.400000000000006, -73.50000000000001, -44.0, -47.900000000000006, -48.000000000000014, -54.70000000000001, -44.00000000000001, -48.400000000000006, -40.0, -35.800000000000004, -35.70000000000001, -39.1, -52.50000000000001, -64.10000000000001, -52.40000000000001, -67.5, -54.79999999999999, -81.30000000000001, -60.700000000000024, -35.900000000000006, -51.00000000000001, -42.2, -44.000000000000014, -64.10000000000001, -37.6, -47.20000000000001, -54.10000000000001, -35.300000000000004, -39.300000000000004, -27.400000000000002, -31.799999999999997, -56.000000000000014, -74.9, -42.1, -41.80000000000001, -50.20000000000001, -42.699999999999996, -54.6, -39.800000000000004, -47.5, -57.10000000000001, -53.400000000000006, -47.099999999999994, -58.20000000000001, -36.900000000000006, -51.3, -55.00000000000001, -51.1, -34.300000000000004, -28.000000000000004, -45.0, -56.500000000000014, -41.900000000000006, -53.400000000000006, -58.0, -47.7, -54.400000000000006, -44.0, -43.4, -58.7, -51.900000000000006, -55.400000000000006, -49.900000000000006, -46.800000000000004, -53.600000000000016, -32.50000000000001, -55.60000000000001, -43.300000000000004, -37.1, -35.6, -55.900000000000006, -52.10000000000001, -70.8, -56.89999999999999, -66.20000000000002, -59.1, -48.800000000000004, -39.1, -47.900000000000006, -54.39999999999999, -55.60000000000001, -40.9, -45.2, -62.39999999999999, -40.0, -65.80000000000001, -51.60000000000001, -62.00000000000001, -43.30000000000001, -45.7, -56.400000000000006, -32.7, -49.900000000000006, -37.7, -46.2, -42.300000000000004, -58.6, -56.3, -30.8, -28.8, -27.5, -37.50000000000001, -69.4, -43.30000000000001, -54.9, -53.400000000000006, -57.90000000000001, -45.4, -57.5, -46.8], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1371305072493611, "mean_inference_ms": 1.2386046579983896, "mean_action_processing_ms": 0.05558043955966066, "mean_env_wait_ms": 2.2666882484863473, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 76000, "agent_timesteps_total": 76000, "timers": {"sample_time_ms": 7439.837, "sample_throughput": 537.646, "load_time_ms": 0.046, "load_throughput": 86569742.002, "learn_time_ms": 7906.005, "learn_throughput": 505.945, "update_time_ms": 1.65}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 225.01544433921896, "policy_loss": -0.03352890234160167, "vf_loss": 225.046875984438, "vf_explained_var": [0.03408157825469971], "kl": 0.01048543932541783, "entropy": 1.6244291259396462, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 76000, "num_agent_steps_sampled": 76000, "num_steps_trained": 76000, "num_agent_steps_trained": 76000}, "done": false, "episodes_total": 5066, "training_iteration": 19, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-15-21", "timestamp": 1632518121, "time_this_iter_s": 15.311262130737305, "time_total_s": 289.0529124736786, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 289.0529124736786, "timesteps_since_restore": 0, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 35.11363636363636, "ram_util_percent": 15.899999999999995}}
{"episode_reward_max": -21.099999999999998, "episode_reward_min": -93.59999999999995, "episode_reward_mean": -48.15601503759399, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-45.3, -51.10000000000001, -58.400000000000006, -24.3, -38.900000000000006, -25.1, -49.7, -51.00000000000001, -37.7, -38.900000000000006, -41.2, -55.3, -48.900000000000006, -47.900000000000006, -71.4, -58.300000000000004, -39.0, -36.70000000000001, -55.900000000000006, -53.30000000000001, -49.9, -59.40000000000001, -35.300000000000004, -31.700000000000003, -54.10000000000001, -46.00000000000001, -45.50000000000001, -52.30000000000002, -38.1, -50.10000000000001, -46.50000000000001, -35.400000000000006, -43.300000000000004, -35.1, -56.0, -47.10000000000001, -62.30000000000001, -70.89999999999998, -56.400000000000006, -65.9, -38.5, -43.6, -50.7, -48.10000000000001, -43.60000000000001, -37.800000000000004, -49.70000000000001, -33.20000000000001, -75.7, -67.3, -40.70000000000001, -49.40000000000001, -30.099999999999998, -34.900000000000006, -31.900000000000002, -70.7, -26.400000000000006, -55.900000000000006, -52.6, -40.1, -79.4, -58.40000000000002, -58.0, -41.10000000000001, -45.800000000000004, -37.6, -48.9, -55.2, -55.400000000000006, -46.400000000000006, -33.1, -34.2, -36.400000000000006, -60.500000000000014, -38.2, -51.00000000000001, -37.8, -57.80000000000001, -64.30000000000001, -62.300000000000004, -65.89999999999999, -27.0, -40.2, -47.0, -54.2, -56.100000000000016, -38.300000000000004, -41.500000000000014, -45.50000000000001, -47.40000000000001, -43.800000000000004, -56.30000000000002, -67.30000000000003, -34.3, -52.8, -38.800000000000004, -50.60000000000001, -42.70000000000001, -44.50000000000001, -38.800000000000004, -54.00000000000001, -79.7, -50.9, -61.60000000000001, -46.70000000000001, -30.800000000000004, -39.900000000000006, -49.9, -21.099999999999998, -41.7, -56.10000000000001, -64.30000000000001, -28.6, -52.699999999999996, -41.6, -72.1, -38.800000000000004, -37.8, -41.5, -37.7, -60.20000000000001, -46.60000000000001, -54.800000000000004, -72.5, -40.20000000000001, -52.30000000000001, -36.900000000000006, -59.500000000000014, -66.9, -41.60000000000001, -44.10000000000001, -35.4, -48.900000000000006, -55.7, -75.5, -38.30000000000001, -60.70000000000001, -42.800000000000004, -56.6, -30.700000000000003, -59.9, -40.60000000000001, -62.7, -93.59999999999995, -37.300000000000004, -32.5, -53.900000000000006, -47.4, -57.800000000000004, -48.9, -33.0, -47.800000000000004, -72.2, -36.7, -49.6, -39.0, -33.300000000000004, -46.60000000000001, -39.699999999999996, -47.10000000000001, -63.50000000000001, -29.6, -56.400000000000006, -31.8, -44.00000000000001, -38.900000000000006, -39.2, -29.6, -50.099999999999994, -35.300000000000004, -41.9, -51.500000000000014, -45.7, -32.4, -44.00000000000001, -64.50000000000001, -28.299999999999997, -39.7, -50.6, -42.2, -47.20000000000001, -46.99999999999999, -41.30000000000001, -55.7, -55.400000000000006, -54.099999999999994, -63.500000000000014, -49.70000000000002, -45.900000000000006, -62.2, -72.80000000000001, -50.900000000000006, -51.900000000000006, -52.800000000000004, -31.3, -44.900000000000006, -65.60000000000001, -44.900000000000006, -50.00000000000001, -49.500000000000014, -79.0, -45.7, -50.6, -51.1, -37.99999999999999, -45.10000000000001, -45.8, -55.000000000000014, -42.00000000000001, -46.900000000000006, -46.2, -33.6, -45.2, -47.4, -48.60000000000001, -40.9, -61.20000000000002, -46.800000000000004, -40.6, -41.8, -60.600000000000016, -34.800000000000004, -47.00000000000001, -45.000000000000014, -33.2, -59.400000000000006, -27.400000000000006, -49.7, -55.300000000000004, -35.2, -52.9, -58.2, -64.8, -45.00000000000001, -43.90000000000001, -42.60000000000001, -57.099999999999994, -36.2, -36.00000000000001, -59.400000000000006, -36.2, -47.90000000000001, -50.2, -55.6, -26.100000000000005, -55.70000000000002, -49.50000000000001, -42.2, -46.4, -42.70000000000002, -66.10000000000001, -65.00000000000001, -55.6, -52.00000000000001, -49.900000000000006, -33.7, -53.5, -41.0, -56.50000000000001, -34.7, -72.2, -67.89999999999999, -55.6, -49.70000000000001, -50.7, -49.300000000000004], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1368736559765175, "mean_inference_ms": 1.2367566088843842, "mean_action_processing_ms": 0.055496041373799335, "mean_env_wait_ms": 2.2599863733656065, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 80000, "agent_timesteps_total": 80000, "timers": {"sample_time_ms": 7359.379, "sample_throughput": 543.524, "load_time_ms": 0.045, "load_throughput": 88674503.171, "learn_time_ms": 7835.301, "learn_throughput": 510.51, "update_time_ms": 1.634}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 232.46373966996387, "policy_loss": -0.03344657795794148, "vf_loss": 232.49488861740275, "vf_explained_var": [0.04500236362218857], "kl": 0.011483757007130226, "entropy": 1.5507622886729497, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 80000, "num_agent_steps_sampled": 80000, "num_steps_trained": 80000, "num_agent_steps_trained": 80000}, "done": false, "episodes_total": 5332, "training_iteration": 20, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-15-35", "timestamp": 1632518135, "time_this_iter_s": 14.326100826263428, "time_total_s": 303.379013299942, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 303.379013299942, "timesteps_since_restore": 0, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 34.57142857142857, "ram_util_percent": 15.899999999999997}}
{"episode_reward_max": -25.800000000000004, "episode_reward_min": -88.10000000000001, "episode_reward_mean": -48.066044776119405, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 268, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-46.900000000000006, -48.0, -36.900000000000006, -46.20000000000001, -47.7, -32.60000000000001, -47.7, -40.30000000000001, -49.80000000000001, -63.30000000000001, -33.2, -72.6, -32.699999999999996, -35.6, -41.00000000000001, -34.5, -39.900000000000006, -36.900000000000006, -37.0, -44.2, -58.80000000000001, -30.999999999999996, -48.30000000000001, -38.1, -46.00000000000001, -52.699999999999996, -49.40000000000001, -45.50000000000001, -48.20000000000001, -33.599999999999994, -49.800000000000004, -37.0, -38.20000000000001, -54.400000000000006, -52.10000000000001, -47.300000000000004, -44.5, -64.40000000000002, -35.1, -32.7, -45.50000000000001, -44.2, -42.1, -46.099999999999994, -41.800000000000004, -55.70000000000001, -45.1, -54.400000000000006, -70.19999999999999, -55.400000000000006, -27.1, -68.7, -44.50000000000001, -42.5, -42.5, -57.29999999999999, -41.7, -49.300000000000004, -30.000000000000004, -47.400000000000006, -61.300000000000004, -30.200000000000003, -38.900000000000006, -40.2, -40.10000000000001, -43.00000000000001, -48.10000000000001, -48.800000000000004, -50.50000000000001, -40.300000000000004, -55.100000000000016, -63.400000000000006, -42.900000000000006, -47.400000000000006, -71.30000000000001, -44.3, -47.50000000000001, -48.1, -42.6, -48.400000000000006, -28.900000000000006, -49.800000000000004, -76.0, -35.699999999999996, -63.6, -63.30000000000001, -47.70000000000001, -47.3, -73.9, -31.0, -50.50000000000001, -53.7, -65.00000000000001, -45.00000000000001, -49.800000000000004, -54.50000000000001, -62.999999999999986, -40.0, -49.2, -43.00000000000001, -44.300000000000004, -28.599999999999998, -53.5, -88.10000000000001, -45.900000000000006, -46.00000000000001, -60.80000000000001, -54.60000000000001, -45.00000000000001, -45.30000000000001, -79.19999999999999, -37.300000000000004, -60.89999999999999, -57.6, -48.599999999999994, -55.1, -45.50000000000001, -49.4, -51.70000000000002, -56.500000000000014, -43.60000000000001, -32.300000000000004, -43.800000000000004, -46.900000000000006, -47.6, -34.1, -49.00000000000001, -37.4, -73.5, -32.800000000000004, -62.6, -59.60000000000001, -34.4, -55.40000000000001, -44.699999999999996, -44.9, -41.7, -48.90000000000001, -36.3, -56.70000000000001, -45.7, -28.200000000000003, -25.800000000000004, -42.800000000000004, -56.20000000000001, -40.2, -45.70000000000001, -48.1, -47.80000000000001, -53.50000000000001, -34.800000000000004, -48.60000000000001, -62.2, -34.6, -55.7, -53.50000000000001, -62.900000000000006, -44.0, -38.1, -61.40000000000001, -55.900000000000006, -56.30000000000001, -48.2, -47.2, -78.39999999999999, -52.400000000000006, -46.10000000000001, -43.7, -46.10000000000001, -55.6, -33.900000000000006, -47.900000000000006, -36.50000000000001, -37.900000000000006, -42.4, -47.8, -37.3, -46.40000000000001, -35.30000000000001, -40.7, -48.1, -62.50000000000001, -37.7, -67.50000000000001, -33.0, -44.10000000000001, -60.2, -56.400000000000006, -43.90000000000001, -52.300000000000004, -49.8, -57.00000000000001, -52.8, -54.400000000000006, -31.9, -56.900000000000006, -29.5, -46.7, -54.099999999999994, -45.0, -52.50000000000001, -59.70000000000001, -50.20000000000001, -32.49999999999999, -38.1, -43.300000000000004, -37.800000000000004, -59.50000000000001, -46.00000000000001, -54.10000000000001, -41.400000000000006, -48.80000000000001, -32.1, -62.800000000000004, -44.900000000000006, -50.900000000000006, -56.00000000000001, -45.5, -44.50000000000001, -50.60000000000001, -27.700000000000003, -77.50000000000003, -51.0, -54.50000000000001, -34.6, -48.60000000000001, -45.300000000000004, -39.60000000000001, -59.7, -50.30000000000001, -39.1, -27.3, -41.60000000000001, -37.30000000000001, -56.30000000000001, -38.20000000000001, -53.5, -47.10000000000001, -51.20000000000001, -77.80000000000001, -49.00000000000001, -44.00000000000001, -47.60000000000001, -37.00000000000001, -26.4, -38.4, -40.400000000000006, -54.7, -55.10000000000001, -55.60000000000001, -56.60000000000001, -54.90000000000001, -58.50000000000001, -64.7, -40.00000000000001, -79.00000000000001, -44.900000000000006, -35.0, -50.2, -67.50000000000001, -53.4, -68.00000000000001, -43.800000000000004, -54.60000000000001, -62.2, -44.7, -61.20000000000002, -46.30000000000001], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13653990092815319, "mean_inference_ms": 1.2342750207318776, "mean_action_processing_ms": 0.05539056048592268, "mean_env_wait_ms": 2.252870345552184, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 84000, "agent_timesteps_total": 84000, "timers": {"sample_time_ms": 7357.401, "sample_throughput": 543.67, "load_time_ms": 0.045, "load_throughput": 88674503.171, "learn_time_ms": 7782.379, "learn_throughput": 513.982, "update_time_ms": 1.52}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 223.82086137340914, "policy_loss": -0.03909229763573216, "vf_loss": 223.8574983822402, "vf_explained_var": [0.04318249970674515], "kl": 0.012276592115214665, "entropy": 1.5127830724562368, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 84000, "num_agent_steps_sampled": 84000, "num_steps_trained": 84000, "num_agent_steps_trained": 84000}, "done": false, "episodes_total": 5600, "training_iteration": 21, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-15-50", "timestamp": 1632518150, "time_this_iter_s": 14.068346738815308, "time_total_s": 317.4473600387573, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 317.4473600387573, "timesteps_since_restore": 0, "iterations_since_restore": 21, "perf": {"cpu_util_percent": 34.12, "ram_util_percent": 15.899999999999997}}
{"episode_reward_max": -15.700000000000001, "episode_reward_min": -76.5, "episode_reward_mean": -45.99849624060151, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-63.900000000000006, -44.2, -47.70000000000001, -53.000000000000014, -34.2, -44.0, -39.2, -31.6, -48.10000000000001, -48.300000000000004, -40.800000000000004, -45.800000000000004, -26.5, -24.6, -32.6, -43.199999999999996, -47.800000000000004, -47.699999999999996, -47.2, -42.60000000000001, -31.200000000000003, -35.6, -43.40000000000001, -45.8, -59.800000000000004, -45.00000000000001, -52.70000000000002, -37.7, -46.6, -33.4, -41.90000000000001, -50.000000000000014, -53.50000000000001, -62.60000000000001, -48.1, -52.7, -48.900000000000006, -58.0, -39.00000000000001, -35.70000000000001, -40.2, -40.10000000000001, -55.19999999999999, -49.4, -47.2, -46.1, -41.800000000000004, -37.0, -64.10000000000001, -24.8, -54.900000000000006, -48.10000000000001, -50.300000000000004, -59.400000000000006, -50.0, -49.1, -53.1, -56.60000000000001, -48.70000000000001, -61.60000000000001, -47.9, -73.4, -44.00000000000001, -49.800000000000004, -42.900000000000006, -52.80000000000001, -58.2, -64.4, -46.80000000000001, -51.80000000000001, -56.8, -37.0, -43.6, -40.5, -33.5, -51.400000000000006, -54.70000000000001, -31.500000000000004, -51.10000000000001, -47.70000000000001, -30.299999999999997, -36.800000000000004, -31.900000000000002, -47.60000000000001, -60.699999999999996, -41.50000000000001, -46.6, -62.400000000000006, -15.700000000000001, -41.900000000000006, -26.700000000000003, -46.800000000000004, -33.2, -48.3, -52.40000000000001, -44.7, -42.30000000000001, -61.19999999999999, -30.200000000000003, -41.300000000000004, -35.2, -44.3, -44.800000000000004, -37.800000000000004, -61.20000000000001, -48.10000000000001, -46.2, -47.00000000000001, -40.2, -47.500000000000014, -42.10000000000001, -59.40000000000001, -58.599999999999994, -67.60000000000001, -42.7, -28.200000000000003, -57.900000000000006, -53.60000000000001, -44.400000000000006, -39.900000000000006, -34.5, -39.900000000000006, -59.8, -45.70000000000001, -64.19999999999999, -56.100000000000016, -41.300000000000004, -45.60000000000001, -35.300000000000004, -27.299999999999997, -64.4, -57.09999999999999, -57.40000000000001, -49.2, -43.2, -46.80000000000001, -52.300000000000004, -48.80000000000001, -49.60000000000001, -35.70000000000001, -43.7, -36.2, -30.8, -51.900000000000006, -43.800000000000004, -29.700000000000003, -40.0, -58.00000000000001, -60.50000000000001, -44.60000000000001, -68.20000000000002, -44.6, -28.400000000000002, -52.60000000000001, -48.40000000000001, -56.400000000000006, -39.5, -55.6, -57.9, -54.60000000000001, -61.900000000000006, -61.900000000000006, -32.1, -57.0, -62.800000000000004, -37.7, -41.900000000000006, -53.0, -50.800000000000004, -47.30000000000001, -49.2, -41.30000000000001, -41.10000000000001, -38.80000000000001, -51.2, -51.60000000000001, -34.6, -45.2, -55.80000000000001, -34.3, -59.50000000000001, -51.800000000000004, -35.70000000000001, -43.800000000000004, -48.10000000000001, -57.600000000000016, -51.800000000000004, -41.1, -44.2, -44.400000000000006, -50.50000000000001, -41.7, -40.9, -39.2, -48.2, -38.9, -41.0, -48.500000000000014, -47.1, -52.0, -51.000000000000014, -47.300000000000004, -40.099999999999994, -51.60000000000001, -32.0, -54.199999999999996, -38.500000000000014, -39.5, -48.00000000000001, -39.2, -63.90000000000001, -70.60000000000001, -38.599999999999994, -29.399999999999995, -43.900000000000006, -33.5, -61.00000000000002, -49.600000000000016, -42.4, -51.70000000000001, -30.6, -42.400000000000006, -36.900000000000006, -46.7, -43.7, -36.10000000000001, -33.5, -44.300000000000004, -55.10000000000001, -39.800000000000004, -48.00000000000001, -50.6, -37.5, -49.0, -36.4, -38.1, -37.50000000000001, -45.00000000000001, -54.400000000000006, -34.7, -47.30000000000001, -40.300000000000004, -31.4, -52.800000000000004, -52.60000000000001, -36.0, -37.6, -48.4, -45.70000000000001, -51.30000000000001, -47.300000000000004, -32.50000000000001, -68.80000000000001, -35.300000000000004, -29.5, -48.70000000000001, -51.7, -34.50000000000001, -29.900000000000006, -33.300000000000004, -52.000000000000014, -76.5, -39.400000000000006, -42.3, -42.20000000000001, -65.6], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13636330068578764, "mean_inference_ms": 1.2330717071750286, "mean_action_processing_ms": 0.05534775340934496, "mean_env_wait_ms": 2.2476183788627013, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 88000, "agent_timesteps_total": 88000, "timers": {"sample_time_ms": 7327.255, "sample_throughput": 545.907, "load_time_ms": 0.045, "load_throughput": 88862372.881, "learn_time_ms": 7593.187, "learn_throughput": 526.788, "update_time_ms": 1.549}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 196.67977055375295, "policy_loss": -0.036116273379984805, "vf_loss": 196.71332248154508, "vf_explained_var": [0.05555317550897598], "kl": 0.012823680956469491, "entropy": 1.4869405604177905, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 88000, "num_agent_steps_sampled": 88000, "num_steps_trained": 88000, "num_agent_steps_trained": 88000}, "done": false, "episodes_total": 5866, "training_iteration": 22, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-16-04", "timestamp": 1632518164, "time_this_iter_s": 14.18005657196045, "time_total_s": 331.6274166107178, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 331.6274166107178, "timesteps_since_restore": 0, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 33.504999999999995, "ram_util_percent": 15.899999999999997}}
{"episode_reward_max": -25.299999999999997, "episode_reward_min": -114.59999999999992, "episode_reward_mean": -46.44624060150376, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-46.800000000000004, -53.50000000000001, -38.8, -50.900000000000006, -43.50000000000001, -38.20000000000001, -35.2, -38.900000000000006, -64.80000000000003, -37.900000000000006, -54.20000000000002, -40.80000000000001, -39.300000000000004, -38.800000000000004, -42.1, -53.1, -39.1, -50.70000000000001, -44.800000000000004, -30.1, -47.800000000000004, -38.9, -51.30000000000001, -34.2, -39.7, -28.000000000000004, -43.00000000000001, -47.900000000000006, -67.80000000000001, -61.00000000000001, -39.3, -30.000000000000004, -43.6, -64.30000000000001, -44.7, -42.0, -51.800000000000004, -58.7, -44.10000000000001, -43.300000000000004, -56.800000000000004, -41.2, -60.80000000000001, -34.900000000000006, -67.50000000000003, -36.6, -42.7, -39.2, -38.20000000000001, -45.5, -40.50000000000001, -63.0, -50.400000000000006, -43.0, -42.1, -59.0, -44.60000000000001, -64.50000000000001, -45.6, -43.0, -46.10000000000001, -43.0, -70.0, -62.40000000000001, -56.0, -42.7, -43.30000000000001, -58.50000000000001, -40.400000000000006, -62.5, -60.0, -35.6, -56.60000000000001, -60.000000000000014, -55.20000000000001, -31.099999999999998, -44.00000000000001, -49.300000000000004, -31.7, -55.400000000000006, -35.00000000000001, -38.6, -36.0, -52.599999999999994, -54.80000000000001, -34.800000000000004, -49.70000000000001, -53.0, -43.00000000000001, -50.400000000000006, -63.80000000000001, -31.900000000000002, -39.099999999999994, -40.1, -47.2, -52.300000000000004, -41.10000000000001, -44.900000000000006, -45.80000000000001, -36.7, -44.7, -44.800000000000004, -46.800000000000004, -44.60000000000001, -52.900000000000006, -50.900000000000006, -41.60000000000001, -46.70000000000001, -34.4, -32.6, -31.900000000000006, -46.900000000000006, -46.0, -45.800000000000004, -45.1, -42.90000000000001, -55.400000000000006, -26.900000000000002, -48.80000000000001, -67.3, -48.20000000000001, -39.2, -62.99999999999999, -60.20000000000001, -53.10000000000001, -57.900000000000006, -46.7, -58.800000000000004, -37.7, -61.10000000000001, -54.60000000000001, -41.800000000000004, -36.6, -66.19999999999999, -51.50000000000001, -41.7, -53.40000000000001, -31.000000000000007, -44.1, -30.1, -38.099999999999994, -42.60000000000001, -33.0, -59.6, -35.900000000000006, -29.600000000000005, -35.699999999999996, -36.1, -41.2, -47.30000000000001, -39.6, -55.699999999999996, -52.8, -54.60000000000001, -43.6, -52.80000000000001, -59.6, -40.00000000000001, -32.0, -44.9, -32.400000000000006, -30.2, -34.400000000000006, -33.00000000000001, -46.900000000000006, -47.20000000000001, -49.2, -50.8, -55.1, -63.80000000000002, -27.900000000000002, -29.0, -43.30000000000001, -63.40000000000001, -49.30000000000001, -80.6, -34.7, -47.6, -38.00000000000001, -56.500000000000014, -40.400000000000006, -44.2, -48.400000000000006, -49.300000000000004, -44.7, -54.900000000000006, -34.3, -46.50000000000001, -55.60000000000001, -25.299999999999997, -64.2, -31.700000000000003, -54.19999999999999, -49.2, -56.70000000000002, -56.10000000000001, -33.6, -49.0, -42.199999999999996, -74.79999999999998, -28.900000000000006, -37.2, -39.6, -37.800000000000004, -42.6, -39.7, -58.7, -59.199999999999996, -47.9, -38.10000000000001, -47.2, -28.800000000000004, -59.50000000000001, -39.400000000000006, -38.800000000000004, -39.400000000000006, -41.2, -72.10000000000001, -41.60000000000001, -58.400000000000006, -47.6, -32.6, -43.900000000000006, -47.7, -44.9, -35.7, -38.10000000000001, -55.30000000000001, -45.00000000000001, -41.800000000000004, -36.2, -57.5, -55.300000000000004, -60.80000000000001, -114.59999999999992, -45.80000000000001, -36.7, -52.4, -44.1, -36.400000000000006, -34.4, -40.900000000000006, -39.8, -48.2, -36.4, -44.1, -52.599999999999994, -41.800000000000004, -44.0, -44.60000000000001, -45.300000000000004, -48.199999999999996, -53.900000000000006, -61.89999999999999, -34.2, -48.500000000000014, -45.8, -44.7, -52.1, -51.800000000000004, -45.10000000000001, -57.300000000000004, -44.60000000000001, -46.1, -52.300000000000004, -53.80000000000001], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13608801212262278, "mean_inference_ms": 1.2308500639285909, "mean_action_processing_ms": 0.05526727796759269, "mean_env_wait_ms": 2.2412506446291895, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 92000, "agent_timesteps_total": 92000, "timers": {"sample_time_ms": 7289.561, "sample_throughput": 548.73, "load_time_ms": 0.045, "load_throughput": 89003798.408, "learn_time_ms": 7439.471, "learn_throughput": 537.673, "update_time_ms": 1.478}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 207.19829236102362, "policy_loss": -0.040263316003725895, "vf_loss": 207.23587311775452, "vf_explained_var": [0.05029572546482086], "kl": 0.013409405591411135, "entropy": 1.4237141137482017, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 92000, "num_agent_steps_sampled": 92000, "num_steps_trained": 92000, "num_agent_steps_trained": 92000}, "done": false, "episodes_total": 6132, "training_iteration": 23, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-16-18", "timestamp": 1632518178, "time_this_iter_s": 14.278424501419067, "time_total_s": 345.90584111213684, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 345.90584111213684, "timesteps_since_restore": 0, "iterations_since_restore": 23, "perf": {"cpu_util_percent": 34.30952380952381, "ram_util_percent": 15.899999999999997}}
{"episode_reward_max": -19.0, "episode_reward_min": -93.59999999999997, "episode_reward_mean": -45.94477611940299, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 268, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.2, -51.10000000000001, -42.70000000000001, -36.8, -39.7, -56.800000000000004, -50.2, -45.00000000000001, -49.20000000000001, -50.0, -30.7, -37.7, -45.60000000000001, -37.4, -35.0, -46.4, -61.100000000000016, -40.300000000000004, -46.9, -34.0, -45.50000000000001, -43.599999999999994, -44.0, -43.800000000000004, -44.800000000000004, -58.60000000000001, -74.69999999999999, -48.400000000000006, -45.7, -47.900000000000006, -31.900000000000002, -53.300000000000004, -38.2, -37.0, -38.50000000000001, -53.60000000000001, -38.400000000000006, -45.10000000000001, -49.4, -41.10000000000001, -45.60000000000001, -37.5, -32.1, -60.900000000000006, -59.50000000000001, -43.70000000000001, -35.300000000000004, -56.0, -41.800000000000004, -31.4, -39.6, -44.60000000000001, -40.0, -33.60000000000001, -52.6, -51.10000000000001, -55.400000000000006, -51.20000000000001, -54.4, -36.60000000000001, -49.40000000000001, -40.7, -39.2, -38.2, -45.1, -35.7, -55.10000000000001, -36.900000000000006, -39.900000000000006, -40.1, -51.900000000000006, -36.900000000000006, -53.70000000000002, -44.50000000000001, -38.6, -58.400000000000006, -19.0, -26.0, -45.2, -51.7, -44.1, -48.90000000000001, -57.70000000000001, -51.9, -57.900000000000006, -54.00000000000001, -51.10000000000001, -45.10000000000001, -41.1, -29.600000000000005, -60.80000000000001, -41.20000000000001, -58.900000000000006, -42.3, -45.800000000000004, -34.10000000000001, -43.5, -44.80000000000001, -58.800000000000004, -32.1, -53.00000000000001, -33.00000000000001, -81.69999999999996, -39.0, -30.500000000000004, -62.70000000000001, -59.400000000000006, -50.50000000000001, -29.2, -60.60000000000001, -61.10000000000001, -40.300000000000004, -59.8, -36.0, -48.50000000000001, -36.2, -33.300000000000004, -35.400000000000006, -44.900000000000006, -93.59999999999997, -35.2, -26.699999999999996, -54.099999999999994, -37.10000000000001, -51.2, -43.00000000000001, -63.89999999999999, -44.5, -45.50000000000001, -42.300000000000004, -50.30000000000001, -56.100000000000016, -43.00000000000001, -43.6, -51.00000000000001, -34.400000000000006, -39.800000000000004, -64.9, -58.599999999999994, -42.2, -42.1, -41.0, -45.1, -56.900000000000006, -46.2, -23.5, -34.300000000000004, -41.30000000000001, -43.70000000000001, -37.2, -62.599999999999994, -43.3, -51.00000000000001, -49.0, -48.60000000000001, -54.00000000000001, -41.10000000000001, -40.800000000000004, -45.7, -30.9, -58.300000000000004, -32.199999999999996, -40.900000000000006, -58.5, -70.9, -53.699999999999996, -39.900000000000006, -39.00000000000001, -43.50000000000001, -44.5, -52.099999999999994, -39.50000000000001, -40.0, -41.30000000000001, -35.2, -44.30000000000002, -33.199999999999996, -50.300000000000004, -52.7, -40.70000000000001, -46.199999999999996, -45.7, -45.6, -42.400000000000006, -42.7, -34.800000000000004, -51.10000000000001, -40.2, -45.9, -52.6, -47.6, -48.7, -39.900000000000006, -53.10000000000002, -67.2, -30.900000000000002, -51.900000000000006, -61.199999999999996, -39.10000000000001, -37.2, -59.099999999999994, -61.4, -46.80000000000001, -51.70000000000001, -49.7, -40.4, -37.1, -37.1, -42.10000000000001, -51.00000000000001, -46.00000000000001, -38.400000000000006, -49.300000000000004, -40.00000000000001, -40.5, -39.50000000000001, -52.40000000000001, -45.90000000000001, -51.20000000000001, -36.7, -47.40000000000001, -50.900000000000006, -48.00000000000001, -51.30000000000001, -56.300000000000004, -48.900000000000006, -58.10000000000001, -39.50000000000001, -62.900000000000006, -54.70000000000001, -56.20000000000002, -50.2, -23.800000000000004, -66.99999999999999, -48.7, -46.6, -36.70000000000001, -57.7, -50.300000000000004, -44.800000000000004, -35.0, -50.800000000000004, -35.2, -41.7, -44.5, -41.60000000000001, -50.9, -40.900000000000006, -54.7, -60.5, -53.4, -68.2, -36.900000000000006, -42.099999999999994, -45.900000000000006, -54.2, -41.900000000000006, -45.00000000000001, -43.30000000000001, -59.90000000000001, -33.4, -58.50000000000001, -27.9, -38.300000000000004, -39.70000000000001, -50.400000000000006, -43.2, -36.7], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13595183082765416, "mean_inference_ms": 1.2300774339899336, "mean_action_processing_ms": 0.055220841800184814, "mean_env_wait_ms": 2.2372774515461717, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 96000, "agent_timesteps_total": 96000, "timers": {"sample_time_ms": 7256.13, "sample_throughput": 551.258, "load_time_ms": 0.045, "load_throughput": 88768338.624, "learn_time_ms": 7364.384, "learn_throughput": 543.155, "update_time_ms": 1.489}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 199.8584009150023, "policy_loss": -0.03196708997260899, "vf_loss": 199.88799858503444, "vf_explained_var": [0.04772653430700302], "kl": 0.011848592274429122, "entropy": 1.4051356657858818, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 96000, "num_agent_steps_sampled": 96000, "num_steps_trained": 96000, "num_agent_steps_trained": 96000}, "done": false, "episodes_total": 6400, "training_iteration": 24, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-16-32", "timestamp": 1632518192, "time_this_iter_s": 14.135025024414062, "time_total_s": 360.0408661365509, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 360.0408661365509, "timesteps_since_restore": 0, "iterations_since_restore": 24, "perf": {"cpu_util_percent": 33.885000000000005, "ram_util_percent": 15.899999999999997}}
{"episode_reward_max": -21.2, "episode_reward_min": -102.09999999999997, "episode_reward_mean": -45.84248120300753, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-36.1, -42.800000000000004, -51.0, -34.5, -76.5, -41.400000000000006, -35.900000000000006, -29.300000000000004, -38.5, -43.0, -46.800000000000004, -62.900000000000006, -36.1, -58.900000000000006, -48.6, -39.70000000000001, -60.50000000000001, -44.800000000000004, -56.80000000000001, -42.2, -54.7, -46.7, -43.5, -51.4, -28.8, -42.800000000000004, -51.10000000000001, -37.2, -38.6, -50.2, -47.8, -37.49999999999999, -61.30000000000001, -44.0, -28.500000000000007, -35.800000000000004, -39.300000000000004, -45.3, -46.2, -24.300000000000004, -41.3, -74.7, -100.19999999999996, -55.60000000000001, -41.400000000000006, -38.800000000000004, -38.7, -43.2, -43.90000000000001, -32.2, -33.5, -36.300000000000004, -38.5, -42.800000000000004, -37.4, -28.6, -39.60000000000001, -50.4, -56.0, -62.00000000000001, -62.400000000000006, -36.1, -26.900000000000002, -40.800000000000004, -60.30000000000001, -34.2, -48.800000000000004, -39.1, -27.7, -48.7, -34.1, -43.50000000000001, -44.2, -46.3, -30.300000000000008, -43.099999999999994, -56.00000000000001, -45.300000000000004, -40.199999999999996, -44.00000000000001, -31.900000000000002, -58.2, -49.30000000000001, -55.199999999999996, -41.199999999999996, -52.2, -49.1, -60.599999999999994, -30.900000000000002, -46.7, -39.0, -43.9, -43.50000000000001, -21.900000000000002, -54.0, -55.00000000000001, -55.3, -43.5, -54.50000000000001, -50.50000000000001, -37.4, -26.700000000000003, -50.1, -47.60000000000001, -45.400000000000006, -58.60000000000001, -45.300000000000004, -36.60000000000001, -47.2, -43.400000000000006, -41.2, -59.20000000000002, -46.00000000000001, -64.80000000000001, -34.0, -55.800000000000004, -47.300000000000004, -56.0, -46.5, -41.2, -54.00000000000001, -54.70000000000001, -42.50000000000001, -53.50000000000001, -59.00000000000001, -54.70000000000002, -41.7, -39.50000000000001, -56.900000000000006, -47.400000000000006, -37.2, -47.30000000000001, -44.500000000000014, -49.7, -43.3, -47.5, -38.4, -35.2, -45.0, -58.300000000000004, -30.3, -60.60000000000001, -48.10000000000001, -41.800000000000004, -43.60000000000001, -39.50000000000001, -46.7, -36.900000000000006, -50.70000000000002, -36.400000000000006, -31.700000000000003, -68.79999999999998, -46.2, -53.10000000000001, -54.00000000000001, -53.80000000000001, -44.1, -44.2, -43.60000000000001, -50.99999999999999, -39.50000000000001, -47.800000000000004, -50.70000000000002, -60.100000000000016, -41.30000000000001, -47.8, -52.70000000000002, -53.3, -48.30000000000001, -62.500000000000014, -64.60000000000001, -32.9, -41.9, -44.7, -38.1, -60.9, -35.50000000000001, -35.60000000000001, -45.300000000000004, -54.30000000000001, -41.7, -46.00000000000001, -50.600000000000016, -44.300000000000004, -37.00000000000001, -42.10000000000001, -48.599999999999994, -40.1, -38.6, -60.40000000000001, -33.300000000000004, -43.90000000000001, -34.5, -46.900000000000006, -34.50000000000001, -36.900000000000006, -42.60000000000001, -59.40000000000001, -44.900000000000006, -33.800000000000004, -31.900000000000006, -45.900000000000006, -39.1, -60.5, -47.400000000000006, -47.2, -45.900000000000006, -55.2, -46.800000000000004, -45.0, -51.5, -38.50000000000001, -53.30000000000001, -50.900000000000006, -46.800000000000004, -37.60000000000001, -45.70000000000001, -37.800000000000004, -42.80000000000001, -21.2, -49.400000000000006, -37.50000000000001, -43.800000000000004, -67.20000000000002, -26.799999999999997, -43.8, -45.10000000000001, -32.5, -39.0, -40.10000000000001, -38.800000000000004, -40.7, -53.7, -53.2, -51.70000000000001, -39.300000000000004, -49.400000000000006, -69.2, -62.200000000000024, -35.6, -44.2, -102.09999999999997, -59.60000000000001, -27.7, -35.7, -41.89999999999999, -64.7, -50.10000000000001, -38.300000000000004, -43.900000000000006, -47.0, -45.2, -42.0, -32.900000000000006, -42.300000000000004, -53.400000000000006, -43.199999999999996, -41.7, -28.900000000000002, -50.900000000000006, -47.30000000000001, -52.20000000000001, -38.6, -73.5, -74.80000000000001, -33.60000000000001], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1357318148589421, "mean_inference_ms": 1.2283996044093402, "mean_action_processing_ms": 0.055120200200671286, "mean_env_wait_ms": 2.231619612736377, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 100000, "agent_timesteps_total": 100000, "timers": {"sample_time_ms": 7227.503, "sample_throughput": 553.441, "load_time_ms": 0.044, "load_throughput": 90200086.022, "learn_time_ms": 7342.276, "learn_throughput": 544.79, "update_time_ms": 1.514}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 207.38416383804812, "policy_loss": -0.03882870255038142, "vf_loss": 207.4203227955808, "vf_explained_var": [0.05904241278767586], "kl": 0.013346623772987542, "entropy": 1.4008245496339695, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 100000, "num_agent_steps_sampled": 100000, "num_steps_trained": 100000, "num_agent_steps_trained": 100000}, "done": false, "episodes_total": 6666, "training_iteration": 25, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-16-46", "timestamp": 1632518206, "time_this_iter_s": 14.17432451248169, "time_total_s": 374.2151906490326, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 374.2151906490326, "timesteps_since_restore": 0, "iterations_since_restore": 25, "perf": {"cpu_util_percent": 34.14, "ram_util_percent": 15.899999999999997}}
{"episode_reward_max": -21.4, "episode_reward_min": -85.2, "episode_reward_mean": -46.93195488721805, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-36.10000000000001, -50.599999999999994, -57.900000000000006, -52.30000000000001, -66.7, -30.300000000000004, -41.60000000000001, -45.800000000000004, -46.7, -35.9, -67.19999999999999, -50.20000000000002, -47.60000000000001, -77.99999999999997, -34.699999999999996, -34.8, -47.60000000000001, -49.2, -41.5, -45.7, -51.00000000000001, -58.0, -42.0, -55.7, -52.900000000000006, -42.7, -44.80000000000001, -49.900000000000006, -38.2, -50.10000000000001, -43.0, -43.400000000000006, -54.50000000000001, -60.5, -40.10000000000001, -47.7, -41.7, -33.40000000000001, -37.1, -33.1, -43.3, -58.70000000000001, -37.6, -45.20000000000001, -52.60000000000001, -55.5, -46.400000000000006, -54.6, -56.2, -52.80000000000001, -41.90000000000001, -45.40000000000001, -40.2, -43.300000000000004, -54.80000000000001, -29.6, -43.70000000000001, -34.300000000000004, -47.0, -38.300000000000004, -39.89999999999999, -36.50000000000001, -37.30000000000001, -45.2, -41.800000000000004, -48.10000000000001, -43.20000000000001, -51.00000000000001, -24.500000000000004, -29.7, -67.50000000000001, -52.900000000000006, -58.79999999999999, -22.200000000000003, -47.00000000000001, -66.0, -38.6, -57.00000000000001, -33.900000000000006, -34.800000000000004, -29.700000000000003, -49.2, -35.5, -33.900000000000006, -41.2, -65.70000000000002, -28.9, -55.0, -40.300000000000004, -51.2, -26.900000000000002, -61.2, -36.7, -48.10000000000001, -48.40000000000001, -85.2, -31.1, -40.2, -57.00000000000001, -43.599999999999994, -38.1, -25.500000000000004, -44.900000000000006, -63.1, -42.00000000000001, -38.7, -57.0, -42.1, -53.2, -42.300000000000004, -45.900000000000006, -37.10000000000001, -36.60000000000001, -74.00000000000001, -54.30000000000002, -57.099999999999994, -53.6, -42.400000000000006, -37.2, -35.4, -32.50000000000001, -53.300000000000004, -52.79999999999999, -60.70000000000002, -65.30000000000001, -60.000000000000014, -45.000000000000014, -42.00000000000001, -50.1, -75.69999999999999, -48.10000000000001, -57.400000000000006, -38.9, -34.6, -38.3, -50.10000000000001, -25.2, -37.300000000000004, -47.00000000000001, -36.7, -43.6, -54.500000000000014, -41.800000000000004, -57.500000000000014, -44.6, -51.60000000000001, -52.30000000000001, -30.1, -41.1, -47.900000000000006, -54.70000000000001, -59.50000000000001, -52.6, -36.50000000000001, -36.5, -69.80000000000001, -55.400000000000006, -21.4, -53.40000000000002, -56.30000000000001, -43.599999999999994, -37.1, -52.7, -61.000000000000014, -62.70000000000002, -48.900000000000006, -49.2, -54.900000000000006, -51.1, -36.8, -51.300000000000004, -46.7, -50.2, -40.10000000000001, -51.0, -49.00000000000001, -30.400000000000002, -45.8, -45.3, -44.00000000000001, -48.60000000000001, -68.30000000000001, -37.7, -53.00000000000001, -50.60000000000001, -46.5, -43.8, -44.900000000000006, -36.5, -60.3, -41.30000000000001, -39.400000000000006, -27.900000000000002, -47.00000000000001, -46.1, -55.400000000000006, -39.300000000000004, -43.1, -43.00000000000001, -44.80000000000001, -65.10000000000001, -50.2, -55.20000000000002, -38.900000000000006, -46.3, -60.30000000000002, -43.900000000000006, -69.49999999999999, -32.00000000000001, -50.60000000000001, -51.10000000000001, -44.500000000000014, -35.400000000000006, -41.7, -61.10000000000001, -39.80000000000001, -55.599999999999994, -52.7, -45.900000000000006, -49.70000000000001, -43.900000000000006, -40.699999999999996, -44.699999999999996, -56.50000000000001, -40.80000000000001, -30.900000000000006, -75.00000000000001, -37.1, -48.5, -49.60000000000001, -46.60000000000001, -55.000000000000014, -43.5, -52.6, -54.0, -59.100000000000016, -59.400000000000006, -25.0, -43.300000000000004, -48.10000000000001, -46.0, -63.800000000000004, -43.60000000000001, -44.0, -49.2, -73.59999999999998, -39.7, -68.39999999999998, -51.900000000000006, -44.900000000000006, -54.900000000000006, -42.400000000000006, -28.299999999999997, -49.10000000000001, -34.3, -31.5, -51.90000000000002, -41.900000000000006, -63.8, -56.300000000000004, -43.199999999999996, -37.8, -65.39999999999999, -42.5, -30.0, -53.300000000000004], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13560343127060767, "mean_inference_ms": 1.2275286081747305, "mean_action_processing_ms": 0.05507926519475385, "mean_env_wait_ms": 2.2278318968908772, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 104000, "agent_timesteps_total": 104000, "timers": {"sample_time_ms": 7196.357, "sample_throughput": 555.837, "load_time_ms": 0.044, "load_throughput": 90248606.778, "learn_time_ms": 7326.612, "learn_throughput": 545.955, "update_time_ms": 1.503}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 210.76201491817352, "policy_loss": -0.033639212957613414, "vf_loss": 210.79339949084866, "vf_explained_var": [0.0524081215262413], "kl": 0.011276664697885928, "entropy": 1.346660078597325, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 104000, "num_agent_steps_sampled": 104000, "num_steps_trained": 104000, "num_agent_steps_trained": 104000}, "done": false, "episodes_total": 6932, "training_iteration": 26, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-17-01", "timestamp": 1632518221, "time_this_iter_s": 14.333061456680298, "time_total_s": 388.5482521057129, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 388.5482521057129, "timesteps_since_restore": 0, "iterations_since_restore": 26, "perf": {"cpu_util_percent": 34.919047619047625, "ram_util_percent": 15.899999999999997}}
{"episode_reward_max": -22.700000000000003, "episode_reward_min": -74.60000000000001, "episode_reward_mean": -44.89589552238807, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 268, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-29.700000000000003, -49.40000000000001, -39.3, -30.800000000000004, -43.7, -44.2, -45.000000000000014, -49.00000000000001, -29.0, -37.50000000000001, -38.50000000000001, -42.400000000000006, -60.000000000000014, -50.300000000000004, -40.900000000000006, -48.10000000000001, -40.3, -42.300000000000004, -36.0, -39.7, -33.800000000000004, -46.0, -41.1, -37.9, -53.100000000000016, -36.9, -43.900000000000006, -36.2, -29.400000000000002, -34.900000000000006, -34.30000000000001, -52.10000000000001, -38.9, -53.60000000000001, -39.1, -43.10000000000001, -38.8, -49.0, -42.9, -57.89999999999999, -42.0, -44.20000000000001, -41.3, -43.7, -43.40000000000001, -33.0, -48.2, -48.8, -42.0, -29.200000000000003, -35.00000000000001, -60.00000000000002, -39.8, -45.7, -35.9, -38.10000000000001, -52.30000000000001, -46.60000000000001, -61.7, -45.2, -55.300000000000004, -47.7, -46.00000000000001, -33.10000000000001, -48.90000000000001, -41.7, -54.0, -41.800000000000004, -49.9, -31.400000000000002, -35.7, -42.900000000000006, -44.50000000000001, -50.900000000000006, -43.2, -67.9, -43.400000000000006, -35.5, -40.5, -46.900000000000006, -55.00000000000001, -48.60000000000001, -47.100000000000016, -41.8, -38.40000000000001, -60.10000000000001, -35.60000000000001, -41.10000000000001, -51.900000000000006, -34.400000000000006, -51.60000000000001, -26.4, -47.10000000000001, -41.6, -42.6, -49.20000000000001, -53.7, -58.60000000000001, -60.60000000000001, -63.70000000000001, -45.4, -61.599999999999994, -26.700000000000003, -48.7, -45.10000000000001, -60.90000000000002, -30.500000000000007, -43.8, -53.300000000000004, -45.6, -26.200000000000003, -53.300000000000004, -39.699999999999996, -42.1, -28.9, -22.700000000000003, -46.900000000000006, -43.7, -40.8, -39.800000000000004, -46.500000000000014, -32.7, -41.6, -40.8, -31.899999999999995, -44.1, -59.90000000000001, -40.0, -43.1, -36.10000000000001, -63.3, -74.60000000000001, -45.800000000000004, -43.99999999999999, -40.7, -50.400000000000006, -56.400000000000006, -30.6, -26.8, -53.9, -34.400000000000006, -46.60000000000001, -46.1, -50.400000000000006, -46.70000000000001, -47.50000000000001, -35.5, -47.00000000000001, -41.5, -43.0, -50.000000000000014, -41.900000000000006, -34.5, -61.2, -55.7, -46.6, -51.900000000000006, -49.300000000000004, -27.1, -47.3, -45.2, -43.50000000000001, -46.3, -52.0, -49.70000000000001, -46.30000000000001, -41.00000000000001, -52.5, -64.4, -28.200000000000006, -58.300000000000004, -54.1, -39.6, -53.2, -56.1, -53.2, -55.90000000000001, -59.8, -47.4, -30.099999999999998, -63.300000000000004, -48.99999999999999, -40.30000000000001, -61.70000000000002, -56.30000000000002, -36.4, -39.30000000000001, -33.0, -35.6, -41.6, -31.900000000000006, -54.00000000000001, -38.30000000000001, -45.90000000000001, -46.1, -35.8, -51.10000000000001, -36.2, -59.20000000000001, -38.300000000000004, -51.89999999999998, -37.5, -55.40000000000001, -29.800000000000004, -44.199999999999996, -45.70000000000001, -42.900000000000006, -56.9, -41.8, -41.900000000000006, -43.40000000000001, -42.400000000000006, -32.9, -61.50000000000001, -43.79999999999999, -39.1, -46.2, -47.00000000000001, -44.10000000000001, -45.5, -27.5, -44.8, -49.400000000000006, -35.400000000000006, -39.300000000000004, -37.9, -39.300000000000004, -48.300000000000004, -43.7, -52.80000000000001, -66.0, -34.2, -24.700000000000003, -50.7, -57.800000000000004, -37.900000000000006, -61.49999999999999, -56.1, -66.5, -51.800000000000004, -51.3, -39.60000000000001, -39.2, -49.3, -44.300000000000004, -37.900000000000006, -51.800000000000004, -37.7, -39.1, -53.70000000000002, -40.9, -34.0, -41.80000000000001, -58.30000000000001, -57.1, -53.699999999999996, -31.400000000000002, -42.2, -54.5, -43.4, -54.20000000000002, -38.7, -36.7, -36.1, -63.800000000000004, -58.9, -46.400000000000006, -48.000000000000014], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13543555225319973, "mean_inference_ms": 1.226049639892098, "mean_action_processing_ms": 0.055010127892319995, "mean_env_wait_ms": 2.2241678752889635, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 108000, "agent_timesteps_total": 108000, "timers": {"sample_time_ms": 7169.96, "sample_throughput": 557.883, "load_time_ms": 0.044, "load_throughput": 90345805.062, "learn_time_ms": 7271.918, "learn_throughput": 550.061, "update_time_ms": 1.515}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 189.545630128922, "policy_loss": -0.03391626967838214, "vf_loss": 189.57701059977214, "vf_explained_var": [0.052181169390678406], "kl": 0.012684107179154596, "entropy": 1.3117138942082722, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 108000, "num_agent_steps_sampled": 108000, "num_steps_trained": 108000, "num_agent_steps_trained": 108000}, "done": false, "episodes_total": 7200, "training_iteration": 27, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-17-15", "timestamp": 1632518235, "time_this_iter_s": 14.097594022750854, "time_total_s": 402.64584612846375, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 402.64584612846375, "timesteps_since_restore": 0, "iterations_since_restore": 27, "perf": {"cpu_util_percent": 33.849999999999994, "ram_util_percent": 15.899999999999997}}
{"episode_reward_max": -20.200000000000003, "episode_reward_min": -77.19999999999999, "episode_reward_mean": -45.10639097744361, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-65.3, -38.300000000000004, -26.5, -43.50000000000001, -59.60000000000001, -39.30000000000001, -75.20000000000002, -48.7, -47.10000000000001, -60.099999999999994, -61.900000000000006, -47.60000000000001, -53.10000000000001, -53.300000000000004, -39.50000000000001, -45.2, -39.300000000000004, -43.70000000000001, -77.19999999999999, -51.10000000000001, -53.60000000000001, -51.8, -43.400000000000006, -33.300000000000004, -36.6, -71.9, -41.90000000000001, -52.60000000000001, -37.8, -55.900000000000006, -51.80000000000002, -28.700000000000003, -44.00000000000001, -43.4, -34.7, -45.60000000000001, -39.300000000000004, -38.6, -30.700000000000006, -38.60000000000001, -38.300000000000004, -56.19999999999999, -52.0, -51.1, -46.699999999999996, -39.6, -50.500000000000014, -31.900000000000006, -30.900000000000002, -52.000000000000014, -42.90000000000001, -36.6, -62.7, -30.5, -47.1, -39.0, -58.2, -68.30000000000001, -48.2, -44.1, -55.20000000000001, -56.00000000000001, -44.300000000000004, -49.400000000000006, -48.8, -47.800000000000004, -56.3, -39.7, -36.10000000000001, -31.5, -42.900000000000006, -49.600000000000016, -43.0, -43.0, -63.20000000000002, -46.5, -37.0, -51.8, -61.40000000000001, -42.00000000000001, -30.200000000000003, -45.6, -50.30000000000001, -37.60000000000001, -30.700000000000003, -41.2, -45.70000000000001, -28.6, -37.7, -40.7, -40.5, -66.00000000000001, -36.2, -52.400000000000006, -37.300000000000004, -40.800000000000004, -25.700000000000003, -37.7, -47.9, -22.500000000000004, -34.300000000000004, -43.800000000000004, -47.40000000000001, -39.60000000000001, -35.900000000000006, -39.2, -31.6, -43.20000000000001, -58.7, -52.400000000000006, -39.60000000000001, -65.50000000000001, -62.900000000000006, -28.500000000000004, -44.0, -53.900000000000006, -31.200000000000003, -43.10000000000001, -50.800000000000004, -43.10000000000001, -58.7, -36.1, -44.80000000000001, -45.6, -47.7, -46.80000000000002, -46.900000000000006, -45.699999999999996, -64.10000000000001, -56.4, -38.2, -59.60000000000001, -50.400000000000006, -58.70000000000002, -62.29999999999999, -39.800000000000004, -50.10000000000001, -31.5, -30.6, -51.20000000000001, -38.199999999999996, -49.00000000000001, -68.20000000000002, -44.800000000000004, -38.00000000000001, -58.2, -45.40000000000001, -39.300000000000004, -41.300000000000004, -46.2, -41.500000000000014, -44.3, -31.799999999999997, -46.00000000000001, -42.60000000000001, -41.400000000000006, -41.800000000000004, -60.1, -43.30000000000001, -35.00000000000001, -37.800000000000004, -47.30000000000001, -40.50000000000001, -49.9, -58.00000000000001, -47.900000000000006, -41.1, -29.6, -31.900000000000002, -63.00000000000002, -40.300000000000004, -38.400000000000006, -31.0, -54.800000000000004, -57.900000000000006, -49.50000000000001, -40.7, -27.7, -64.2, -20.200000000000003, -34.5, -48.000000000000014, -41.900000000000006, -35.5, -35.099999999999994, -73.9, -45.6, -35.5, -43.30000000000001, -29.9, -48.400000000000006, -43.8, -57.39999999999999, -35.2, -43.800000000000004, -52.400000000000006, -40.50000000000001, -46.800000000000004, -53.20000000000001, -58.50000000000001, -33.8, -33.2, -56.000000000000014, -35.6, -49.9, -52.000000000000014, -40.8, -42.3, -35.3, -43.10000000000001, -55.400000000000006, -37.9, -48.39999999999999, -45.50000000000001, -38.60000000000001, -43.4, -30.7, -44.4, -54.300000000000004, -61.900000000000006, -47.50000000000001, -57.7, -47.6, -40.400000000000006, -28.299999999999997, -27.5, -38.9, -44.4, -31.7, -39.1, -41.800000000000004, -57.7, -51.60000000000001, -37.00000000000001, -41.0, -48.300000000000004, -71.7, -49.70000000000001, -42.0, -30.599999999999998, -45.800000000000004, -29.8, -41.0, -51.6, -29.700000000000003, -62.8, -48.099999999999994, -61.80000000000001, -50.20000000000001, -42.7, -38.800000000000004, -58.1, -31.60000000000001, -51.20000000000001, -39.6, -37.099999999999994, -38.7, -45.400000000000006, -52.70000000000001, -33.1, -43.5, -45.70000000000001, -53.50000000000001, -34.7, -51.70000000000001, -39.9], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1353221340598031, "mean_inference_ms": 1.2249317819038776, "mean_action_processing_ms": 0.05495256190746929, "mean_env_wait_ms": 2.21987975984575, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 112000, "agent_timesteps_total": 112000, "timers": {"sample_time_ms": 7110.629, "sample_throughput": 562.538, "load_time_ms": 0.044, "load_throughput": 90884160.347, "learn_time_ms": 7199.476, "learn_throughput": 555.596, "update_time_ms": 1.517}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 188.7001678959016, "policy_loss": -0.027438011872131497, "vf_loss": 188.72581751013314, "vf_explained_var": [0.05962643027305603], "kl": 0.008942931869010112, "entropy": 1.3002480292832979, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 112000, "num_agent_steps_sampled": 112000, "num_steps_trained": 112000, "num_agent_steps_trained": 112000}, "done": false, "episodes_total": 7466, "training_iteration": 28, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-17-29", "timestamp": 1632518249, "time_this_iter_s": 14.311297178268433, "time_total_s": 416.9571433067322, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 416.9571433067322, "timesteps_since_restore": 0, "iterations_since_restore": 28, "perf": {"cpu_util_percent": 34.309999999999995, "ram_util_percent": 15.899999999999997}}
{"episode_reward_max": -19.2, "episode_reward_min": -96.39999999999992, "episode_reward_mean": -43.81353383458647, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-61.2, -41.70000000000001, -36.300000000000004, -39.2, -41.2, -66.19999999999999, -28.800000000000004, -46.900000000000006, -51.20000000000002, -43.5, -36.0, -49.500000000000014, -48.90000000000001, -38.10000000000001, -49.60000000000001, -32.3, -38.70000000000001, -42.10000000000001, -33.900000000000006, -54.7, -43.90000000000001, -37.599999999999994, -46.2, -46.800000000000004, -47.30000000000001, -43.60000000000001, -19.2, -38.1, -43.300000000000004, -57.99999999999999, -38.199999999999996, -36.5, -33.300000000000004, -71.5, -43.4, -43.6, -55.600000000000016, -45.10000000000001, -52.000000000000014, -23.900000000000002, -40.300000000000004, -40.9, -27.4, -44.50000000000001, -56.2, -33.800000000000004, -54.90000000000001, -39.8, -47.60000000000001, -48.50000000000001, -39.300000000000004, -34.800000000000004, -41.60000000000001, -37.400000000000006, -45.300000000000004, -27.900000000000006, -42.5, -44.50000000000001, -55.400000000000006, -36.400000000000006, -28.400000000000002, -46.40000000000001, -37.8, -50.2, -49.70000000000001, -48.300000000000004, -46.60000000000001, -54.20000000000002, -33.7, -42.5, -51.60000000000001, -56.00000000000001, -47.60000000000001, -38.00000000000001, -30.000000000000004, -36.400000000000006, -50.10000000000001, -45.300000000000004, -52.8, -43.00000000000001, -35.900000000000006, -46.8, -43.000000000000014, -40.50000000000001, -57.300000000000004, -48.10000000000001, -31.3, -61.6, -41.50000000000001, -32.3, -28.0, -49.900000000000006, -73.9, -39.1, -46.60000000000001, -39.7, -55.20000000000001, -35.5, -51.9, -55.09999999999999, -44.00000000000001, -30.200000000000003, -31.600000000000005, -39.3, -41.8, -60.39999999999999, -34.60000000000001, -54.20000000000001, -49.1, -31.400000000000002, -55.6, -37.49999999999999, -54.2, -32.4, -35.1, -58.30000000000001, -36.7, -53.800000000000004, -36.6, -41.2, -35.9, -29.100000000000005, -44.10000000000001, -32.400000000000006, -46.800000000000004, -41.7, -55.30000000000001, -37.00000000000001, -47.0, -33.00000000000001, -32.900000000000006, -54.400000000000006, -27.800000000000004, -41.1, -48.900000000000006, -33.0, -45.900000000000006, -31.599999999999998, -48.5, -41.2, -31.099999999999998, -52.199999999999996, -59.000000000000014, -47.0, -38.4, -29.500000000000004, -44.1, -40.199999999999996, -38.199999999999996, -50.60000000000001, -36.6, -37.7, -33.400000000000006, -34.8, -44.900000000000006, -34.800000000000004, -45.90000000000001, -54.400000000000006, -41.900000000000006, -50.60000000000001, -27.0, -55.70000000000001, -34.7, -60.40000000000001, -44.800000000000004, -38.4, -42.00000000000001, -46.5, -42.2, -41.400000000000006, -40.0, -42.1, -55.8, -33.7, -55.70000000000002, -47.1, -57.5, -50.400000000000006, -45.800000000000004, -96.39999999999992, -43.099999999999994, -39.9, -48.9, -46.800000000000004, -34.1, -43.900000000000006, -49.60000000000001, -34.800000000000004, -29.400000000000002, -42.400000000000006, -55.300000000000004, -48.400000000000006, -37.9, -55.80000000000001, -52.70000000000001, -42.90000000000001, -49.2, -43.6, -49.900000000000006, -41.400000000000006, -39.800000000000004, -35.900000000000006, -28.400000000000002, -43.8, -51.50000000000001, -39.800000000000004, -48.2, -46.6, -43.0, -61.500000000000014, -58.80000000000001, -44.1, -53.10000000000001, -53.2, -39.6, -47.2, -47.2, -48.99999999999999, -47.900000000000006, -43.2, -52.6, -43.2, -29.200000000000003, -45.3, -42.7, -51.4, -49.20000000000001, -33.0, -39.099999999999994, -50.199999999999996, -40.6, -49.70000000000001, -30.6, -47.00000000000001, -46.2, -32.1, -51.5, -36.6, -32.900000000000006, -40.40000000000001, -52.30000000000001, -38.599999999999994, -49.10000000000001, -32.6, -57.10000000000001, -27.400000000000002, -39.800000000000004, -56.10000000000001, -49.300000000000004, -47.699999999999996, -42.10000000000001, -33.4, -34.50000000000001, -42.400000000000006, -39.300000000000004, -41.10000000000001, -41.5, -34.900000000000006, -48.000000000000014, -42.7, -52.800000000000004, -52.20000000000001, -45.50000000000001, -61.000000000000014, -39.00000000000001, -42.300000000000004], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13513194575613693, "mean_inference_ms": 1.22361200348788, "mean_action_processing_ms": 0.05489021857745344, "mean_env_wait_ms": 2.2158596022836368, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 116000, "agent_timesteps_total": 116000, "timers": {"sample_time_ms": 7112.698, "sample_throughput": 562.375, "load_time_ms": 0.044, "load_throughput": 91279738.847, "learn_time_ms": 7067.573, "learn_throughput": 565.965, "update_time_ms": 1.485}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 179.39334877588416, "policy_loss": -0.03672318608670305, "vf_loss": 179.427607464534, "vf_explained_var": [0.06342637538909912], "kl": 0.012323151958777742, "entropy": 1.272065450811899, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 116000, "num_agent_steps_sampled": 116000, "num_steps_trained": 116000, "num_agent_steps_trained": 116000}, "done": false, "episodes_total": 7732, "training_iteration": 29, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-17-43", "timestamp": 1632518263, "time_this_iter_s": 14.013535499572754, "time_total_s": 430.97067880630493, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 430.97067880630493, "timesteps_since_restore": 0, "iterations_since_restore": 29, "perf": {"cpu_util_percent": 33.760000000000005, "ram_util_percent": 15.899999999999997}}
{"episode_reward_max": -23.700000000000003, "episode_reward_min": -82.9, "episode_reward_mean": -45.21305970149254, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 268, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-38.7, -41.1, -52.000000000000014, -47.199999999999996, -41.0, -40.6, -61.099999999999994, -41.3, -37.300000000000004, -40.400000000000006, -69.4, -42.1, -34.6, -49.00000000000001, -36.6, -42.599999999999994, -43.70000000000001, -44.7, -41.00000000000001, -48.699999999999996, -37.1, -48.800000000000004, -43.80000000000001, -36.1, -39.900000000000006, -51.20000000000001, -68.70000000000002, -54.300000000000004, -48.900000000000006, -45.00000000000001, -50.50000000000001, -54.89999999999999, -40.300000000000004, -50.1, -82.9, -44.50000000000001, -50.800000000000004, -31.400000000000006, -51.00000000000001, -41.300000000000004, -45.400000000000006, -29.400000000000006, -54.2, -32.699999999999996, -53.600000000000016, -34.1, -38.1, -56.00000000000001, -36.0, -46.2, -46.0, -47.800000000000004, -38.7, -33.7, -68.7, -39.0, -44.60000000000001, -37.5, -49.300000000000004, -39.300000000000004, -38.699999999999996, -27.3, -45.199999999999996, -46.00000000000001, -41.50000000000001, -57.800000000000004, -50.7, -48.50000000000001, -37.599999999999994, -36.2, -53.900000000000006, -35.0, -52.199999999999996, -40.8, -50.30000000000001, -35.099999999999994, -56.00000000000001, -31.8, -50.10000000000001, -41.10000000000001, -46.800000000000004, -37.3, -38.2, -48.80000000000001, -48.20000000000001, -34.60000000000001, -41.00000000000001, -35.00000000000001, -46.10000000000001, -45.50000000000001, -35.2, -34.8, -35.699999999999996, -40.6, -58.1, -53.60000000000001, -44.5, -53.60000000000001, -53.000000000000014, -35.2, -38.3, -46.10000000000001, -46.60000000000001, -52.7, -43.50000000000001, -62.000000000000014, -50.300000000000004, -61.70000000000001, -42.400000000000006, -40.90000000000001, -56.70000000000001, -64.50000000000001, -41.00000000000001, -42.80000000000001, -28.5, -70.10000000000001, -44.10000000000001, -50.300000000000004, -53.500000000000014, -33.300000000000004, -45.6, -44.50000000000001, -34.800000000000004, -39.6, -44.300000000000004, -44.20000000000001, -53.3, -42.00000000000001, -38.800000000000004, -31.799999999999997, -56.00000000000001, -54.70000000000001, -48.099999999999994, -59.80000000000001, -44.1, -34.400000000000006, -43.70000000000001, -55.20000000000001, -30.500000000000004, -42.40000000000001, -41.6, -55.30000000000001, -55.1, -45.9, -62.40000000000001, -38.5, -40.400000000000006, -25.900000000000002, -74.3, -47.6, -49.300000000000004, -41.7, -47.70000000000001, -43.70000000000001, -29.900000000000002, -53.7, -45.7, -54.50000000000001, -50.10000000000001, -51.199999999999996, -48.30000000000001, -53.300000000000004, -39.6, -73.19999999999999, -55.199999999999996, -38.6, -47.800000000000004, -45.90000000000001, -41.9, -37.4, -49.10000000000001, -46.300000000000004, -44.1, -40.7, -72.30000000000001, -48.900000000000006, -37.9, -53.300000000000004, -45.900000000000006, -45.70000000000002, -53.80000000000001, -30.100000000000005, -64.4, -46.70000000000001, -36.1, -42.2, -43.5, -59.30000000000001, -44.300000000000004, -34.4, -40.900000000000006, -47.2, -33.0, -62.000000000000014, -37.3, -34.2, -31.900000000000002, -44.400000000000006, -49.00000000000001, -29.4, -38.6, -47.1, -35.2, -41.50000000000001, -28.9, -42.50000000000001, -23.700000000000003, -44.20000000000001, -47.6, -47.7, -37.7, -46.60000000000001, -49.50000000000001, -43.3, -48.400000000000006, -45.6, -29.8, -48.1, -44.2, -34.6, -33.300000000000004, -51.1, -58.00000000000001, -51.30000000000002, -37.900000000000006, -53.5, -36.900000000000006, -48.2, -46.900000000000006, -36.400000000000006, -31.5, -35.800000000000004, -54.900000000000006, -57.00000000000001, -36.89999999999999, -30.300000000000004, -56.400000000000006, -39.70000000000001, -46.1, -34.1, -40.6, -49.4, -42.8, -40.6, -61.20000000000002, -56.10000000000001, -49.800000000000004, -38.300000000000004, -26.6, -46.9, -30.1, -63.50000000000001, -51.80000000000001, -38.900000000000006, -44.20000000000001, -27.700000000000003, -44.6, -48.300000000000004, -77.79999999999998, -41.1, -47.6, -40.2, -61.500000000000014, -35.2, -55.10000000000001, -56.00000000000001, -38.400000000000006, -44.2], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13517517461071182, "mean_inference_ms": 1.2239251652788459, "mean_action_processing_ms": 0.05492317929064993, "mean_env_wait_ms": 2.213474083013533, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 120000, "agent_timesteps_total": 120000, "timers": {"sample_time_ms": 7124.433, "sample_throughput": 561.448, "load_time_ms": 0.044, "load_throughput": 91829315.818, "learn_time_ms": 7065.126, "learn_throughput": 566.161, "update_time_ms": 1.49}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 189.24384457167758, "policy_loss": -0.03221270688458957, "vf_loss": 189.27363668462283, "vf_explained_var": [0.06297203153371811], "kl": 0.01210892468876931, "entropy": 1.2252181115970817, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 120000, "num_agent_steps_sampled": 120000, "num_steps_trained": 120000, "num_agent_steps_trained": 120000}, "done": false, "episodes_total": 8000, "training_iteration": 30, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-17-58", "timestamp": 1632518278, "time_this_iter_s": 14.418900489807129, "time_total_s": 445.38957929611206, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 445.38957929611206, "timesteps_since_restore": 0, "iterations_since_restore": 30, "perf": {"cpu_util_percent": 34.180952380952384, "ram_util_percent": 15.899999999999997}}
{"episode_reward_max": -20.099999999999998, "episode_reward_min": -74.0, "episode_reward_mean": -44.52894736842106, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-41.400000000000006, -39.300000000000004, -45.400000000000006, -43.3, -56.1, -46.099999999999994, -48.5, -32.0, -42.400000000000006, -43.5, -26.300000000000004, -45.50000000000001, -29.1, -29.700000000000003, -52.00000000000001, -32.4, -38.900000000000006, -47.90000000000001, -53.80000000000001, -47.6, -49.900000000000006, -41.599999999999994, -35.900000000000006, -40.900000000000006, -39.300000000000004, -44.800000000000004, -49.400000000000006, -42.50000000000001, -31.9, -48.7, -41.800000000000004, -38.7, -48.800000000000004, -36.8, -38.7, -42.3, -51.400000000000006, -50.70000000000001, -71.20000000000002, -44.9, -37.0, -42.2, -51.70000000000002, -37.2, -54.00000000000001, -35.2, -56.00000000000001, -47.10000000000001, -54.500000000000014, -55.000000000000014, -49.50000000000001, -42.800000000000004, -57.20000000000002, -41.70000000000001, -27.500000000000004, -49.3, -71.2, -49.60000000000001, -63.000000000000014, -36.9, -63.5, -33.800000000000004, -46.40000000000001, -48.7, -46.2, -53.70000000000002, -48.50000000000001, -48.60000000000001, -57.300000000000004, -43.3, -50.1, -35.4, -44.50000000000001, -30.5, -33.6, -48.10000000000001, -37.00000000000001, -66.10000000000001, -42.2, -42.80000000000001, -53.800000000000004, -45.900000000000006, -41.5, -51.1, -66.8, -36.7, -42.6, -33.300000000000004, -43.300000000000004, -48.2, -23.000000000000004, -41.800000000000004, -42.6, -50.400000000000006, -32.5, -45.7, -49.6, -31.700000000000003, -35.6, -26.900000000000006, -49.400000000000006, -41.3, -48.8, -31.800000000000004, -74.0, -33.300000000000004, -40.300000000000004, -34.00000000000001, -59.70000000000001, -47.9, -32.7, -27.8, -37.2, -37.800000000000004, -45.900000000000006, -50.10000000000001, -54.00000000000001, -47.10000000000001, -45.80000000000001, -66.2, -54.50000000000001, -62.3, -30.200000000000003, -56.6, -37.900000000000006, -38.2, -39.5, -42.60000000000001, -22.2, -36.800000000000004, -20.099999999999998, -43.400000000000006, -44.00000000000001, -54.400000000000006, -65.0, -44.1, -43.900000000000006, -24.1, -49.500000000000014, -46.00000000000001, -43.7, -49.800000000000004, -37.50000000000001, -55.7, -31.4, -36.900000000000006, -38.2, -57.80000000000001, -47.0, -57.30000000000001, -57.80000000000001, -50.60000000000001, -44.0, -63.900000000000006, -50.000000000000014, -41.3, -56.80000000000001, -44.500000000000014, -29.700000000000003, -45.800000000000004, -49.2, -54.099999999999994, -38.400000000000006, -46.400000000000006, -40.3, -37.60000000000001, -52.6, -38.00000000000001, -42.900000000000006, -48.2, -62.800000000000004, -50.8, -58.00000000000001, -45.30000000000001, -38.00000000000001, -39.699999999999996, -43.800000000000004, -24.1, -40.7, -40.800000000000004, -34.900000000000006, -38.2, -38.9, -36.89999999999999, -38.3, -42.4, -45.10000000000001, -34.300000000000004, -38.3, -73.1, -45.800000000000004, -24.400000000000002, -32.00000000000001, -35.400000000000006, -42.6, -43.900000000000006, -27.500000000000004, -57.90000000000001, -39.300000000000004, -65.1, -30.900000000000002, -53.10000000000001, -45.00000000000001, -62.30000000000002, -39.6, -37.40000000000001, -35.1, -49.000000000000014, -51.900000000000006, -47.400000000000006, -42.0, -48.00000000000001, -56.70000000000001, -53.100000000000016, -47.7, -33.099999999999994, -55.00000000000001, -42.70000000000001, -43.9, -47.400000000000006, -50.1, -40.400000000000006, -44.40000000000001, -48.400000000000006, -31.900000000000002, -58.2, -37.2, -71.10000000000001, -47.199999999999996, -68.60000000000002, -40.3, -42.0, -43.80000000000001, -42.4, -38.300000000000004, -41.1, -49.300000000000004, -50.500000000000014, -45.10000000000001, -39.699999999999996, -47.900000000000006, -49.50000000000001, -59.600000000000016, -41.0, -35.7, -37.4, -42.5, -41.400000000000006, -45.4, -29.900000000000002, -46.0, -56.20000000000002, -36.1, -47.0, -47.300000000000004, -45.400000000000006, -20.8, -43.699999999999996, -47.70000000000001, -37.00000000000001, -38.7, -34.5, -51.30000000000001, -45.1, -49.2, -37.7], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13508429033302768, "mean_inference_ms": 1.2230785971170384, "mean_action_processing_ms": 0.05487845145153063, "mean_env_wait_ms": 2.210313040499429, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 124000, "agent_timesteps_total": 124000, "timers": {"sample_time_ms": 7127.682, "sample_throughput": 561.192, "load_time_ms": 0.043, "load_throughput": 92131883.58, "learn_time_ms": 7092.563, "learn_throughput": 563.971, "update_time_ms": 1.516}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 182.31229736164053, "policy_loss": -0.033093822390962674, "vf_loss": 182.34293759253717, "vf_explained_var": [0.06484382599592209], "kl": 0.012271054187858087, "entropy": 1.2436227589525202, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 124000, "num_agent_steps_sampled": 124000, "num_steps_trained": 124000, "num_agent_steps_trained": 124000}, "done": false, "episodes_total": 8266, "training_iteration": 31, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-18-12", "timestamp": 1632518292, "time_this_iter_s": 14.37500524520874, "time_total_s": 459.7645845413208, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 459.7645845413208, "timesteps_since_restore": 0, "iterations_since_restore": 31, "perf": {"cpu_util_percent": 34.30476190476191, "ram_util_percent": 15.899999999999997}}
{"episode_reward_max": -25.800000000000004, "episode_reward_min": -70.1, "episode_reward_mean": -44.22706766917294, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-32.300000000000004, -33.199999999999996, -44.00000000000001, -33.800000000000004, -40.0, -45.800000000000004, -48.0, -56.8, -36.800000000000004, -45.1, -54.7, -44.4, -32.6, -34.6, -41.300000000000004, -45.60000000000001, -34.300000000000004, -35.400000000000006, -55.6, -43.0, -42.60000000000001, -38.9, -47.00000000000001, -39.7, -34.4, -53.70000000000001, -50.00000000000001, -39.0, -36.50000000000001, -54.2, -35.50000000000001, -43.3, -34.6, -37.3, -35.8, -39.6, -49.7, -50.8, -42.300000000000004, -50.6, -43.40000000000001, -45.800000000000004, -44.6, -53.30000000000001, -27.4, -48.50000000000001, -65.39999999999999, -47.80000000000001, -37.0, -42.1, -43.900000000000006, -37.2, -49.70000000000001, -41.9, -28.400000000000002, -37.7, -43.300000000000004, -30.6, -44.2, -40.6, -39.300000000000004, -45.50000000000001, -52.1, -32.10000000000001, -50.3, -45.5, -42.5, -37.70000000000001, -37.800000000000004, -38.3, -32.8, -36.2, -42.0, -46.400000000000006, -35.8, -38.70000000000001, -35.2, -46.5, -34.50000000000001, -35.3, -39.0, -63.20000000000001, -44.60000000000001, -46.800000000000004, -63.900000000000006, -49.20000000000001, -38.400000000000006, -45.10000000000001, -45.2, -48.40000000000001, -45.900000000000006, -40.5, -42.9, -46.60000000000001, -58.0, -33.699999999999996, -26.8, -40.90000000000001, -43.300000000000004, -41.800000000000004, -40.4, -43.400000000000006, -29.900000000000006, -29.6, -44.60000000000001, -50.300000000000004, -53.20000000000002, -33.300000000000004, -51.80000000000001, -53.2, -37.400000000000006, -38.800000000000004, -41.00000000000001, -37.2, -61.50000000000001, -38.80000000000001, -52.9, -55.00000000000001, -42.9, -53.0, -31.900000000000002, -64.8, -49.600000000000016, -53.20000000000001, -47.60000000000001, -41.400000000000006, -56.000000000000014, -43.00000000000001, -55.500000000000014, -47.20000000000001, -56.10000000000001, -39.50000000000001, -29.3, -56.20000000000001, -37.3, -63.600000000000016, -48.90000000000001, -31.700000000000003, -52.500000000000014, -39.9, -51.0, -33.6, -42.400000000000006, -37.900000000000006, -50.20000000000001, -38.400000000000006, -33.7, -33.6, -53.600000000000016, -48.400000000000006, -32.4, -37.5, -34.900000000000006, -45.199999999999996, -45.0, -41.9, -33.6, -51.5, -49.60000000000001, -31.100000000000005, -44.800000000000004, -51.400000000000006, -46.900000000000006, -35.400000000000006, -34.70000000000001, -36.7, -48.4, -31.800000000000004, -56.80000000000002, -48.4, -49.900000000000006, -52.7, -37.300000000000004, -37.300000000000004, -56.30000000000001, -41.699999999999996, -50.400000000000006, -65.20000000000002, -36.900000000000006, -49.2, -50.300000000000004, -49.7, -56.00000000000001, -40.7, -48.500000000000014, -56.4, -32.00000000000001, -50.70000000000001, -37.300000000000004, -46.60000000000001, -50.5, -53.20000000000001, -54.5, -41.00000000000001, -33.7, -39.5, -50.900000000000006, -25.800000000000004, -39.4, -42.1, -38.199999999999996, -43.00000000000001, -49.300000000000004, -36.2, -38.300000000000004, -29.800000000000004, -40.50000000000001, -52.70000000000001, -61.100000000000016, -40.6, -48.800000000000004, -48.9, -55.50000000000001, -48.00000000000001, -41.400000000000006, -48.50000000000001, -44.10000000000001, -57.2, -57.50000000000001, -45.00000000000001, -38.300000000000004, -46.30000000000001, -33.9, -55.5, -39.4, -42.400000000000006, -50.40000000000001, -50.900000000000006, -45.000000000000014, -48.5, -43.60000000000001, -48.30000000000001, -40.5, -64.00000000000001, -44.800000000000004, -38.400000000000006, -47.400000000000006, -59.90000000000001, -55.4, -50.80000000000001, -57.40000000000001, -47.2, -49.00000000000001, -43.4, -37.50000000000001, -37.1, -45.20000000000001, -47.4, -31.5, -44.00000000000001, -70.1, -31.6, -32.50000000000001, -47.400000000000006, -43.10000000000001, -46.2, -31.900000000000006, -49.60000000000001, -53.70000000000001, -62.10000000000001, -30.699999999999996, -44.9, -41.70000000000001, -54.0, -45.900000000000006, -46.800000000000004], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13488484826662162, "mean_inference_ms": 1.221759546805344, "mean_action_processing_ms": 0.05482477898974041, "mean_env_wait_ms": 2.207548593618361, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 128000, "agent_timesteps_total": 128000, "timers": {"sample_time_ms": 7113.454, "sample_throughput": 562.315, "load_time_ms": 0.044, "load_throughput": 91578689.956, "learn_time_ms": 7108.366, "learn_throughput": 562.717, "update_time_ms": 1.486}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 176.74285380045572, "policy_loss": -0.03138910841837685, "vf_loss": 176.77233738232684, "vf_explained_var": [0.053307998925447464], "kl": 0.00952718939049939, "entropy": 1.1915633995045898, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 128000, "num_agent_steps_sampled": 128000, "num_steps_trained": 128000, "num_agent_steps_trained": 128000}, "done": false, "episodes_total": 8532, "training_iteration": 32, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-18-27", "timestamp": 1632518307, "time_this_iter_s": 14.186825513839722, "time_total_s": 473.9514100551605, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 473.9514100551605, "timesteps_since_restore": 0, "iterations_since_restore": 32, "perf": {"cpu_util_percent": 34.07, "ram_util_percent": 15.899999999999997}}
{"episode_reward_max": -22.200000000000003, "episode_reward_min": -80.69999999999999, "episode_reward_mean": -43.88619402985075, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 268, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-35.50000000000001, -52.500000000000014, -40.300000000000004, -38.300000000000004, -53.1, -44.60000000000001, -58.999999999999986, -44.300000000000004, -43.2, -31.0, -37.300000000000004, -43.7, -39.50000000000001, -41.90000000000001, -50.10000000000001, -51.5, -42.800000000000004, -59.10000000000001, -54.80000000000001, -31.000000000000004, -39.3, -41.10000000000001, -27.700000000000003, -34.7, -48.60000000000001, -48.400000000000006, -34.3, -26.0, -49.60000000000001, -48.70000000000001, -50.50000000000001, -22.400000000000002, -51.20000000000001, -65.60000000000001, -40.4, -37.2, -48.70000000000001, -52.30000000000001, -52.400000000000006, -52.00000000000001, -40.1, -35.900000000000006, -56.40000000000002, -37.0, -43.00000000000001, -55.50000000000001, -42.099999999999994, -23.8, -24.5, -45.2, -55.100000000000016, -49.400000000000006, -63.900000000000006, -80.69999999999999, -40.900000000000006, -33.900000000000006, -50.10000000000001, -45.800000000000004, -46.30000000000001, -40.1, -44.0, -46.4, -37.80000000000001, -50.4, -50.60000000000001, -37.2, -33.1, -37.400000000000006, -33.50000000000001, -50.9, -65.60000000000001, -38.800000000000004, -50.2, -36.400000000000006, -33.8, -54.00000000000001, -49.60000000000001, -42.0, -33.9, -47.3, -35.9, -26.4, -38.0, -35.400000000000006, -31.3, -35.00000000000001, -30.9, -55.70000000000001, -45.900000000000006, -47.10000000000001, -36.5, -39.900000000000006, -44.60000000000001, -32.400000000000006, -28.3, -32.50000000000001, -32.8, -32.800000000000004, -48.20000000000002, -57.10000000000001, -61.900000000000006, -41.300000000000004, -41.5, -45.400000000000006, -41.800000000000004, -43.0, -36.2, -37.0, -46.000000000000014, -49.0, -46.10000000000001, -42.2, -55.90000000000001, -40.50000000000001, -38.7, -44.8, -41.0, -45.50000000000001, -30.9, -38.70000000000001, -47.900000000000006, -35.90000000000001, -39.8, -60.2, -42.1, -36.0, -32.9, -51.400000000000006, -39.099999999999994, -58.00000000000001, -52.30000000000002, -38.2, -45.5, -51.20000000000002, -41.1, -38.0, -40.0, -43.00000000000001, -33.6, -49.2, -53.70000000000001, -57.400000000000006, -35.800000000000004, -43.900000000000006, -37.800000000000004, -41.50000000000001, -47.400000000000006, -34.5, -66.0, -43.20000000000001, -35.1, -42.400000000000006, -35.699999999999996, -52.400000000000006, -47.5, -38.800000000000004, -57.900000000000006, -51.70000000000001, -48.600000000000016, -38.2, -39.6, -32.099999999999994, -40.800000000000004, -52.20000000000001, -52.300000000000004, -43.70000000000001, -46.50000000000001, -48.0, -43.2, -53.50000000000001, -49.50000000000001, -42.49999999999999, -49.900000000000006, -33.9, -43.70000000000001, -52.60000000000001, -44.900000000000006, -29.0, -45.0, -32.7, -44.80000000000001, -47.2, -46.400000000000006, -46.2, -66.5, -26.5, -62.199999999999996, -55.699999999999996, -31.2, -34.8, -38.8, -45.400000000000006, -47.70000000000001, -54.900000000000006, -43.1, -41.50000000000001, -44.8, -39.20000000000001, -35.900000000000006, -36.1, -42.10000000000001, -55.900000000000006, -34.400000000000006, -41.20000000000001, -38.900000000000006, -38.800000000000004, -50.400000000000006, -29.200000000000003, -41.1, -60.6, -44.400000000000006, -36.6, -41.80000000000001, -53.400000000000006, -27.3, -43.1, -40.20000000000001, -36.70000000000001, -47.10000000000001, -44.50000000000001, -27.4, -37.8, -36.300000000000004, -49.300000000000004, -56.80000000000001, -33.300000000000004, -59.400000000000006, -50.500000000000014, -48.50000000000001, -61.10000000000001, -48.0, -49.20000000000001, -49.5, -40.300000000000004, -58.49999999999999, -66.5, -42.6, -43.50000000000001, -35.400000000000006, -48.2, -68.50000000000001, -41.6, -37.20000000000001, -37.7, -48.9, -34.9, -57.400000000000006, -34.900000000000006, -33.3, -56.6, -38.400000000000006, -45.39999999999999, -44.99999999999999, -57.699999999999996, -45.400000000000006, -28.200000000000003, -47.000000000000014, -63.50000000000001, -27.5, -39.5, -22.200000000000003, -74.30000000000001, -46.6, -44.2, -42.90000000000001, -41.2, -44.300000000000004, -36.7], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13468008370394488, "mean_inference_ms": 1.220143241767885, "mean_action_processing_ms": 0.05475428373123199, "mean_env_wait_ms": 2.2038755264284537, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 132000, "agent_timesteps_total": 132000, "timers": {"sample_time_ms": 7104.02, "sample_throughput": 563.061, "load_time_ms": 0.044, "load_throughput": 91528728.86, "learn_time_ms": 7090.296, "learn_throughput": 564.151, "update_time_ms": 1.463}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 178.84077632452852, "policy_loss": -0.0327339404112389, "vf_loss": 178.87127810242356, "vf_explained_var": [0.05974206328392029], "kl": 0.011158295010424184, "entropy": 1.1968790022275781, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 132000, "num_agent_steps_sampled": 132000, "num_steps_trained": 132000, "num_agent_steps_trained": 132000}, "done": false, "episodes_total": 8800, "training_iteration": 33, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-18-41", "timestamp": 1632518321, "time_this_iter_s": 14.00279188156128, "time_total_s": 487.9542019367218, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 487.9542019367218, "timesteps_since_restore": 0, "iterations_since_restore": 33, "perf": {"cpu_util_percent": 34.335, "ram_util_percent": 15.899999999999997}}
{"episode_reward_max": -22.0, "episode_reward_min": -76.90000000000002, "episode_reward_mean": -44.03082706766918, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-41.1, -49.10000000000001, -32.0, -27.0, -45.500000000000014, -38.4, -43.80000000000001, -39.6, -46.1, -46.20000000000001, -40.6, -50.199999999999996, -64.00000000000001, -51.60000000000001, -43.0, -27.7, -53.90000000000001, -48.7, -34.900000000000006, -40.7, -49.900000000000006, -45.6, -61.30000000000001, -33.400000000000006, -43.599999999999994, -74.10000000000004, -28.300000000000004, -48.6, -38.50000000000001, -48.60000000000001, -32.5, -46.00000000000001, -22.0, -45.2, -42.7, -39.8, -42.1, -31.9, -34.7, -46.50000000000001, -39.4, -57.00000000000002, -30.300000000000004, -39.6, -40.900000000000006, -35.400000000000006, -38.30000000000001, -39.50000000000001, -38.5, -47.4, -48.60000000000001, -47.50000000000001, -33.10000000000001, -25.6, -38.9, -43.4, -31.300000000000004, -40.0, -30.2, -30.000000000000004, -45.20000000000001, -45.00000000000001, -50.2, -35.400000000000006, -43.900000000000006, -34.0, -34.5, -34.7, -42.9, -43.7, -43.70000000000001, -50.800000000000004, -58.800000000000004, -58.400000000000006, -51.70000000000001, -68.40000000000002, -53.3, -40.6, -44.800000000000004, -53.7, -46.60000000000001, -41.30000000000001, -46.60000000000001, -35.800000000000004, -53.10000000000001, -39.6, -64.10000000000001, -48.50000000000001, -42.9, -45.10000000000001, -37.1, -37.0, -34.2, -43.2, -43.400000000000006, -38.60000000000001, -43.9, -35.1, -47.00000000000001, -45.30000000000001, -50.400000000000006, -45.7, -54.100000000000016, -65.89999999999999, -37.5, -64.29999999999998, -44.6, -49.60000000000001, -28.700000000000003, -30.000000000000004, -41.800000000000004, -41.900000000000006, -75.70000000000002, -25.0, -25.900000000000002, -38.5, -39.80000000000001, -47.400000000000006, -36.8, -55.900000000000006, -54.9, -31.500000000000004, -34.800000000000004, -40.5, -51.60000000000001, -32.50000000000001, -53.70000000000001, -70.80000000000001, -38.60000000000001, -64.9, -43.900000000000006, -29.400000000000006, -48.70000000000001, -43.6, -45.1, -33.400000000000006, -42.20000000000001, -40.00000000000001, -57.800000000000004, -35.2, -37.0, -30.900000000000006, -60.40000000000001, -37.50000000000001, -60.00000000000001, -36.00000000000001, -52.90000000000001, -54.70000000000001, -49.9, -53.7, -30.8, -40.6, -27.6, -56.80000000000002, -40.00000000000001, -52.30000000000001, -43.199999999999996, -36.900000000000006, -41.60000000000001, -51.6, -52.30000000000001, -47.6, -56.199999999999996, -60.60000000000002, -53.4, -42.6, -35.8, -33.2, -42.400000000000006, -39.400000000000006, -35.2, -53.7, -31.400000000000006, -45.9, -26.6, -66.10000000000002, -47.300000000000004, -42.800000000000004, -38.99999999999999, -49.50000000000001, -46.400000000000006, -48.1, -49.5, -33.900000000000006, -30.000000000000004, -44.0, -42.7, -40.300000000000004, -42.6, -55.20000000000001, -49.80000000000001, -41.400000000000006, -45.20000000000001, -52.30000000000001, -48.300000000000004, -46.80000000000001, -31.1, -62.5, -27.3, -50.1, -25.799999999999997, -37.3, -40.099999999999994, -40.50000000000001, -43.300000000000004, -40.30000000000001, -40.7, -53.9, -42.800000000000004, -52.10000000000001, -34.699999999999996, -54.50000000000001, -55.400000000000006, -30.1, -48.30000000000001, -47.40000000000001, -49.2, -59.199999999999996, -55.000000000000014, -39.90000000000001, -25.1, -76.90000000000002, -49.0, -36.2, -32.300000000000004, -45.10000000000001, -54.30000000000001, -44.60000000000001, -34.1, -29.8, -32.0, -55.10000000000001, -42.7, -52.00000000000001, -46.2, -48.800000000000004, -47.2, -41.900000000000006, -51.00000000000001, -52.7, -41.800000000000004, -36.50000000000001, -66.99999999999999, -43.8, -44.80000000000001, -41.10000000000001, -46.6, -47.70000000000001, -57.30000000000001, -40.00000000000001, -54.00000000000001, -39.800000000000004, -40.199999999999996, -33.10000000000001, -29.200000000000003, -33.7, -46.0, -28.1, -36.900000000000006, -56.80000000000001, -47.6, -49.60000000000001, -53.60000000000001, -47.60000000000001, -50.10000000000001, -39.9], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13457874002124423, "mean_inference_ms": 1.219402718033167, "mean_action_processing_ms": 0.05472312069849394, "mean_env_wait_ms": 2.200823920879032, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 136000, "agent_timesteps_total": 136000, "timers": {"sample_time_ms": 7088.619, "sample_throughput": 564.285, "load_time_ms": 0.044, "load_throughput": 91628705.625, "learn_time_ms": 7135.711, "learn_throughput": 560.561, "update_time_ms": 1.479}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 181.39354899416688, "policy_loss": -0.02933690439889668, "vf_loss": 181.4208742859543, "vf_explained_var": [0.06761429458856583], "kl": 0.010060620014425708, "entropy": 1.1766582347372527, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 136000, "num_agent_steps_sampled": 136000, "num_steps_trained": 136000, "num_agent_steps_trained": 136000}, "done": false, "episodes_total": 9066, "training_iteration": 34, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-18-55", "timestamp": 1632518335, "time_this_iter_s": 14.430522203445435, "time_total_s": 502.38472414016724, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 502.38472414016724, "timesteps_since_restore": 0, "iterations_since_restore": 34, "perf": {"cpu_util_percent": 35.480952380952374, "ram_util_percent": 15.899999999999997}}
{"episode_reward_max": -22.0, "episode_reward_min": -77.7, "episode_reward_mean": -43.72969924812031, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-59.40000000000001, -45.900000000000006, -49.00000000000001, -49.9, -50.60000000000001, -33.6, -32.3, -55.500000000000014, -43.900000000000006, -35.9, -44.300000000000004, -32.7, -49.90000000000001, -47.199999999999996, -71.5, -39.7, -22.0, -55.69999999999999, -40.0, -52.7, -42.1, -35.800000000000004, -70.8, -42.3, -29.1, -35.5, -37.900000000000006, -54.3, -45.5, -46.300000000000004, -36.2, -52.400000000000006, -57.300000000000004, -42.6, -36.7, -51.70000000000001, -42.800000000000004, -55.30000000000001, -46.300000000000004, -42.30000000000001, -44.2, -48.300000000000004, -31.3, -41.10000000000001, -41.60000000000001, -42.4, -44.50000000000001, -51.70000000000001, -38.1, -45.00000000000001, -31.6, -48.300000000000004, -40.900000000000006, -37.800000000000004, -37.0, -51.300000000000004, -32.4, -41.900000000000006, -51.800000000000004, -50.300000000000004, -53.400000000000006, -48.00000000000001, -41.2, -38.900000000000006, -36.9, -32.0, -37.6, -31.4, -27.200000000000003, -48.900000000000006, -33.400000000000006, -40.1, -31.800000000000004, -49.1, -36.2, -35.800000000000004, -44.800000000000004, -38.2, -36.7, -59.3, -57.400000000000006, -42.900000000000006, -53.30000000000001, -31.200000000000003, -41.0, -63.80000000000001, -26.1, -49.0, -48.50000000000001, -49.900000000000006, -41.4, -34.00000000000001, -45.00000000000001, -35.5, -48.60000000000001, -43.60000000000001, -61.40000000000001, -47.0, -52.40000000000001, -29.2, -50.60000000000001, -34.70000000000001, -68.3, -29.700000000000006, -52.60000000000001, -46.50000000000001, -61.0, -51.4, -27.900000000000002, -35.0, -32.6, -39.400000000000006, -47.00000000000002, -43.900000000000006, -43.300000000000004, -48.100000000000016, -39.5, -32.300000000000004, -36.60000000000001, -40.000000000000014, -43.900000000000006, -47.300000000000004, -65.00000000000001, -24.1, -35.00000000000001, -38.7, -39.7, -56.20000000000001, -53.70000000000001, -42.800000000000004, -54.699999999999996, -39.1, -48.70000000000001, -46.3, -44.400000000000006, -43.9, -54.6, -58.100000000000016, -37.7, -31.300000000000004, -33.0, -34.50000000000001, -38.9, -41.80000000000001, -42.10000000000001, -38.3, -31.900000000000002, -37.4, -43.6, -42.50000000000001, -32.1, -46.800000000000004, -65.80000000000003, -57.50000000000001, -44.3, -35.1, -52.400000000000006, -47.2, -51.500000000000014, -44.8, -45.7, -31.200000000000006, -51.800000000000004, -36.400000000000006, -60.20000000000001, -40.00000000000001, -46.00000000000001, -51.70000000000001, -29.9, -30.0, -40.900000000000006, -31.400000000000002, -26.499999999999996, -41.2, -29.1, -32.1, -38.2, -37.0, -33.9, -50.60000000000001, -40.0, -36.4, -23.200000000000003, -49.10000000000001, -31.7, -44.50000000000001, -45.60000000000001, -48.7, -44.80000000000001, -35.7, -28.900000000000002, -39.800000000000004, -43.6, -43.2, -40.0, -35.30000000000001, -44.50000000000001, -49.8, -40.800000000000004, -36.300000000000004, -36.7, -45.10000000000001, -49.699999999999996, -43.80000000000001, -44.50000000000001, -49.40000000000001, -40.900000000000006, -38.5, -35.900000000000006, -47.20000000000001, -46.0, -31.200000000000003, -46.900000000000006, -43.5, -42.70000000000001, -40.40000000000001, -54.400000000000006, -45.30000000000001, -50.800000000000004, -48.60000000000001, -39.500000000000014, -52.1, -62.20000000000001, -47.7, -51.80000000000001, -53.0, -37.800000000000004, -44.400000000000006, -34.7, -47.5, -41.1, -66.4, -47.7, -33.5, -49.400000000000006, -33.9, -40.599999999999994, -52.000000000000014, -60.0, -41.20000000000001, -47.10000000000001, -59.300000000000004, -56.300000000000004, -51.100000000000016, -45.00000000000001, -48.9, -40.6, -37.4, -43.60000000000001, -52.800000000000004, -50.30000000000001, -45.800000000000004, -48.9, -77.7, -56.80000000000001, -29.3, -43.3, -41.9, -48.10000000000001, -46.10000000000001, -43.199999999999996, -32.300000000000004, -64.89999999999999, -46.7, -46.0, -29.400000000000002], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1344114686333774, "mean_inference_ms": 1.2181276519036872, "mean_action_processing_ms": 0.054665710978473184, "mean_env_wait_ms": 2.197298911164106, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 140000, "agent_timesteps_total": 140000, "timers": {"sample_time_ms": 7083.867, "sample_throughput": 564.663, "load_time_ms": 0.044, "load_throughput": 90638660.184, "learn_time_ms": 7122.142, "learn_throughput": 561.629, "update_time_ms": 1.458}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 172.51774935978716, "policy_loss": -0.02907291888709991, "vf_loss": 172.54482096190094, "vf_explained_var": [0.040568411350250244], "kl": 0.01000604758650412, "entropy": 1.1625994973285223, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 140000, "num_agent_steps_sampled": 140000, "num_steps_trained": 140000, "num_agent_steps_trained": 140000}, "done": false, "episodes_total": 9332, "training_iteration": 35, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-19-09", "timestamp": 1632518349, "time_this_iter_s": 13.988686561584473, "time_total_s": 516.3734107017517, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 516.3734107017517, "timesteps_since_restore": 0, "iterations_since_restore": 35, "perf": {"cpu_util_percent": 34.155, "ram_util_percent": 15.899999999999997}}
{"episode_reward_max": -20.0, "episode_reward_min": -76.2, "episode_reward_mean": -43.09440298507462, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 268, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-54.900000000000006, -48.400000000000006, -35.10000000000001, -28.900000000000006, -37.800000000000004, -50.60000000000001, -40.6, -41.60000000000001, -37.50000000000001, -64.8, -57.300000000000004, -46.2, -37.099999999999994, -30.200000000000003, -32.7, -34.00000000000001, -49.6, -55.50000000000001, -38.00000000000001, -41.20000000000001, -31.6, -47.6, -73.5, -48.80000000000001, -37.2, -44.4, -29.8, -47.4, -35.3, -29.1, -36.6, -56.70000000000001, -33.10000000000001, -43.900000000000006, -56.20000000000001, -45.2, -35.7, -49.00000000000001, -43.1, -39.6, -44.10000000000001, -41.300000000000004, -40.7, -38.80000000000001, -50.7, -41.7, -42.50000000000001, -46.3, -47.900000000000006, -26.6, -36.6, -36.800000000000004, -39.50000000000001, -38.2, -44.50000000000001, -43.800000000000004, -35.1, -44.900000000000006, -38.8, -41.60000000000001, -57.20000000000001, -38.800000000000004, -47.10000000000001, -48.2, -60.90000000000001, -51.400000000000006, -53.20000000000001, -26.7, -42.60000000000001, -45.7, -51.60000000000001, -50.89999999999999, -47.300000000000004, -38.400000000000006, -42.20000000000001, -53.4, -46.90000000000001, -46.5, -35.699999999999996, -43.599999999999994, -38.10000000000001, -44.70000000000002, -40.900000000000006, -22.400000000000002, -38.00000000000001, -32.7, -55.000000000000014, -37.2, -45.80000000000001, -34.9, -37.0, -49.50000000000001, -62.500000000000014, -44.800000000000004, -56.10000000000001, -34.300000000000004, -43.800000000000004, -35.3, -54.90000000000001, -40.4, -48.300000000000004, -56.900000000000006, -42.0, -38.2, -27.0, -43.8, -38.2, -48.60000000000001, -40.7, -50.6, -37.900000000000006, -40.50000000000001, -41.60000000000001, -24.3, -35.0, -43.1, -55.900000000000006, -50.6, -42.4, -37.7, -35.1, -52.10000000000001, -46.40000000000001, -47.400000000000006, -38.5, -38.10000000000001, -46.2, -64.69999999999999, -58.40000000000001, -41.60000000000001, -38.3, -36.300000000000004, -50.70000000000001, -29.8, -42.300000000000004, -41.7, -36.800000000000004, -44.10000000000001, -42.800000000000004, -30.400000000000006, -33.4, -54.400000000000006, -51.1, -61.59999999999998, -48.400000000000006, -39.199999999999996, -36.7, -38.4, -57.00000000000001, -54.1, -44.0, -38.60000000000001, -37.6, -45.20000000000001, -49.6, -32.199999999999996, -43.900000000000006, -38.0, -42.400000000000006, -44.900000000000006, -55.3, -51.900000000000006, -48.4, -27.900000000000002, -30.0, -25.0, -52.7, -41.8, -52.70000000000001, -39.400000000000006, -30.199999999999996, -39.099999999999994, -39.7, -36.400000000000006, -42.300000000000004, -41.00000000000001, -46.5, -44.50000000000001, -42.5, -36.5, -38.00000000000001, -44.50000000000001, -46.6, -45.400000000000006, -42.90000000000002, -34.3, -52.60000000000001, -42.80000000000001, -50.80000000000001, -65.0, -44.300000000000004, -42.80000000000001, -44.600000000000016, -50.50000000000001, -76.2, -45.6, -38.90000000000001, -40.6, -56.20000000000002, -29.1, -52.70000000000001, -44.5, -39.80000000000001, -43.60000000000001, -42.900000000000006, -41.199999999999996, -41.900000000000006, -44.6, -43.300000000000004, -35.3, -46.3, -21.1, -37.6, -43.2, -50.60000000000001, -31.599999999999994, -45.0, -43.0, -42.8, -48.400000000000006, -45.1, -31.400000000000002, -47.80000000000001, -38.7, -29.5, -38.2, -30.200000000000003, -28.1, -48.70000000000001, -38.8, -49.0, -52.900000000000006, -52.2, -71.80000000000001, -46.9, -52.1, -33.800000000000004, -40.5, -32.400000000000006, -35.70000000000001, -55.6, -41.80000000000001, -56.70000000000002, -55.2, -20.0, -58.80000000000001, -43.60000000000001, -36.300000000000004, -58.300000000000004, -32.6, -63.30000000000001, -39.5, -32.5, -44.30000000000001, -54.50000000000001, -45.80000000000001, -50.80000000000001, -46.50000000000001, -30.2, -30.700000000000003, -32.1, -36.8, -29.800000000000004, -40.400000000000006, -39.300000000000004, -38.3, -37.7, -40.7], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13427901530593297, "mean_inference_ms": 1.2169906284124958, "mean_action_processing_ms": 0.05461813315731164, "mean_env_wait_ms": 2.1939984136279347, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 144000, "agent_timesteps_total": 144000, "timers": {"sample_time_ms": 7064.336, "sample_throughput": 566.224, "load_time_ms": 0.044, "load_throughput": 91081520.087, "learn_time_ms": 7164.337, "learn_throughput": 558.321, "update_time_ms": 1.472}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 164.76916837794806, "policy_loss": -0.030713675349389995, "vf_loss": 164.79768564367808, "vf_explained_var": [0.07820863276720047], "kl": 0.010982555930004863, "entropy": 1.1400647626128249, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 144000, "num_agent_steps_sampled": 144000, "num_steps_trained": 144000, "num_agent_steps_trained": 144000}, "done": false, "episodes_total": 9600, "training_iteration": 36, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-19-24", "timestamp": 1632518364, "time_this_iter_s": 14.559707164764404, "time_total_s": 530.9331178665161, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 530.9331178665161, "timesteps_since_restore": 0, "iterations_since_restore": 36, "perf": {"cpu_util_percent": 34.285000000000004, "ram_util_percent": 15.940000000000001}}
{"episode_reward_max": -18.7, "episode_reward_min": -73.9, "episode_reward_mean": -44.27067669172932, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-53.000000000000014, -49.5, -57.699999999999996, -37.1, -40.3, -21.500000000000004, -48.50000000000001, -46.2, -37.400000000000006, -27.6, -48.50000000000001, -49.80000000000001, -39.400000000000006, -47.50000000000001, -57.900000000000006, -59.5, -39.9, -30.9, -53.0, -48.199999999999996, -32.199999999999996, -50.70000000000001, -32.6, -44.7, -40.900000000000006, -41.00000000000001, -44.2, -42.0, -33.0, -60.20000000000001, -49.50000000000001, -48.400000000000006, -51.80000000000001, -35.2, -43.10000000000001, -42.300000000000004, -50.70000000000001, -43.50000000000001, -61.599999999999994, -36.7, -66.30000000000001, -41.8, -58.1, -51.6, -58.30000000000001, -51.300000000000004, -50.300000000000004, -47.300000000000004, -31.000000000000004, -49.50000000000001, -57.400000000000006, -32.9, -49.2, -38.50000000000001, -46.800000000000004, -38.1, -59.1, -30.4, -45.20000000000002, -47.300000000000004, -40.400000000000006, -41.2, -35.80000000000001, -26.400000000000002, -34.900000000000006, -59.30000000000001, -46.300000000000004, -69.30000000000001, -52.7, -51.40000000000001, -34.7, -42.5, -40.7, -36.599999999999994, -44.900000000000006, -40.7, -43.50000000000001, -54.70000000000001, -52.400000000000006, -59.2, -49.400000000000006, -37.1, -49.50000000000001, -58.1, -43.00000000000001, -33.1, -28.4, -42.300000000000004, -38.80000000000001, -40.6, -71.00000000000001, -43.7, -55.300000000000004, -33.7, -35.7, -44.2, -50.40000000000001, -49.3, -40.60000000000001, -34.1, -44.00000000000001, -41.199999999999996, -46.3, -44.00000000000001, -45.7, -53.900000000000006, -48.00000000000001, -43.0, -59.800000000000004, -43.800000000000004, -18.7, -36.3, -58.70000000000001, -50.3, -36.7, -49.50000000000001, -49.800000000000004, -44.7, -47.6, -40.80000000000001, -35.7, -42.2, -46.7, -37.2, -49.50000000000001, -46.300000000000004, -43.2, -43.50000000000001, -26.6, -39.1, -63.900000000000006, -47.80000000000001, -55.60000000000001, -47.60000000000001, -46.900000000000006, -44.1, -44.400000000000006, -51.2, -43.00000000000001, -25.3, -33.699999999999996, -35.70000000000001, -42.0, -36.7, -59.500000000000014, -57.5, -37.3, -35.2, -42.8, -37.7, -58.10000000000001, -30.6, -46.30000000000001, -32.0, -48.10000000000001, -54.000000000000014, -42.80000000000001, -33.699999999999996, -43.70000000000001, -73.9, -43.7, -40.2, -42.7, -50.50000000000001, -38.2, -42.900000000000006, -45.2, -39.099999999999994, -49.800000000000004, -35.50000000000001, -27.3, -50.80000000000001, -38.300000000000004, -39.900000000000006, -49.60000000000001, -31.7, -31.5, -53.1, -60.50000000000001, -29.900000000000002, -45.2, -43.1, -46.2, -62.50000000000001, -35.7, -44.2, -44.300000000000004, -53.500000000000014, -40.7, -60.500000000000014, -42.90000000000001, -49.6, -50.2, -34.1, -46.5, -34.7, -27.300000000000004, -29.200000000000003, -38.5, -47.300000000000004, -35.00000000000001, -44.10000000000001, -49.400000000000006, -35.2, -34.900000000000006, -34.800000000000004, -51.400000000000006, -55.00000000000001, -34.60000000000001, -38.6, -33.599999999999994, -55.70000000000001, -42.800000000000004, -45.60000000000001, -41.300000000000004, -45.699999999999996, -49.60000000000001, -32.8, -44.6, -50.2, -40.5, -51.300000000000004, -54.400000000000006, -36.1, -42.900000000000006, -41.400000000000006, -42.10000000000001, -47.800000000000004, -50.500000000000014, -38.50000000000001, -37.6, -39.900000000000006, -49.90000000000001, -41.00000000000001, -51.2, -66.99999999999999, -33.4, -33.400000000000006, -31.600000000000005, -27.200000000000003, -58.00000000000001, -50.900000000000006, -36.5, -39.10000000000001, -48.80000000000001, -47.900000000000006, -45.80000000000001, -59.50000000000001, -43.60000000000001, -43.300000000000004, -33.8, -49.10000000000001, -45.300000000000004, -34.1, -43.400000000000006, -35.6, -32.2, -50.6, -34.7, -41.400000000000006, -44.60000000000001, -56.1, -50.4, -56.199999999999996, -38.00000000000001, -50.00000000000001], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13423101320242364, "mean_inference_ms": 1.216889864670177, "mean_action_processing_ms": 0.054608812055204875, "mean_env_wait_ms": 2.192960969676949, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 148000, "agent_timesteps_total": 148000, "timers": {"sample_time_ms": 7073.815, "sample_throughput": 565.466, "load_time_ms": 0.044, "load_throughput": 90785800.866, "learn_time_ms": 7169.547, "learn_throughput": 557.915, "update_time_ms": 1.47}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 173.76157987861222, "policy_loss": -0.029793691201516058, "vf_loss": 173.7891359554824, "vf_explained_var": [0.08045211434364319], "kl": 0.01118513915952091, "entropy": 1.1223366095173744, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 148000, "num_agent_steps_sampled": 148000, "num_steps_trained": 148000, "num_agent_steps_trained": 148000}, "done": false, "episodes_total": 9866, "training_iteration": 37, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-19-38", "timestamp": 1632518378, "time_this_iter_s": 14.244600296020508, "time_total_s": 545.1777181625366, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 545.1777181625366, "timesteps_since_restore": 0, "iterations_since_restore": 37, "perf": {"cpu_util_percent": 34.580952380952375, "ram_util_percent": 16.0}}
{"episode_reward_max": -22.2, "episode_reward_min": -83.69999999999999, "episode_reward_mean": -43.164661654135344, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-42.00000000000001, -36.7, -33.0, -42.2, -43.5, -37.0, -39.30000000000001, -30.0, -33.0, -32.800000000000004, -56.300000000000004, -36.800000000000004, -47.70000000000001, -36.3, -36.2, -38.6, -41.900000000000006, -44.400000000000006, -44.10000000000001, -43.300000000000004, -42.3, -35.00000000000001, -54.300000000000004, -47.50000000000001, -34.5, -49.500000000000014, -51.900000000000006, -61.80000000000002, -46.20000000000001, -61.20000000000001, -48.9, -48.80000000000001, -52.10000000000001, -33.7, -43.300000000000004, -43.10000000000001, -46.900000000000006, -41.6, -55.00000000000001, -43.1, -59.00000000000001, -42.300000000000004, -55.7, -35.10000000000001, -49.0, -41.300000000000004, -41.60000000000001, -30.2, -49.300000000000004, -37.5, -44.900000000000006, -45.300000000000004, -45.60000000000001, -41.6, -30.7, -43.400000000000006, -38.70000000000001, -46.7, -47.2, -44.7, -54.300000000000004, -34.0, -32.7, -36.800000000000004, -40.70000000000001, -42.20000000000001, -41.90000000000001, -31.700000000000003, -37.2, -39.2, -61.20000000000001, -34.9, -46.900000000000006, -28.900000000000002, -42.5, -37.4, -44.400000000000006, -28.8, -45.8, -48.7, -34.6, -43.900000000000006, -34.0, -32.800000000000004, -39.800000000000004, -41.10000000000001, -36.9, -43.400000000000006, -26.0, -28.800000000000004, -41.50000000000001, -40.5, -39.400000000000006, -49.400000000000006, -52.900000000000006, -42.4, -30.900000000000002, -41.30000000000001, -37.9, -43.8, -49.00000000000001, -46.400000000000006, -52.00000000000001, -54.00000000000001, -29.6, -36.1, -32.4, -39.50000000000001, -62.599999999999994, -44.8, -37.2, -49.900000000000006, -32.0, -44.0, -36.400000000000006, -41.300000000000004, -49.400000000000006, -54.2, -50.0, -44.300000000000004, -37.5, -41.900000000000006, -38.0, -35.400000000000006, -50.4, -42.4, -48.400000000000006, -59.9, -31.5, -28.7, -36.2, -58.60000000000001, -45.7, -36.2, -43.2, -50.400000000000006, -33.1, -54.600000000000016, -44.50000000000001, -49.5, -37.400000000000006, -38.70000000000001, -29.1, -41.10000000000001, -51.500000000000014, -73.30000000000001, -23.800000000000004, -54.0, -55.800000000000004, -54.50000000000001, -42.900000000000006, -33.400000000000006, -44.900000000000006, -33.800000000000004, -38.599999999999994, -54.300000000000004, -59.599999999999994, -54.6, -30.5, -42.400000000000006, -38.60000000000001, -58.900000000000006, -46.7, -36.4, -30.400000000000002, -47.599999999999994, -46.3, -46.800000000000004, -38.8, -48.5, -43.0, -38.0, -47.6, -31.4, -38.6, -29.900000000000002, -52.10000000000001, -37.900000000000006, -58.00000000000001, -37.7, -48.7, -42.2, -30.5, -34.400000000000006, -42.5, -43.00000000000001, -35.400000000000006, -38.800000000000004, -44.60000000000001, -42.5, -50.0, -41.60000000000001, -34.400000000000006, -40.1, -58.900000000000006, -39.9, -38.800000000000004, -43.1, -46.20000000000001, -57.00000000000001, -40.8, -23.300000000000004, -32.9, -41.10000000000001, -22.2, -46.60000000000001, -53.10000000000001, -40.2, -45.70000000000001, -41.7, -38.4, -65.2, -36.7, -25.100000000000005, -74.50000000000001, -40.599999999999994, -37.6, -49.50000000000001, -41.9, -39.1, -62.7, -47.0, -33.2, -39.4, -40.5, -57.000000000000014, -45.50000000000001, -36.50000000000001, -63.70000000000001, -35.2, -51.70000000000001, -49.6, -49.800000000000004, -52.70000000000002, -51.900000000000006, -41.300000000000004, -55.20000000000001, -35.1, -40.8, -32.3, -83.69999999999999, -43.0, -37.2, -50.900000000000006, -51.6, -34.800000000000004, -41.80000000000001, -49.100000000000016, -49.000000000000014, -38.70000000000001, -34.9, -50.300000000000004, -33.900000000000006, -34.900000000000006, -44.2, -47.300000000000004, -59.10000000000001, -39.70000000000001, -25.5, -41.0, -55.10000000000001, -54.80000000000001, -45.10000000000001, -44.800000000000004, -35.300000000000004, -50.500000000000014], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13410870654744758, "mean_inference_ms": 1.2157121047655408, "mean_action_processing_ms": 0.05455558136044953, "mean_env_wait_ms": 2.19008944097035, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 152000, "agent_timesteps_total": 152000, "timers": {"sample_time_ms": 7066.933, "sample_throughput": 566.016, "load_time_ms": 0.044, "load_throughput": 91032099.837, "learn_time_ms": 7181.657, "learn_throughput": 556.975, "update_time_ms": 1.474}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 167.83568680465862, "policy_loss": -0.035637872513904365, "vf_loss": 167.86890040571973, "vf_explained_var": [0.06079932302236557], "kl": 0.012118871768985634, "entropy": 1.0782724176042824, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 152000, "num_agent_steps_sampled": 152000, "num_steps_trained": 152000, "num_agent_steps_trained": 152000}, "done": false, "episodes_total": 10132, "training_iteration": 38, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-19-53", "timestamp": 1632518393, "time_this_iter_s": 14.364830017089844, "time_total_s": 559.5425481796265, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 559.5425481796265, "timesteps_since_restore": 0, "iterations_since_restore": 38, "perf": {"cpu_util_percent": 34.315000000000005, "ram_util_percent": 16.0}}
{"episode_reward_max": -21.3, "episode_reward_min": -67.3, "episode_reward_mean": -43.54477611940298, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 268, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-32.5, -53.00000000000001, -38.6, -50.10000000000001, -38.9, -39.80000000000001, -40.300000000000004, -45.7, -48.60000000000001, -47.90000000000001, -48.9, -45.50000000000001, -46.50000000000001, -55.1, -47.400000000000006, -38.0, -44.400000000000006, -58.300000000000004, -36.5, -44.300000000000004, -55.6, -46.80000000000001, -31.000000000000004, -45.20000000000001, -31.600000000000005, -33.800000000000004, -26.500000000000007, -49.60000000000001, -50.6, -43.400000000000006, -33.800000000000004, -28.0, -44.6, -43.900000000000006, -60.400000000000006, -31.900000000000002, -50.40000000000001, -31.5, -44.2, -42.800000000000004, -28.200000000000003, -60.60000000000001, -44.900000000000006, -30.400000000000002, -60.2, -52.800000000000004, -38.1, -52.39999999999999, -54.30000000000001, -44.800000000000004, -48.400000000000006, -38.800000000000004, -28.1, -33.0, -36.800000000000004, -51.800000000000004, -38.6, -43.0, -50.7, -44.5, -39.0, -40.800000000000004, -34.5, -39.6, -48.10000000000001, -42.00000000000001, -35.7, -38.9, -43.00000000000001, -56.6, -53.20000000000001, -47.9, -44.900000000000006, -42.80000000000001, -52.30000000000001, -63.099999999999994, -54.2, -56.5, -45.90000000000001, -50.00000000000001, -60.50000000000001, -42.8, -51.60000000000001, -33.6, -25.999999999999996, -35.60000000000001, -63.00000000000001, -34.9, -42.500000000000014, -31.6, -39.1, -48.7, -41.70000000000001, -44.0, -31.8, -42.900000000000006, -42.2, -42.699999999999996, -43.10000000000001, -53.20000000000001, -38.6, -50.80000000000001, -67.3, -58.80000000000001, -39.2, -43.1, -37.00000000000001, -47.7, -34.300000000000004, -46.1, -52.10000000000001, -53.70000000000001, -61.100000000000016, -42.20000000000001, -50.7, -40.800000000000004, -48.300000000000004, -36.699999999999996, -43.3, -53.1, -46.00000000000001, -33.300000000000004, -36.7, -48.10000000000001, -33.400000000000006, -39.900000000000006, -56.9, -37.6, -41.0, -38.800000000000004, -59.80000000000001, -32.2, -36.1, -38.2, -57.80000000000002, -44.400000000000006, -49.10000000000001, -50.20000000000001, -32.6, -38.099999999999994, -31.400000000000006, -41.60000000000001, -46.2, -33.5, -61.2, -40.400000000000006, -47.599999999999994, -37.50000000000001, -46.400000000000006, -41.2, -54.10000000000001, -32.1, -32.50000000000001, -40.900000000000006, -40.900000000000006, -57.500000000000014, -33.7, -50.1, -44.2, -65.10000000000001, -38.6, -38.3, -36.8, -35.50000000000001, -55.80000000000001, -38.5, -48.9, -37.10000000000001, -31.800000000000004, -35.199999999999996, -49.0, -36.400000000000006, -44.000000000000014, -46.900000000000006, -21.3, -30.699999999999996, -65.0, -41.00000000000001, -39.300000000000004, -46.80000000000001, -36.30000000000001, -33.900000000000006, -45.7, -46.10000000000001, -48.80000000000001, -56.20000000000001, -32.599999999999994, -51.7, -28.6, -52.70000000000001, -45.60000000000001, -48.7, -43.900000000000006, -43.500000000000014, -41.6, -62.10000000000001, -42.1, -46.300000000000004, -30.6, -42.9, -38.60000000000001, -58.400000000000006, -41.7, -46.60000000000001, -27.300000000000004, -48.70000000000001, -43.2, -39.3, -44.900000000000006, -55.80000000000001, -45.400000000000006, -40.4, -39.0, -36.800000000000004, -38.699999999999996, -30.800000000000004, -46.5, -51.70000000000001, -40.300000000000004, -59.80000000000001, -37.2, -44.70000000000001, -48.2, -34.50000000000001, -37.300000000000004, -29.300000000000004, -48.3, -50.000000000000014, -39.2, -33.6, -38.30000000000001, -32.6, -36.400000000000006, -32.1, -43.199999999999996, -50.800000000000004, -42.8, -30.900000000000002, -47.4, -52.3, -34.4, -26.5, -40.70000000000001, -56.2, -47.50000000000001, -48.4, -43.2, -49.2, -41.300000000000004, -56.900000000000006, -59.30000000000001, -49.10000000000001, -45.800000000000004, -43.800000000000004, -35.10000000000001, -36.2, -40.400000000000006, -37.50000000000001, -46.0, -53.5, -46.8, -42.50000000000001, -37.8, -41.1, -44.7, -42.800000000000004, -48.40000000000001, -35.10000000000001], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13401368613689427, "mean_inference_ms": 1.2152732435696352, "mean_action_processing_ms": 0.05453761037399422, "mean_env_wait_ms": 2.1883285901015883, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 156000, "agent_timesteps_total": 156000, "timers": {"sample_time_ms": 7069.447, "sample_throughput": 565.815, "load_time_ms": 0.044, "load_throughput": 91180521.739, "learn_time_ms": 7205.067, "learn_throughput": 555.165, "update_time_ms": 1.447}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 168.660229738297, "policy_loss": -0.028776957162265335, "vf_loss": 168.68674485401442, "vf_explained_var": [0.04988947883248329], "kl": 0.011310380532915386, "entropy": 1.0706658667774611, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 156000, "num_agent_steps_sampled": 156000, "num_steps_trained": 156000, "num_agent_steps_trained": 156000}, "done": false, "episodes_total": 10400, "training_iteration": 39, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-20-07", "timestamp": 1632518407, "time_this_iter_s": 14.270992279052734, "time_total_s": 573.8135404586792, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 573.8135404586792, "timesteps_since_restore": 0, "iterations_since_restore": 39, "perf": {"cpu_util_percent": 35.12380952380953, "ram_util_percent": 16.0}}
{"episode_reward_max": -19.500000000000004, "episode_reward_min": -68.2, "episode_reward_mean": -42.74172932330828, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-43.300000000000004, -33.8, -53.999999999999986, -48.70000000000001, -48.500000000000014, -50.00000000000001, -49.90000000000001, -33.8, -32.199999999999996, -48.5, -39.1, -34.2, -36.4, -41.8, -33.400000000000006, -28.0, -38.6, -52.80000000000001, -53.2, -36.7, -48.500000000000014, -62.00000000000001, -38.900000000000006, -38.400000000000006, -44.900000000000006, -41.300000000000004, -42.300000000000004, -54.600000000000016, -68.2, -31.600000000000005, -34.3, -49.00000000000001, -47.00000000000001, -41.7, -50.60000000000001, -43.900000000000006, -52.80000000000001, -25.2, -27.1, -48.000000000000014, -24.4, -39.5, -44.400000000000006, -40.900000000000006, -41.10000000000001, -40.2, -32.60000000000001, -32.7, -27.699999999999996, -47.0, -51.50000000000001, -48.900000000000006, -39.300000000000004, -49.70000000000001, -38.10000000000001, -54.2, -41.5, -41.10000000000001, -25.8, -33.5, -32.4, -38.300000000000004, -44.50000000000001, -44.0, -50.900000000000006, -47.50000000000001, -48.10000000000001, -45.30000000000001, -38.1, -40.6, -50.60000000000001, -44.30000000000001, -43.50000000000001, -49.80000000000001, -36.900000000000006, -40.900000000000006, -32.1, -41.400000000000006, -46.400000000000006, -52.1, -43.4, -37.199999999999996, -42.70000000000001, -40.8, -48.60000000000001, -42.00000000000001, -61.50000000000001, -35.400000000000006, -50.2, -43.2, -50.40000000000001, -26.6, -36.50000000000001, -26.400000000000002, -48.3, -41.80000000000001, -61.000000000000014, -49.50000000000001, -41.0, -43.10000000000001, -40.70000000000002, -39.9, -38.7, -36.400000000000006, -48.8, -46.7, -52.2, -31.8, -31.900000000000002, -51.90000000000001, -45.2, -54.90000000000001, -49.20000000000001, -51.300000000000004, -50.50000000000001, -43.400000000000006, -42.3, -41.80000000000001, -37.00000000000001, -56.7, -42.800000000000004, -53.1, -49.1, -37.900000000000006, -41.900000000000006, -46.300000000000004, -62.70000000000001, -28.500000000000004, -36.6, -50.30000000000001, -41.6, -31.600000000000005, -38.7, -36.5, -31.7, -41.900000000000006, -43.50000000000001, -41.60000000000001, -56.900000000000006, -37.0, -52.5, -52.5, -32.5, -42.7, -63.10000000000001, -43.20000000000001, -44.900000000000006, -67.50000000000001, -57.4, -39.1, -32.7, -40.9, -37.800000000000004, -51.400000000000006, -34.400000000000006, -51.60000000000001, -48.60000000000001, -47.5, -36.599999999999994, -45.800000000000004, -40.60000000000001, -44.10000000000001, -41.1, -37.2, -33.4, -56.8, -65.5, -41.1, -53.10000000000001, -30.3, -49.900000000000006, -46.7, -43.300000000000004, -40.800000000000004, -37.7, -45.50000000000001, -43.0, -47.50000000000001, -32.9, -37.400000000000006, -45.2, -43.800000000000004, -45.80000000000001, -31.900000000000002, -43.0, -57.900000000000006, -44.00000000000001, -34.20000000000001, -32.9, -56.50000000000001, -39.699999999999996, -35.2, -44.300000000000004, -44.50000000000001, -42.800000000000004, -40.900000000000006, -48.2, -36.5, -49.6, -35.50000000000001, -38.199999999999996, -39.5, -48.1, -41.1, -31.800000000000004, -29.6, -32.7, -52.500000000000014, -28.4, -44.2, -31.200000000000003, -49.10000000000001, -44.60000000000002, -36.4, -35.1, -51.400000000000006, -27.299999999999997, -38.50000000000001, -41.6, -34.7, -31.6, -25.400000000000006, -36.60000000000001, -56.400000000000006, -41.40000000000001, -41.50000000000001, -50.90000000000001, -39.400000000000006, -46.900000000000006, -61.7, -48.70000000000001, -29.800000000000004, -42.7, -50.300000000000004, -50.9, -55.3, -51.0, -47.4, -34.5, -37.6, -56.500000000000014, -57.70000000000001, -34.800000000000004, -47.300000000000004, -46.50000000000001, -34.5, -52.0, -43.50000000000001, -42.60000000000001, -30.999999999999996, -50.5, -52.500000000000014, -35.4, -25.800000000000004, -26.1, -29.700000000000003, -19.500000000000004, -45.20000000000001, -57.300000000000004, -54.20000000000001, -41.00000000000001, -45.900000000000006, -28.500000000000007, -31.7, -43.3, -37.2], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13389819678740986, "mean_inference_ms": 1.2142129338438352, "mean_action_processing_ms": 0.054493097780293244, "mean_env_wait_ms": 2.185346457340159, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 160000, "agent_timesteps_total": 160000, "timers": {"sample_time_ms": 7038.098, "sample_throughput": 568.335, "load_time_ms": 0.044, "load_throughput": 91032099.837, "learn_time_ms": 7183.71, "learn_throughput": 556.815, "update_time_ms": 1.447}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 166.26918480985907, "policy_loss": -0.022244215833764243, "vf_loss": 166.2896348604592, "vf_explained_var": [0.04826047271490097], "kl": 0.00896875285855048, "entropy": 1.0533843677531007, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 160000, "num_agent_steps_sampled": 160000, "num_steps_trained": 160000, "num_agent_steps_trained": 160000}, "done": false, "episodes_total": 10666, "training_iteration": 40, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-20-21", "timestamp": 1632518421, "time_this_iter_s": 13.892258167266846, "time_total_s": 587.705798625946, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 587.705798625946, "timesteps_since_restore": 0, "iterations_since_restore": 40, "perf": {"cpu_util_percent": 34.095, "ram_util_percent": 15.995}}
{"episode_reward_max": -18.099999999999998, "episode_reward_min": -71.10000000000001, "episode_reward_mean": -42.665413533834595, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.5, -35.50000000000001, -45.90000000000001, -31.800000000000004, -47.900000000000006, -52.599999999999994, -38.4, -43.6, -52.900000000000006, -23.5, -41.0, -40.1, -28.099999999999998, -42.30000000000001, -43.300000000000004, -46.7, -46.400000000000006, -44.2, -56.800000000000004, -44.000000000000014, -41.199999999999996, -56.400000000000006, -37.60000000000001, -57.20000000000001, -38.7, -41.400000000000006, -48.10000000000001, -36.0, -49.30000000000001, -46.6, -40.1, -37.900000000000006, -45.50000000000001, -44.70000000000001, -45.800000000000004, -40.4, -37.89999999999999, -58.1, -40.2, -49.6, -48.5, -33.7, -42.8, -38.7, -46.2, -43.300000000000004, -44.2, -40.800000000000004, -37.70000000000002, -41.6, -37.5, -39.2, -29.800000000000004, -39.50000000000001, -60.4, -36.6, -41.800000000000004, -46.80000000000001, -43.60000000000001, -33.0, -49.300000000000004, -45.6, -42.0, -33.6, -42.400000000000006, -39.60000000000001, -43.6, -49.7, -41.5, -27.700000000000003, -28.600000000000005, -39.6, -53.30000000000001, -35.5, -58.49999999999999, -47.20000000000001, -47.000000000000014, -43.300000000000004, -47.10000000000001, -49.3, -34.00000000000001, -49.30000000000002, -38.900000000000006, -37.1, -47.1, -34.1, -53.00000000000001, -47.4, -32.6, -37.800000000000004, -26.4, -32.900000000000006, -49.8, -40.00000000000001, -35.400000000000006, -56.10000000000001, -32.1, -31.000000000000004, -43.00000000000001, -29.800000000000004, -23.600000000000005, -51.30000000000001, -30.7, -46.60000000000001, -49.20000000000001, -47.6, -52.80000000000001, -49.50000000000001, -35.6, -41.50000000000001, -42.300000000000004, -37.1, -45.300000000000004, -46.20000000000001, -33.5, -37.400000000000006, -46.20000000000001, -40.2, -54.80000000000001, -52.30000000000001, -33.6, -38.3, -35.9, -42.0, -53.90000000000001, -36.5, -45.7, -34.400000000000006, -42.3, -36.1, -32.400000000000006, -50.1, -39.3, -55.10000000000001, -46.20000000000001, -45.30000000000001, -26.200000000000003, -58.300000000000004, -42.6, -43.00000000000001, -48.30000000000001, -40.30000000000001, -33.50000000000001, -23.700000000000003, -42.10000000000001, -50.0, -37.3, -53.40000000000001, -48.70000000000002, -50.400000000000006, -39.1, -39.900000000000006, -34.0, -44.2, -37.3, -40.4, -40.300000000000004, -38.2, -45.400000000000006, -35.2, -48.2, -44.2, -56.30000000000001, -29.1, -58.50000000000001, -34.900000000000006, -39.800000000000004, -47.400000000000006, -37.20000000000001, -45.800000000000004, -50.7, -39.80000000000001, -35.000000000000014, -42.0, -41.800000000000004, -39.300000000000004, -43.7, -51.7, -36.6, -33.4, -39.400000000000006, -33.0, -34.4, -47.10000000000001, -39.5, -57.6, -40.3, -33.0, -43.9, -41.300000000000004, -37.400000000000006, -36.300000000000004, -31.800000000000004, -35.900000000000006, -51.10000000000001, -36.199999999999996, -42.800000000000004, -47.599999999999994, -40.0, -43.10000000000001, -40.800000000000004, -71.10000000000001, -48.5, -34.6, -41.800000000000004, -36.2, -25.1, -51.400000000000006, -36.9, -40.900000000000006, -53.2, -41.900000000000006, -47.900000000000006, -49.300000000000004, -39.1, -70.10000000000002, -43.20000000000001, -40.1, -45.49999999999999, -39.5, -69.00000000000001, -46.900000000000006, -37.00000000000001, -42.1, -47.70000000000001, -50.099999999999994, -49.2, -18.099999999999998, -62.300000000000004, -51.2, -39.800000000000004, -61.900000000000006, -23.8, -45.7, -50.80000000000001, -57.10000000000001, -42.00000000000001, -37.4, -56.2, -44.900000000000006, -33.40000000000001, -45.1, -45.900000000000006, -37.6, -42.7, -49.2, -39.60000000000001, -37.7, -37.6, -46.699999999999996, -34.2, -46.3, -42.60000000000001, -32.7, -33.0, -48.10000000000001, -42.2, -55.50000000000001, -52.30000000000001, -49.2, -32.300000000000004, -45.400000000000006, -49.00000000000001, -47.3, -43.7, -43.6], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1337453273198623, "mean_inference_ms": 1.2142128994464267, "mean_action_processing_ms": 0.0544277842839365, "mean_env_wait_ms": 2.1817351685484905, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 164000, "agent_timesteps_total": 164000, "timers": {"sample_time_ms": 7017.567, "sample_throughput": 569.998, "load_time_ms": 0.044, "load_throughput": 90736700.919, "learn_time_ms": 7168.309, "learn_throughput": 558.012, "update_time_ms": 1.428}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 163.08088820262623, "policy_loss": -0.02726146391272465, "vf_loss": 163.1062845619776, "vf_explained_var": [0.05078606680035591], "kl": 0.009327950412658778, "entropy": 1.0387075363948781, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 164000, "num_agent_steps_sampled": 164000, "num_steps_trained": 164000, "num_agent_steps_trained": 164000}, "done": false, "episodes_total": 10932, "training_iteration": 41, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-20-35", "timestamp": 1632518435, "time_this_iter_s": 14.015640258789062, "time_total_s": 601.7214388847351, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 601.7214388847351, "timesteps_since_restore": 0, "iterations_since_restore": 41, "perf": {"cpu_util_percent": 34.25000000000001, "ram_util_percent": 16.0}}
{"episode_reward_max": -18.7, "episode_reward_min": -78.80000000000001, "episode_reward_mean": -42.034701492537316, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 268, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.6, -57.000000000000014, -39.00000000000001, -37.5, -39.2, -41.6, -51.9, -42.5, -59.000000000000014, -42.800000000000004, -55.000000000000014, -35.400000000000006, -48.1, -56.5, -42.60000000000001, -39.800000000000004, -38.300000000000004, -28.1, -41.20000000000001, -34.6, -44.900000000000006, -37.7, -47.50000000000001, -25.4, -44.5, -26.799999999999997, -39.7, -36.3, -37.1, -38.900000000000006, -35.0, -37.5, -43.8, -52.00000000000001, -34.300000000000004, -38.10000000000001, -30.9, -35.9, -47.5, -41.300000000000004, -39.6, -37.0, -50.900000000000006, -48.1, -52.900000000000006, -33.599999999999994, -50.400000000000006, -30.500000000000004, -48.9, -52.800000000000004, -48.300000000000004, -38.300000000000004, -35.1, -24.400000000000002, -42.6, -33.0, -26.9, -48.50000000000001, -34.20000000000001, -42.800000000000004, -53.400000000000006, -41.8, -31.7, -46.1, -45.6, -29.9, -35.6, -36.900000000000006, -18.7, -37.6, -34.9, -62.60000000000001, -39.6, -50.10000000000001, -23.3, -39.7, -39.6, -34.7, -43.4, -38.6, -43.5, -26.6, -41.00000000000001, -31.400000000000002, -39.10000000000001, -52.0, -41.90000000000001, -45.900000000000006, -57.50000000000001, -61.1, -55.7, -48.70000000000001, -34.800000000000004, -42.7, -30.6, -47.400000000000006, -33.50000000000001, -44.300000000000004, -41.9, -39.1, -24.1, -44.400000000000006, -38.50000000000001, -55.2, -36.9, -25.1, -49.1, -54.4, -52.699999999999996, -28.200000000000003, -38.5, -46.60000000000001, -37.400000000000006, -52.7, -39.6, -48.2, -33.1, -46.900000000000006, -44.7, -38.400000000000006, -35.2, -48.900000000000006, -45.1, -51.1, -25.800000000000004, -41.900000000000006, -45.2, -40.300000000000004, -40.0, -39.9, -33.6, -43.9, -49.6, -34.50000000000001, -48.60000000000001, -33.400000000000006, -35.2, -56.0, -33.6, -45.10000000000001, -33.10000000000001, -52.20000000000002, -30.800000000000004, -50.20000000000001, -43.00000000000001, -31.599999999999998, -35.099999999999994, -45.100000000000016, -47.5, -52.00000000000001, -38.300000000000004, -35.800000000000004, -49.5, -47.900000000000006, -32.7, -46.0, -67.2, -39.6, -36.20000000000001, -26.3, -50.90000000000001, -31.500000000000004, -39.500000000000014, -31.700000000000003, -33.800000000000004, -40.20000000000001, -31.9, -43.10000000000001, -57.2, -45.00000000000001, -50.2, -54.80000000000001, -39.400000000000006, -43.5, -54.000000000000014, -40.800000000000004, -49.7, -47.2, -50.300000000000004, -37.2, -50.1, -42.199999999999996, -33.0, -50.60000000000001, -57.30000000000001, -46.00000000000001, -37.5, -43.800000000000004, -47.7, -47.80000000000001, -59.7, -44.10000000000001, -22.5, -37.6, -41.400000000000006, -41.70000000000001, -41.900000000000006, -36.5, -57.10000000000001, -50.40000000000001, -50.9, -41.7, -38.4, -44.2, -34.2, -37.800000000000004, -36.5, -44.800000000000004, -33.2, -38.1, -44.300000000000004, -23.4, -31.0, -47.60000000000001, -35.00000000000001, -49.6, -23.7, -38.50000000000001, -43.2, -44.89999999999999, -45.000000000000014, -35.7, -50.10000000000001, -31.200000000000003, -51.199999999999996, -39.900000000000006, -42.70000000000001, -58.8, -37.60000000000001, -36.800000000000004, -27.300000000000004, -39.2, -50.2, -40.6, -42.400000000000006, -43.1, -38.7, -53.400000000000006, -57.5, -78.80000000000001, -42.0, -51.5, -51.50000000000001, -32.4, -50.70000000000001, -46.6, -48.00000000000001, -51.20000000000001, -32.7, -35.400000000000006, -35.7, -42.00000000000001, -55.500000000000014, -50.90000000000001, -36.00000000000001, -60.5, -32.10000000000001, -37.50000000000001, -49.2, -44.699999999999996, -36.50000000000001, -42.60000000000001, -37.800000000000004, -35.199999999999996, -37.800000000000004, -41.3, -56.40000000000001, -40.8], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13422653082758146, "mean_inference_ms": 1.2189044173113701, "mean_action_processing_ms": 0.05466208211186486, "mean_env_wait_ms": 2.1836421110549398, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 168000, "agent_timesteps_total": 168000, "timers": {"sample_time_ms": 7103.059, "sample_throughput": 563.138, "load_time_ms": 0.044, "load_throughput": 91032099.837, "learn_time_ms": 7359.823, "learn_throughput": 543.491, "update_time_ms": 1.5}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 162.7297338834373, "policy_loss": -0.03259236980730327, "vf_loss": 162.7600585445281, "vf_explained_var": [0.05624375119805336], "kl": 0.011339568696873869, "entropy": 1.01027583524745, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 168000, "num_agent_steps_sampled": 168000, "num_steps_trained": 168000, "num_agent_steps_trained": 168000}, "done": false, "episodes_total": 11200, "training_iteration": 42, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-20-52", "timestamp": 1632518452, "time_this_iter_s": 16.96086573600769, "time_total_s": 618.6823046207428, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 618.6823046207428, "timesteps_since_restore": 0, "iterations_since_restore": 42, "perf": {"cpu_util_percent": 35.425000000000004, "ram_util_percent": 16.0}}
{"episode_reward_max": -15.700000000000001, "episode_reward_min": -70.20000000000002, "episode_reward_mean": -42.08759398496241, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-47.2, -29.000000000000004, -28.300000000000004, -40.00000000000001, -38.10000000000001, -36.800000000000004, -44.00000000000001, -30.1, -36.4, -45.8, -39.800000000000004, -48.5, -34.6, -49.300000000000004, -56.10000000000001, -37.0, -48.1, -48.3, -40.800000000000004, -46.60000000000001, -35.8, -27.099999999999998, -46.6, -26.200000000000003, -46.800000000000004, -40.70000000000001, -34.2, -27.299999999999997, -42.20000000000001, -24.6, -44.7, -42.1, -55.800000000000004, -56.800000000000004, -51.10000000000001, -34.1, -57.30000000000001, -38.1, -49.60000000000001, -37.6, -45.80000000000001, -40.7, -42.00000000000001, -46.10000000000001, -29.8, -47.3, -47.9, -26.9, -39.0, -30.4, -36.0, -41.80000000000001, -32.199999999999996, -38.4, -38.7, -33.2, -44.10000000000001, -35.0, -50.400000000000006, -40.2, -34.2, -36.7, -36.800000000000004, -30.799999999999997, -61.400000000000006, -56.1, -41.0, -35.800000000000004, -35.00000000000001, -41.4, -41.9, -51.800000000000004, -33.00000000000001, -43.400000000000006, -49.10000000000001, -36.4, -39.80000000000001, -70.10000000000002, -45.400000000000006, -45.00000000000001, -34.0, -46.0, -57.1, -36.599999999999994, -33.9, -41.30000000000001, -25.6, -15.700000000000001, -54.2, -51.400000000000006, -45.7, -29.299999999999997, -43.800000000000004, -50.5, -38.50000000000001, -36.0, -26.400000000000002, -37.800000000000004, -39.0, -32.2, -40.60000000000001, -51.900000000000006, -31.000000000000004, -50.800000000000004, -26.6, -48.20000000000001, -46.4, -34.300000000000004, -37.099999999999994, -58.800000000000004, -45.800000000000004, -54.30000000000001, -46.099999999999994, -37.1, -31.8, -48.10000000000001, -42.0, -39.900000000000006, -45.6, -57.60000000000001, -41.50000000000001, -57.800000000000004, -48.10000000000001, -48.70000000000001, -65.4, -31.5, -37.6, -53.39999999999999, -49.800000000000004, -42.7, -31.2, -33.4, -50.300000000000004, -48.60000000000001, -36.2, -36.400000000000006, -60.2, -34.400000000000006, -32.900000000000006, -40.199999999999996, -57.80000000000001, -29.200000000000003, -47.0, -40.2, -33.300000000000004, -55.800000000000004, -40.900000000000006, -51.50000000000001, -44.400000000000006, -31.40000000000001, -50.100000000000016, -49.300000000000004, -48.800000000000004, -53.900000000000006, -22.700000000000003, -44.10000000000001, -35.1, -27.700000000000003, -42.10000000000001, -48.2, -47.400000000000006, -34.6, -55.50000000000001, -32.3, -34.7, -32.900000000000006, -38.2, -35.800000000000004, -60.900000000000006, -34.800000000000004, -41.900000000000006, -48.90000000000001, -35.00000000000001, -38.900000000000006, -51.0, -51.40000000000001, -38.800000000000004, -44.00000000000001, -41.5, -42.2, -29.8, -35.2, -33.50000000000001, -52.000000000000014, -42.4, -27.4, -43.50000000000001, -37.5, -49.80000000000001, -39.6, -53.00000000000001, -31.700000000000006, -40.099999999999994, -70.20000000000002, -34.2, -34.8, -40.900000000000006, -50.900000000000006, -34.5, -64.60000000000001, -29.3, -28.900000000000002, -59.900000000000006, -34.50000000000001, -40.20000000000001, -39.800000000000004, -46.1, -36.7, -58.4, -46.4, -55.7, -27.200000000000006, -46.90000000000001, -45.300000000000004, -43.699999999999996, -35.900000000000006, -35.5, -45.4, -62.400000000000006, -45.6, -58.50000000000001, -34.400000000000006, -40.500000000000014, -34.6, -46.2, -35.300000000000004, -53.7, -56.10000000000001, -33.1, -46.0, -42.300000000000004, -44.300000000000004, -38.00000000000001, -43.699999999999996, -38.1, -41.60000000000001, -40.300000000000004, -61.400000000000006, -45.400000000000006, -36.800000000000004, -37.1, -37.300000000000004, -37.300000000000004, -28.599999999999998, -51.900000000000006, -45.30000000000001, -38.300000000000004, -39.400000000000006, -48.50000000000001, -46.6, -47.50000000000001, -51.7, -46.699999999999996, -50.20000000000001, -61.70000000000001, -59.5, -35.4, -37.5, -32.3, -32.5, -37.7, -44.10000000000001, -34.400000000000006, -35.400000000000006, -36.4, -44.300000000000004], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13464042967726253, "mean_inference_ms": 1.2224314510846552, "mean_action_processing_ms": 0.05481055062285211, "mean_env_wait_ms": 2.184225616604116, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 172000, "agent_timesteps_total": 172000, "timers": {"sample_time_ms": 7176.446, "sample_throughput": 557.379, "load_time_ms": 0.046, "load_throughput": 87884840.23, "learn_time_ms": 7595.374, "learn_throughput": 526.636, "update_time_ms": 1.549}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 161.56757376886182, "policy_loss": -0.02964451532730813, "vf_loss": 161.59513469408918, "vf_explained_var": [0.060344889760017395], "kl": 0.010418011455593587, "entropy": 0.9785760618666167, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 172000, "num_agent_steps_sampled": 172000, "num_steps_trained": 172000, "num_agent_steps_trained": 172000}, "done": false, "episodes_total": 11466, "training_iteration": 43, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-21-09", "timestamp": 1632518469, "time_this_iter_s": 17.093863487243652, "time_total_s": 635.7761681079865, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 635.7761681079865, "timesteps_since_restore": 0, "iterations_since_restore": 43, "perf": {"cpu_util_percent": 35.75, "ram_util_percent": 15.987499999999999}}
{"episode_reward_max": -23.7, "episode_reward_min": -76.6, "episode_reward_mean": -43.172932330827074, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-34.9, -34.699999999999996, -41.800000000000004, -46.10000000000001, -37.0, -64.40000000000002, -56.00000000000001, -49.400000000000006, -42.60000000000001, -48.7, -51.6, -34.00000000000001, -51.30000000000001, -41.00000000000001, -32.2, -34.7, -41.800000000000004, -34.300000000000004, -42.7, -49.300000000000004, -38.900000000000006, -36.2, -48.50000000000001, -49.800000000000004, -45.70000000000001, -44.8, -54.30000000000001, -44.20000000000001, -43.800000000000004, -41.4, -40.800000000000004, -39.5, -31.9, -46.60000000000001, -44.800000000000004, -32.5, -37.800000000000004, -44.5, -34.7, -43.2, -37.300000000000004, -51.3, -38.300000000000004, -54.400000000000006, -37.10000000000001, -35.6, -37.900000000000006, -45.900000000000006, -44.800000000000004, -28.5, -34.2, -34.8, -41.6, -30.0, -36.2, -51.0, -34.5, -66.19999999999997, -39.800000000000004, -38.6, -35.6, -28.7, -42.00000000000001, -39.5, -39.7, -37.6, -47.1, -54.8, -38.300000000000004, -47.5, -31.1, -44.300000000000004, -53.8, -43.60000000000001, -41.0, -50.400000000000006, -51.600000000000016, -28.800000000000004, -45.50000000000001, -47.400000000000006, -53.800000000000004, -37.8, -33.800000000000004, -34.400000000000006, -40.800000000000004, -42.80000000000001, -26.0, -58.8, -25.900000000000002, -39.800000000000004, -43.7, -47.40000000000001, -50.8, -40.2, -44.2, -42.5, -39.50000000000001, -36.199999999999996, -50.7, -38.900000000000006, -33.9, -40.30000000000001, -59.2, -35.3, -43.60000000000001, -49.70000000000001, -39.300000000000004, -36.00000000000001, -40.10000000000001, -42.4, -33.1, -52.300000000000004, -34.1, -57.30000000000001, -64.7, -40.7, -46.0, -40.50000000000001, -37.3, -28.5, -35.9, -33.199999999999996, -40.0, -47.5, -34.49999999999999, -44.400000000000006, -38.40000000000001, -56.6, -59.2, -41.90000000000001, -40.199999999999996, -40.90000000000001, -50.5, -32.5, -36.7, -46.9, -43.00000000000001, -36.6, -41.2, -33.300000000000004, -52.70000000000002, -40.8, -49.10000000000001, -50.10000000000001, -54.6, -23.7, -53.50000000000001, -49.300000000000004, -51.50000000000001, -27.800000000000008, -29.700000000000006, -34.00000000000001, -40.500000000000014, -59.80000000000001, -46.300000000000004, -47.60000000000001, -52.49999999999999, -42.50000000000001, -47.0, -43.4, -50.6, -49.30000000000001, -32.10000000000001, -29.9, -56.39999999999999, -47.60000000000001, -48.0, -54.50000000000001, -42.4, -29.600000000000005, -33.70000000000001, -48.900000000000006, -37.0, -46.00000000000001, -45.80000000000001, -36.0, -50.400000000000006, -50.400000000000006, -47.8, -30.400000000000002, -47.5, -43.9, -51.40000000000001, -42.2, -30.500000000000004, -36.5, -39.5, -52.70000000000001, -50.900000000000006, -68.70000000000002, -61.60000000000001, -50.10000000000001, -49.300000000000004, -37.7, -44.00000000000001, -39.400000000000006, -29.000000000000004, -39.7, -39.80000000000001, -39.9, -49.50000000000001, -49.9, -30.000000000000004, -53.7, -64.50000000000001, -42.1, -50.2, -57.70000000000001, -76.6, -47.30000000000001, -31.800000000000004, -34.7, -50.50000000000001, -31.699999999999996, -50.699999999999996, -41.4, -48.2, -57.199999999999996, -28.2, -41.5, -30.0, -34.0, -57.80000000000001, -49.900000000000006, -35.1, -40.400000000000006, -53.49999999999999, -39.5, -44.5, -40.0, -36.900000000000006, -33.300000000000004, -48.80000000000001, -63.40000000000001, -38.3, -44.60000000000001, -36.9, -46.800000000000004, -51.199999999999996, -41.0, -43.20000000000001, -37.900000000000006, -48.3, -31.5, -32.7, -54.900000000000006, -41.400000000000006, -58.300000000000004, -37.0, -46.6, -33.10000000000001, -41.800000000000004, -55.800000000000004, -54.000000000000014, -57.7, -54.50000000000001, -42.2, -38.0, -38.5, -35.699999999999996, -43.5, -33.7, -53.7, -37.900000000000006, -42.800000000000004, -34.1], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13531860284545968, "mean_inference_ms": 1.228553476857158, "mean_action_processing_ms": 0.05509398042911157, "mean_env_wait_ms": 2.1882581759040463, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 176000, "agent_timesteps_total": 176000, "timers": {"sample_time_ms": 7303.235, "sample_throughput": 547.702, "load_time_ms": 0.045, "load_throughput": 88487426.16, "learn_time_ms": 7661.888, "learn_throughput": 522.065, "update_time_ms": 1.547}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 169.26175012896138, "policy_loss": -0.028634636364476655, "vf_loss": 169.28855822163243, "vf_explained_var": [0.05411776527762413], "kl": 0.009131743297115694, "entropy": 0.9827256608393884, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 176000, "num_agent_steps_sampled": 176000, "num_steps_trained": 176000, "num_agent_steps_trained": 176000}, "done": false, "episodes_total": 11732, "training_iteration": 44, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-21-25", "timestamp": 1632518485, "time_this_iter_s": 16.36390781402588, "time_total_s": 652.1400759220123, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 652.1400759220123, "timesteps_since_restore": 0, "iterations_since_restore": 44, "perf": {"cpu_util_percent": 34.49583333333333, "ram_util_percent": 16.0}}
{"episode_reward_max": -17.3, "episode_reward_min": -69.40000000000002, "episode_reward_mean": -44.05037313432836, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 268, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-38.300000000000004, -51.400000000000006, -48.10000000000001, -38.0, -32.7, -52.3, -57.900000000000006, -32.4, -48.6, -39.7, -48.6, -51.900000000000006, -38.800000000000004, -67.5, -52.99999999999999, -26.1, -33.6, -43.2, -45.5, -46.4, -51.6, -30.400000000000002, -36.5, -44.599999999999994, -36.400000000000006, -43.7, -27.2, -42.2, -50.10000000000001, -29.700000000000003, -58.0, -41.7, -59.1, -37.6, -42.0, -46.10000000000001, -46.70000000000001, -37.2, -31.7, -39.6, -51.900000000000006, -44.900000000000006, -59.300000000000004, -51.900000000000006, -36.900000000000006, -43.5, -49.70000000000001, -37.2, -38.1, -56.80000000000002, -42.800000000000004, -62.800000000000004, -38.60000000000001, -33.400000000000006, -42.800000000000004, -52.2, -46.10000000000001, -51.400000000000006, -41.5, -45.400000000000006, -39.300000000000004, -38.80000000000001, -38.60000000000001, -36.099999999999994, -53.400000000000006, -50.900000000000006, -45.099999999999994, -57.199999999999996, -37.5, -53.800000000000004, -55.70000000000002, -43.40000000000001, -47.1, -46.60000000000001, -45.60000000000001, -47.1, -46.7, -37.800000000000004, -51.00000000000001, -47.00000000000001, -36.10000000000001, -51.29999999999999, -38.1, -35.1, -58.70000000000001, -28.6, -46.2, -37.400000000000006, -55.5, -29.4, -56.300000000000004, -28.200000000000003, -57.000000000000014, -26.0, -37.8, -17.3, -36.0, -39.5, -39.10000000000001, -49.2, -41.80000000000001, -43.300000000000004, -35.300000000000004, -33.3, -38.5, -62.80000000000001, -49.5, -48.70000000000002, -34.3, -41.0, -39.800000000000004, -43.60000000000001, -40.900000000000006, -61.800000000000004, -48.7, -46.2, -42.900000000000006, -53.000000000000014, -39.10000000000001, -27.500000000000004, -38.5, -48.00000000000001, -69.40000000000002, -39.0, -38.3, -34.6, -54.500000000000014, -50.50000000000001, -35.7, -58.4, -43.90000000000001, -44.60000000000001, -48.00000000000001, -40.50000000000001, -38.300000000000004, -38.9, -32.800000000000004, -52.1, -34.800000000000004, -42.8, -39.9, -47.2, -40.800000000000004, -47.900000000000006, -61.3, -40.00000000000001, -44.1, -49.900000000000006, -45.7, -48.099999999999994, -42.5, -44.599999999999994, -45.1, -52.800000000000004, -43.400000000000006, -43.900000000000006, -45.5, -44.10000000000001, -44.199999999999996, -48.2, -34.5, -46.9, -53.9, -39.900000000000006, -52.6, -64.9, -46.400000000000006, -55.699999999999996, -43.60000000000001, -45.0, -44.7, -44.2, -46.80000000000001, -55.80000000000001, -40.400000000000006, -37.10000000000001, -35.4, -52.2, -41.2, -43.900000000000006, -46.800000000000004, -51.20000000000001, -29.599999999999998, -44.199999999999996, -39.300000000000004, -63.60000000000001, -46.400000000000006, -41.9, -42.7, -42.300000000000004, -39.2, -36.400000000000006, -63.1, -36.6, -41.50000000000001, -38.7, -53.70000000000001, -46.5, -51.00000000000001, -49.0, -50.10000000000001, -48.30000000000001, -32.0, -43.0, -33.800000000000004, -38.300000000000004, -40.4, -37.800000000000004, -61.6, -56.70000000000002, -38.60000000000001, -48.800000000000004, -32.800000000000004, -46.10000000000001, -48.7, -50.0, -48.400000000000006, -48.80000000000001, -38.0, -36.50000000000001, -38.6, -36.70000000000001, -52.60000000000001, -39.6, -38.0, -36.50000000000001, -35.5, -41.2, -39.1, -38.50000000000001, -44.900000000000006, -47.10000000000001, -42.2, -39.400000000000006, -32.7, -57.20000000000001, -41.1, -44.10000000000001, -59.00000000000001, -39.5, -34.00000000000001, -45.60000000000001, -43.30000000000001, -34.900000000000006, -35.800000000000004, -39.7, -45.8, -33.2, -51.0, -42.50000000000001, -40.800000000000004, -50.2, -45.40000000000001, -41.5, -46.3, -46.8, -43.9, -38.800000000000004, -32.4, -34.3, -62.3, -34.099999999999994, -50.50000000000001, -46.7, -40.400000000000006, -56.30000000000001, -46.40000000000001, -42.0], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13551668485489596, "mean_inference_ms": 1.2297344065243927, "mean_action_processing_ms": 0.05514132505130707, "mean_env_wait_ms": 2.187334307445327, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 180000, "agent_timesteps_total": 180000, "timers": {"sample_time_ms": 7342.036, "sample_throughput": 544.808, "load_time_ms": 0.045, "load_throughput": 89813790.15, "learn_time_ms": 7733.774, "learn_throughput": 517.212, "update_time_ms": 1.569}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 170.89718557378296, "policy_loss": -0.026755183978727268, "vf_loss": 170.92181990428637, "vf_explained_var": [0.057753849774599075], "kl": 0.010601451812117569, "entropy": 0.97102256513411, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 180000, "num_agent_steps_sampled": 180000, "num_steps_trained": 180000, "num_agent_steps_trained": 180000}, "done": false, "episodes_total": 12000, "training_iteration": 45, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-21-41", "timestamp": 1632518501, "time_this_iter_s": 15.096645593643188, "time_total_s": 667.2367215156555, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 667.2367215156555, "timesteps_since_restore": 0, "iterations_since_restore": 45, "perf": {"cpu_util_percent": 34.34761904761905, "ram_util_percent": 16.0}}
{"episode_reward_max": -19.0, "episode_reward_min": -75.09999999999997, "episode_reward_mean": -42.65338345864662, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-50.2, -31.200000000000003, -41.400000000000006, -45.300000000000004, -57.400000000000006, -52.6, -44.3, -48.20000000000001, -37.5, -30.900000000000002, -44.29999999999999, -40.1, -34.0, -34.900000000000006, -44.400000000000006, -42.10000000000001, -25.300000000000004, -47.0, -35.99999999999999, -45.7, -33.50000000000001, -43.9, -75.09999999999997, -52.70000000000002, -44.300000000000004, -45.00000000000001, -29.4, -51.10000000000001, -37.2, -53.00000000000001, -57.7, -42.70000000000001, -38.6, -40.2, -53.800000000000004, -41.7, -30.200000000000003, -43.100000000000016, -46.300000000000004, -56.400000000000006, -45.80000000000001, -39.1, -39.6, -42.400000000000006, -47.800000000000004, -53.4, -56.699999999999996, -39.2, -19.0, -43.20000000000001, -43.900000000000006, -33.900000000000006, -31.900000000000006, -40.3, -28.7, -46.2, -42.80000000000001, -32.800000000000004, -51.50000000000001, -29.300000000000004, -27.8, -44.900000000000006, -43.80000000000001, -35.2, -35.7, -29.000000000000004, -58.000000000000014, -52.49999999999999, -61.5, -46.400000000000006, -49.6, -39.3, -43.60000000000001, -30.800000000000004, -31.2, -54.7, -41.9, -32.300000000000004, -30.1, -41.2, -54.199999999999996, -53.80000000000001, -40.0, -37.900000000000006, -55.1, -41.800000000000004, -43.60000000000001, -56.000000000000014, -44.3, -47.20000000000001, -57.900000000000006, -39.10000000000001, -42.000000000000014, -37.00000000000001, -40.6, -65.9, -42.2, -52.80000000000001, -46.4, -41.80000000000001, -42.900000000000006, -47.400000000000006, -48.30000000000001, -44.7, -58.2, -45.39999999999999, -48.4, -50.099999999999994, -71.70000000000002, -29.100000000000005, -32.9, -44.4, -45.2, -34.6, -47.199999999999996, -46.50000000000001, -52.0, -35.60000000000001, -55.70000000000001, -42.40000000000001, -36.00000000000001, -44.30000000000001, -19.0, -39.9, -29.600000000000005, -49.099999999999994, -35.7, -51.5, -35.300000000000004, -43.2, -43.30000000000001, -37.60000000000001, -38.20000000000001, -61.20000000000001, -42.8, -35.400000000000006, -40.800000000000004, -51.70000000000001, -43.600000000000016, -49.900000000000006, -41.9, -34.9, -41.6, -36.0, -43.1, -43.800000000000004, -39.300000000000004, -39.800000000000004, -32.7, -44.00000000000001, -45.00000000000001, -36.2, -35.5, -53.5, -46.70000000000001, -58.900000000000006, -45.800000000000004, -36.199999999999996, -42.00000000000001, -25.6, -39.800000000000004, -36.400000000000006, -28.5, -55.7, -42.800000000000004, -35.4, -41.1, -36.50000000000001, -39.7, -37.2, -38.400000000000006, -26.299999999999997, -33.3, -50.800000000000004, -46.90000000000001, -38.7, -26.299999999999997, -44.50000000000001, -35.2, -38.50000000000001, -38.800000000000004, -46.30000000000001, -33.0, -43.2, -43.400000000000006, -40.80000000000001, -56.0, -36.300000000000004, -37.6, -44.60000000000001, -45.0, -37.9, -40.7, -44.5, -36.2, -34.4, -35.7, -36.2, -39.400000000000006, -50.400000000000006, -35.8, -44.900000000000006, -32.400000000000006, -54.4, -34.8, -50.70000000000002, -35.5, -50.300000000000004, -33.50000000000001, -42.300000000000004, -33.900000000000006, -44.60000000000001, -41.10000000000001, -34.7, -29.600000000000005, -32.0, -50.60000000000001, -56.2, -30.7, -42.8, -35.3, -45.7, -36.5, -50.000000000000014, -34.6, -64.10000000000001, -40.800000000000004, -43.50000000000001, -37.900000000000006, -49.9, -29.199999999999996, -37.2, -36.50000000000001, -66.4, -49.400000000000006, -32.1, -42.800000000000004, -57.80000000000001, -48.8, -43.100000000000016, -33.3, -46.0, -41.300000000000004, -43.80000000000001, -52.400000000000006, -43.7, -45.8, -42.6, -52.0, -46.900000000000006, -45.5, -36.50000000000001, -31.099999999999998, -65.0, -38.9, -36.800000000000004, -47.900000000000006, -55.20000000000001, -46.80000000000001, -46.000000000000014, -50.6, -44.2, -37.900000000000006, -41.50000000000001, -46.00000000000001, -44.70000000000001], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13544321943874701, "mean_inference_ms": 1.228951111838703, "mean_action_processing_ms": 0.055107025645043294, "mean_env_wait_ms": 2.1844861406374037, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 184000, "agent_timesteps_total": 184000, "timers": {"sample_time_ms": 7345.109, "sample_throughput": 544.58, "load_time_ms": 0.045, "load_throughput": 89669780.866, "learn_time_ms": 7768.969, "learn_throughput": 514.869, "update_time_ms": 1.577}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 163.49978614725092, "policy_loss": -0.027110122152233636, "vf_loss": 163.52487989035987, "vf_explained_var": [0.06906406581401825], "kl": 0.010083658673012521, "entropy": 0.9337497215117178, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 184000, "num_agent_steps_sampled": 184000, "num_steps_trained": 184000, "num_agent_steps_trained": 184000}, "done": false, "episodes_total": 12266, "training_iteration": 46, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-21-56", "timestamp": 1632518516, "time_this_iter_s": 14.943381786346436, "time_total_s": 682.180103302002, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 682.180103302002, "timesteps_since_restore": 0, "iterations_since_restore": 46, "perf": {"cpu_util_percent": 36.33636363636364, "ram_util_percent": 15.963636363636363}}
{"episode_reward_max": -17.0, "episode_reward_min": -71.3, "episode_reward_mean": -41.908646616541354, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-31.5, -44.900000000000006, -46.7, -35.1, -51.0, -33.5, -47.699999999999996, -44.80000000000001, -37.7, -41.7, -52.10000000000001, -50.00000000000001, -39.199999999999996, -32.6, -47.0, -44.6, -33.5, -43.300000000000004, -41.60000000000001, -52.800000000000004, -39.3, -47.300000000000004, -49.800000000000004, -44.5, -32.7, -36.00000000000001, -38.3, -33.800000000000004, -35.4, -41.60000000000001, -40.30000000000001, -38.0, -38.400000000000006, -34.6, -46.4, -42.900000000000006, -36.5, -37.9, -42.900000000000006, -30.700000000000003, -33.900000000000006, -40.0, -47.50000000000001, -34.00000000000001, -39.300000000000004, -42.699999999999996, -53.20000000000001, -54.60000000000001, -35.4, -40.199999999999996, -46.9, -29.400000000000002, -44.7, -52.400000000000006, -36.5, -52.2, -35.5, -41.50000000000001, -25.9, -23.200000000000003, -31.200000000000003, -39.800000000000004, -50.6, -45.300000000000004, -43.800000000000004, -52.6, -33.800000000000004, -47.00000000000001, -55.5, -31.0, -60.20000000000001, -28.0, -37.6, -40.2, -54.5, -29.1, -47.500000000000014, -42.3, -46.300000000000004, -31.500000000000004, -22.5, -36.6, -40.800000000000004, -44.1, -49.20000000000002, -49.60000000000001, -39.60000000000001, -44.1, -45.50000000000001, -42.400000000000006, -51.199999999999996, -31.100000000000005, -36.6, -45.8, -50.800000000000004, -27.6, -54.20000000000001, -36.300000000000004, -40.00000000000001, -36.099999999999994, -34.50000000000001, -48.2, -42.1, -36.5, -26.6, -41.5, -38.0, -37.1, -35.5, -43.300000000000004, -46.10000000000001, -59.50000000000001, -17.0, -47.80000000000001, -54.39999999999999, -50.3, -42.7, -38.400000000000006, -68.99999999999997, -52.30000000000001, -32.6, -32.900000000000006, -31.8, -57.5, -44.4, -34.6, -32.2, -41.70000000000001, -30.000000000000004, -46.1, -54.60000000000001, -28.700000000000003, -60.90000000000002, -39.699999999999996, -66.30000000000001, -41.5, -44.9, -47.50000000000001, -48.4, -43.40000000000001, -34.6, -60.500000000000014, -53.0, -39.1, -39.2, -46.300000000000004, -39.2, -29.500000000000004, -38.2, -45.800000000000004, -38.10000000000001, -47.199999999999996, -41.6, -39.8, -44.8, -50.100000000000016, -32.4, -45.1, -52.10000000000001, -45.800000000000004, -54.30000000000001, -44.2, -45.300000000000004, -43.300000000000004, -36.400000000000006, -35.2, -45.60000000000001, -41.80000000000001, -38.5, -42.300000000000004, -36.0, -50.400000000000006, -43.3, -40.2, -39.50000000000001, -46.99999999999999, -24.700000000000003, -36.4, -39.900000000000006, -47.400000000000006, -34.900000000000006, -29.900000000000002, -40.400000000000006, -28.900000000000002, -39.0, -28.600000000000005, -35.7, -44.6, -40.5, -50.80000000000001, -43.80000000000001, -46.20000000000002, -32.400000000000006, -21.000000000000004, -43.2, -37.1, -54.70000000000001, -53.20000000000002, -45.00000000000001, -49.2, -45.9, -42.60000000000001, -64.9, -38.20000000000001, -36.5, -49.000000000000014, -52.50000000000001, -41.4, -71.3, -43.6, -36.3, -34.7, -33.0, -43.7, -39.50000000000001, -50.3, -40.400000000000006, -46.40000000000001, -47.400000000000006, -39.900000000000006, -50.900000000000006, -37.0, -37.2, -39.400000000000006, -42.599999999999994, -43.9, -50.2, -31.2, -34.900000000000006, -45.4, -29.700000000000003, -37.10000000000001, -47.1, -39.7, -59.20000000000002, -34.7, -39.400000000000006, -54.60000000000001, -44.80000000000001, -52.0, -45.50000000000001, -48.900000000000006, -28.400000000000002, -26.7, -44.7, -36.6, -60.900000000000006, -45.50000000000001, -28.900000000000002, -37.90000000000001, -52.00000000000001, -38.0, -33.9, -26.799999999999997, -47.2, -39.10000000000001, -39.699999999999996, -50.800000000000004, -35.9, -33.800000000000004, -37.50000000000001, -48.800000000000004, -47.400000000000006, -35.1, -63.900000000000006, -32.1], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13579268390625773, "mean_inference_ms": 1.2324003385440603, "mean_action_processing_ms": 0.05525901780960551, "mean_env_wait_ms": 2.1867934881964266, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 188000, "agent_timesteps_total": 188000, "timers": {"sample_time_ms": 7416.005, "sample_throughput": 539.374, "load_time_ms": 0.045, "load_throughput": 88768338.624, "learn_time_ms": 7979.874, "learn_throughput": 501.261, "update_time_ms": 1.616}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 159.49540662047684, "policy_loss": -0.02771533182521741, "vf_loss": 159.52114151985415, "vf_explained_var": [0.05872707441449165], "kl": 0.009898930689391185, "entropy": 0.9142489185897252, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 188000, "num_agent_steps_sampled": 188000, "num_steps_trained": 188000, "num_agent_steps_trained": 188000}, "done": false, "episodes_total": 12532, "training_iteration": 47, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-22-13", "timestamp": 1632518533, "time_this_iter_s": 17.065120935440063, "time_total_s": 699.245224237442, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 699.245224237442, "timesteps_since_restore": 0, "iterations_since_restore": 47, "perf": {"cpu_util_percent": 34.895833333333336, "ram_util_percent": 15.995833333333332}}
{"episode_reward_max": -13.900000000000002, "episode_reward_min": -94.39999999999998, "episode_reward_mean": -42.66268656716418, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 268, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-43.9, -27.6, -39.8, -37.6, -55.400000000000006, -41.400000000000006, -24.1, -40.300000000000004, -42.7, -47.80000000000001, -28.400000000000002, -53.400000000000006, -52.4, -43.300000000000004, -47.400000000000006, -36.0, -29.700000000000003, -54.6, -42.300000000000004, -39.2, -37.9, -64.7, -39.1, -43.1, -40.7, -61.60000000000001, -54.4, -24.900000000000006, -34.6, -48.00000000000001, -40.7, -42.10000000000001, -44.0, -54.3, -30.300000000000004, -36.00000000000001, -46.40000000000001, -49.5, -29.300000000000004, -35.5, -47.300000000000004, -46.800000000000004, -35.900000000000006, -47.60000000000001, -30.700000000000003, -43.99999999999999, -53.6, -43.699999999999996, -44.599999999999994, -44.7, -33.7, -34.6, -37.4, -38.7, -39.900000000000006, -36.3, -31.8, -46.000000000000014, -46.1, -48.6, -45.199999999999996, -52.199999999999996, -51.20000000000001, -25.4, -34.60000000000001, -48.900000000000006, -51.10000000000001, -35.7, -41.7, -45.800000000000004, -38.800000000000004, -50.5, -52.50000000000001, -35.6, -46.0, -48.30000000000001, -52.5, -38.800000000000004, -38.0, -52.000000000000014, -39.70000000000001, -31.6, -42.4, -40.7, -65.50000000000001, -43.199999999999996, -29.499999999999996, -40.7, -42.900000000000006, -45.300000000000004, -27.500000000000007, -44.599999999999994, -42.7, -40.599999999999994, -32.900000000000006, -40.2, -50.00000000000001, -43.699999999999996, -40.10000000000001, -58.400000000000006, -54.4, -51.10000000000001, -37.7, -34.50000000000001, -49.00000000000001, -52.10000000000001, -51.400000000000006, -40.50000000000001, -41.50000000000001, -38.0, -45.90000000000001, -43.2, -45.5, -48.2, -52.50000000000001, -36.2, -49.7, -37.7, -50.20000000000001, -38.2, -30.700000000000003, -41.50000000000001, -43.7, -29.499999999999996, -63.50000000000001, -34.699999999999996, -47.60000000000001, -44.4, -46.400000000000006, -41.800000000000004, -44.2, -39.400000000000006, -50.90000000000001, -46.6, -57.20000000000001, -47.2, -53.20000000000001, -45.10000000000001, -48.9, -55.50000000000001, -36.50000000000001, -54.20000000000001, -56.2, -41.80000000000001, -42.20000000000001, -42.00000000000001, -26.3, -35.6, -35.400000000000006, -13.900000000000002, -46.300000000000004, -53.40000000000002, -52.0, -47.400000000000006, -34.40000000000001, -48.80000000000001, -43.300000000000004, -49.800000000000004, -42.5, -47.10000000000001, -58.800000000000004, -34.4, -33.1, -34.800000000000004, -51.1, -47.1, -18.599999999999998, -31.6, -30.1, -53.10000000000001, -37.300000000000004, -28.300000000000004, -53.300000000000004, -50.2, -27.599999999999998, -47.4, -44.300000000000004, -34.1, -35.800000000000004, -37.6, -35.800000000000004, -39.6, -94.39999999999998, -42.2, -49.2, -54.300000000000004, -32.2, -29.799999999999997, -24.8, -56.39999999999999, -46.1, -40.70000000000001, -29.9, -48.800000000000004, -44.5, -42.000000000000014, -42.7, -28.799999999999997, -44.2, -40.400000000000006, -55.900000000000006, -40.6, -24.6, -29.9, -52.80000000000001, -38.80000000000001, -29.1, -45.10000000000001, -41.400000000000006, -27.000000000000004, -36.900000000000006, -60.900000000000006, -47.400000000000006, -36.2, -58.20000000000002, -35.7, -38.6, -39.20000000000001, -32.800000000000004, -42.300000000000004, -34.2, -51.80000000000001, -40.00000000000001, -47.70000000000001, -34.800000000000004, -25.800000000000004, -48.2, -44.0, -54.199999999999996, -30.600000000000005, -32.300000000000004, -36.800000000000004, -39.80000000000001, -39.2, -42.2, -50.2, -42.60000000000001, -48.7, -34.2, -37.6, -48.400000000000006, -45.5, -33.8, -56.30000000000001, -38.50000000000001, -56.60000000000001, -46.2, -55.400000000000006, -44.900000000000006, -43.300000000000004, -47.300000000000004, -46.20000000000001, -45.6, -42.300000000000004, -50.800000000000004, -37.300000000000004, -29.400000000000006, -35.00000000000001, -49.800000000000004, -52.60000000000001, -59.50000000000001, -44.00000000000001, -43.20000000000001, -54.00000000000001, -27.6, -41.900000000000006, -39.2, -33.3], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13602089506143272, "mean_inference_ms": 1.2341419809394893, "mean_action_processing_ms": 0.055330804054407344, "mean_env_wait_ms": 2.1866478064019454, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 192000, "agent_timesteps_total": 192000, "timers": {"sample_time_ms": 7467.86, "sample_throughput": 535.629, "load_time_ms": 0.046, "load_throughput": 87381333.333, "learn_time_ms": 8041.876, "learn_throughput": 497.396, "update_time_ms": 1.616}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 163.02950115408947, "policy_loss": -0.021158642992277137, "vf_loss": 163.04899963871125, "vf_explained_var": [0.0721336305141449], "kl": 0.00829821293094083, "entropy": 0.8797582887834118, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 192000, "num_agent_steps_sampled": 192000, "num_steps_trained": 192000, "num_agent_steps_trained": 192000}, "done": false, "episodes_total": 12800, "training_iteration": 48, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-22-28", "timestamp": 1632518548, "time_this_iter_s": 15.503888845443726, "time_total_s": 714.7491130828857, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 714.7491130828857, "timesteps_since_restore": 0, "iterations_since_restore": 48, "perf": {"cpu_util_percent": 34.650000000000006, "ram_util_percent": 16.0}}
{"episode_reward_max": -21.6, "episode_reward_min": -71.09999999999998, "episode_reward_mean": -41.61691729323309, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-46.9, -51.70000000000001, -46.90000000000001, -32.300000000000004, -37.50000000000001, -48.70000000000001, -35.400000000000006, -58.20000000000001, -38.7, -56.2, -34.6, -33.1, -40.300000000000004, -37.89999999999999, -53.500000000000014, -53.0, -40.900000000000006, -31.300000000000004, -42.5, -43.60000000000001, -43.2, -36.9, -44.60000000000001, -35.50000000000001, -40.5, -21.6, -28.300000000000004, -38.400000000000006, -40.70000000000001, -33.199999999999996, -52.00000000000001, -51.900000000000006, -44.50000000000001, -42.10000000000001, -53.7, -47.0, -48.699999999999996, -39.1, -54.800000000000004, -36.0, -26.800000000000004, -41.800000000000004, -45.300000000000004, -43.90000000000001, -47.70000000000001, -45.300000000000004, -37.9, -42.9, -38.6, -44.6, -71.09999999999998, -41.0, -43.20000000000001, -42.0, -44.1, -36.900000000000006, -32.6, -41.80000000000001, -50.2, -37.5, -42.199999999999996, -58.40000000000001, -39.60000000000001, -43.60000000000001, -27.800000000000004, -54.800000000000004, -42.900000000000006, -40.400000000000006, -53.0, -57.2, -52.60000000000001, -47.9, -26.000000000000007, -46.70000000000001, -36.6, -42.5, -36.3, -29.400000000000002, -41.00000000000001, -48.70000000000001, -67.30000000000001, -36.1, -44.900000000000006, -48.5, -47.7, -37.7, -30.300000000000004, -55.300000000000004, -35.6, -35.2, -31.900000000000002, -40.400000000000006, -60.60000000000001, -54.900000000000006, -53.1, -29.700000000000003, -29.8, -53.30000000000001, -43.2, -45.800000000000004, -44.0, -37.300000000000004, -40.6, -42.300000000000004, -33.7, -38.900000000000006, -54.5, -30.800000000000004, -44.60000000000001, -32.7, -27.000000000000004, -32.400000000000006, -28.200000000000003, -40.10000000000001, -44.50000000000001, -42.900000000000006, -51.50000000000001, -30.0, -61.699999999999996, -55.2, -31.0, -35.2, -46.4, -39.9, -40.30000000000001, -41.00000000000001, -40.800000000000004, -33.2, -30.5, -39.4, -37.300000000000004, -40.00000000000001, -43.900000000000006, -50.800000000000004, -28.300000000000004, -46.30000000000001, -46.0, -43.9, -43.60000000000001, -32.3, -39.800000000000004, -47.699999999999996, -28.8, -32.0, -47.00000000000001, -40.2, -31.200000000000003, -41.60000000000001, -36.400000000000006, -41.2, -34.6, -29.500000000000004, -42.6, -46.0, -37.800000000000004, -47.50000000000001, -38.6, -47.7, -34.60000000000001, -42.50000000000001, -33.00000000000001, -33.300000000000004, -38.099999999999994, -37.4, -33.50000000000001, -47.2, -37.0, -44.20000000000001, -42.20000000000001, -53.900000000000006, -50.7, -48.10000000000001, -40.5, -44.60000000000001, -37.2, -40.10000000000001, -28.000000000000004, -63.900000000000006, -52.400000000000006, -33.400000000000006, -29.1, -37.49999999999999, -44.70000000000001, -54.20000000000002, -42.10000000000001, -34.800000000000004, -45.10000000000001, -39.1, -58.2, -38.10000000000001, -38.400000000000006, -48.800000000000004, -38.3, -36.50000000000001, -37.400000000000006, -46.50000000000001, -48.10000000000001, -37.60000000000001, -44.7, -48.50000000000001, -36.3, -41.6, -39.599999999999994, -48.0, -45.400000000000006, -55.30000000000001, -48.0, -43.5, -48.900000000000006, -45.0, -25.9, -41.7, -53.4, -34.5, -43.3, -40.0, -35.800000000000004, -60.000000000000014, -43.300000000000004, -47.4, -30.0, -43.900000000000006, -33.400000000000006, -39.099999999999994, -37.699999999999996, -27.7, -38.1, -47.89999999999999, -41.4, -47.099999999999994, -32.2, -41.300000000000004, -30.8, -38.7, -29.0, -39.70000000000001, -39.599999999999994, -38.8, -62.00000000000001, -35.60000000000001, -24.799999999999997, -44.300000000000004, -33.400000000000006, -44.300000000000004, -38.9, -62.000000000000014, -47.900000000000006, -40.400000000000006, -50.60000000000001, -33.2, -34.300000000000004, -46.10000000000001, -40.7, -25.700000000000003, -36.2, -55.60000000000001, -43.3, -32.30000000000001, -48.7, -43.3, -37.10000000000001, -37.50000000000001, -39.7, -32.2, -28.400000000000002, -41.60000000000001], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13615260059639556, "mean_inference_ms": 1.2351067275098693, "mean_action_processing_ms": 0.05537932678696608, "mean_env_wait_ms": 2.1850118184483525, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 196000, "agent_timesteps_total": 196000, "timers": {"sample_time_ms": 7484.535, "sample_throughput": 534.435, "load_time_ms": 0.047, "load_throughput": 85773087.935, "learn_time_ms": 8167.879, "learn_throughput": 489.723, "update_time_ms": 1.639}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 153.2234772466844, "policy_loss": -0.022311295274024208, "vf_loss": 153.24415417742986, "vf_explained_var": [0.06642981618642807], "kl": 0.008171061879601637, "entropy": 0.8827549151835903, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 196000, "num_agent_steps_sampled": 196000, "num_steps_trained": 196000, "num_agent_steps_trained": 196000}, "done": false, "episodes_total": 13066, "training_iteration": 49, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-22-44", "timestamp": 1632518564, "time_this_iter_s": 15.700546503067017, "time_total_s": 730.4496595859528, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 730.4496595859528, "timesteps_since_restore": 0, "iterations_since_restore": 49, "perf": {"cpu_util_percent": 35.74347826086956, "ram_util_percent": 15.991304347826087}}
{"episode_reward_max": -14.200000000000001, "episode_reward_min": -70.40000000000002, "episode_reward_mean": -42.468421052631584, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-44.5, -39.400000000000006, -52.400000000000006, -49.9, -25.6, -38.6, -38.2, -24.5, -31.8, -40.7, -38.7, -41.900000000000006, -45.900000000000006, -56.60000000000001, -39.800000000000004, -48.2, -41.900000000000006, -60.300000000000004, -49.300000000000004, -41.1, -52.6, -42.400000000000006, -50.80000000000001, -36.6, -44.0, -34.800000000000004, -55.099999999999994, -29.7, -34.800000000000004, -25.6, -48.800000000000004, -39.4, -38.800000000000004, -21.0, -32.300000000000004, -50.6, -46.6, -35.300000000000004, -46.2, -39.8, -70.40000000000002, -42.8, -47.2, -45.80000000000001, -39.2, -43.8, -53.800000000000004, -33.900000000000006, -27.2, -41.60000000000001, -48.0, -55.60000000000001, -46.199999999999996, -43.79999999999999, -44.400000000000006, -57.60000000000001, -43.0, -58.400000000000006, -43.3, -56.70000000000001, -51.0, -54.4, -40.2, -43.50000000000001, -43.4, -43.3, -47.00000000000001, -24.5, -32.800000000000004, -36.4, -33.6, -33.4, -48.300000000000004, -33.6, -35.49999999999999, -29.0, -40.300000000000004, -41.0, -45.50000000000001, -39.2, -38.5, -14.200000000000001, -32.9, -42.8, -46.5, -26.300000000000004, -42.1, -56.80000000000001, -31.800000000000004, -46.5, -29.700000000000003, -37.199999999999996, -34.2, -54.20000000000001, -36.6, -42.70000000000001, -36.00000000000001, -38.6, -41.9, -35.0, -46.00000000000001, -39.900000000000006, -35.5, -30.5, -36.3, -63.1, -39.699999999999996, -40.9, -43.10000000000001, -46.2, -40.50000000000001, -52.4, -42.2, -42.2, -42.300000000000004, -29.000000000000004, -48.5, -33.9, -45.400000000000006, -52.800000000000004, -46.400000000000006, -50.10000000000001, -53.80000000000002, -40.9, -49.300000000000004, -45.7, -40.00000000000001, -46.10000000000001, -44.300000000000004, -35.00000000000001, -38.0, -49.7, -38.900000000000006, -65.30000000000001, -43.6, -57.300000000000004, -36.0, -47.00000000000001, -41.6, -47.8, -33.60000000000001, -46.400000000000006, -53.800000000000004, -37.2, -33.4, -41.0, -19.5, -38.50000000000001, -41.2, -48.00000000000001, -55.000000000000014, -40.699999999999996, -32.4, -57.30000000000001, -36.6, -27.100000000000005, -36.800000000000004, -27.9, -53.900000000000006, -40.80000000000001, -51.60000000000001, -41.40000000000001, -32.300000000000004, -40.50000000000001, -32.400000000000006, -35.5, -31.900000000000002, -35.3, -43.400000000000006, -45.00000000000001, -33.1, -33.5, -53.9, -42.0, -68.50000000000001, -48.80000000000001, -36.6, -44.9, -49.100000000000016, -28.3, -40.7, -41.7, -53.000000000000014, -62.50000000000001, -54.60000000000001, -47.2, -37.7, -43.6, -46.800000000000004, -39.1, -36.300000000000004, -45.400000000000006, -56.00000000000001, -46.60000000000001, -40.2, -26.6, -55.80000000000001, -47.60000000000001, -32.3, -59.6, -45.00000000000001, -45.300000000000004, -32.1, -45.400000000000006, -34.2, -40.0, -40.7, -47.0, -35.300000000000004, -38.60000000000001, -62.000000000000014, -40.8, -39.3, -33.0, -38.900000000000006, -44.10000000000001, -51.6, -49.60000000000001, -49.800000000000004, -46.70000000000001, -43.300000000000004, -44.7, -44.8, -36.0, -50.1, -49.400000000000006, -59.599999999999994, -45.30000000000001, -40.5, -33.5, -33.2, -49.50000000000001, -29.8, -40.800000000000004, -52.49999999999999, -41.900000000000006, -40.800000000000004, -26.999999999999996, -40.199999999999996, -36.800000000000004, -49.10000000000001, -44.6, -40.50000000000001, -50.800000000000004, -39.800000000000004, -50.6, -30.000000000000004, -34.900000000000006, -59.900000000000006, -26.900000000000002, -40.6, -48.100000000000016, -39.7, -48.2, -38.30000000000001, -62.90000000000001, -27.900000000000002, -44.6, -41.099999999999994, -43.300000000000004, -41.7, -48.900000000000006, -43.1, -48.30000000000001, -40.70000000000001, -45.8], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13635007645208583, "mean_inference_ms": 1.2371214142720788, "mean_action_processing_ms": 0.05547489362104365, "mean_env_wait_ms": 2.18506639282057, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 200000, "agent_timesteps_total": 200000, "timers": {"sample_time_ms": 7552.646, "sample_throughput": 529.616, "load_time_ms": 0.047, "load_throughput": 85206785.17, "learn_time_ms": 8245.769, "learn_throughput": 485.097, "update_time_ms": 1.722}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 160.31034660749538, "policy_loss": -0.027048698118236916, "vf_loss": 160.3353180013677, "vf_explained_var": [0.05651084706187248], "kl": 0.010387194266536864, "entropy": 0.8599490548974724, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 200000, "num_agent_steps_sampled": 200000, "num_steps_trained": 200000, "num_agent_steps_trained": 200000}, "done": false, "episodes_total": 13332, "training_iteration": 50, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-22-59", "timestamp": 1632518579, "time_this_iter_s": 15.354965925216675, "time_total_s": 745.8046255111694, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 745.8046255111694, "timesteps_since_restore": 0, "iterations_since_restore": 50, "perf": {"cpu_util_percent": 34.87272727272727, "ram_util_percent": 16.0}}
{"episode_reward_max": -24.099999999999998, "episode_reward_min": -77.10000000000001, "episode_reward_mean": -42.658208955223884, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 268, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-54.5, -26.9, -46.5, -43.6, -51.7, -34.2, -35.900000000000006, -43.400000000000006, -49.400000000000006, -56.600000000000016, -43.400000000000006, -29.300000000000004, -30.0, -37.0, -41.00000000000001, -38.7, -42.400000000000006, -43.0, -43.3, -56.20000000000002, -36.8, -38.6, -56.70000000000002, -24.299999999999997, -35.6, -34.2, -42.6, -56.2, -41.2, -30.799999999999997, -34.9, -48.900000000000006, -47.900000000000006, -44.300000000000004, -55.5, -41.10000000000001, -48.800000000000004, -77.10000000000001, -51.70000000000001, -51.20000000000001, -30.700000000000006, -41.5, -53.400000000000006, -38.300000000000004, -44.2, -27.300000000000004, -38.300000000000004, -45.7, -34.0, -49.60000000000001, -53.30000000000001, -41.5, -41.800000000000004, -53.10000000000001, -33.300000000000004, -33.10000000000001, -50.10000000000001, -51.699999999999996, -36.6, -44.400000000000006, -39.0, -28.800000000000004, -32.300000000000004, -43.50000000000001, -46.300000000000004, -32.0, -46.600000000000016, -52.900000000000006, -33.50000000000001, -52.9, -34.0, -47.900000000000006, -50.50000000000001, -50.4, -50.300000000000004, -24.500000000000004, -51.60000000000001, -43.7, -41.7, -44.4, -32.3, -52.1, -38.5, -48.500000000000014, -48.60000000000001, -37.400000000000006, -26.400000000000006, -38.1, -46.7, -37.70000000000001, -26.5, -47.5, -48.2, -50.400000000000006, -40.2, -48.20000000000001, -27.5, -43.900000000000006, -43.00000000000001, -53.80000000000001, -48.30000000000001, -24.099999999999998, -42.80000000000001, -28.900000000000002, -38.900000000000006, -45.300000000000004, -44.0, -32.800000000000004, -49.2, -34.1, -49.6, -38.2, -48.9, -41.3, -45.1, -39.800000000000004, -25.6, -32.0, -51.80000000000001, -54.0, -44.5, -51.400000000000006, -45.2, -49.50000000000001, -47.10000000000001, -44.7, -32.800000000000004, -37.0, -46.400000000000006, -48.50000000000001, -69.70000000000002, -39.900000000000006, -36.7, -46.900000000000006, -44.40000000000001, -27.600000000000005, -36.599999999999994, -27.099999999999998, -47.70000000000001, -39.60000000000001, -28.099999999999998, -32.4, -42.7, -37.8, -48.400000000000006, -42.70000000000002, -39.900000000000006, -49.300000000000004, -37.60000000000001, -43.00000000000001, -46.400000000000006, -39.80000000000001, -34.800000000000004, -40.400000000000006, -48.60000000000001, -36.1, -37.300000000000004, -36.5, -40.60000000000001, -44.6, -48.00000000000001, -49.900000000000006, -42.00000000000001, -37.6, -52.2, -34.8, -38.1, -50.50000000000001, -37.900000000000006, -74.6, -43.300000000000004, -52.60000000000001, -34.7, -34.9, -49.1, -53.00000000000001, -33.3, -51.00000000000001, -35.00000000000001, -40.1, -36.1, -47.400000000000006, -39.80000000000001, -28.300000000000004, -54.10000000000001, -33.599999999999994, -47.2, -50.50000000000001, -43.30000000000001, -32.70000000000001, -28.500000000000004, -44.10000000000001, -43.6, -59.300000000000004, -44.2, -31.8, -52.30000000000001, -49.30000000000001, -38.099999999999994, -46.4, -40.2, -35.1, -43.900000000000006, -32.1, -53.000000000000014, -45.00000000000001, -47.8, -39.099999999999994, -43.50000000000001, -28.799999999999997, -58.90000000000001, -41.300000000000004, -45.300000000000004, -54.8, -33.00000000000001, -55.00000000000001, -28.800000000000004, -47.500000000000014, -40.1, -39.6, -26.9, -40.400000000000006, -46.300000000000004, -47.6, -39.800000000000004, -53.600000000000016, -45.300000000000004, -39.90000000000001, -37.1, -59.199999999999996, -36.9, -42.60000000000001, -53.900000000000006, -37.60000000000001, -32.300000000000004, -45.599999999999994, -25.2, -45.900000000000006, -37.800000000000004, -40.300000000000004, -48.4, -51.3, -26.200000000000003, -55.30000000000001, -46.2, -54.20000000000001, -49.5, -37.50000000000001, -67.7, -36.9, -42.20000000000001, -42.300000000000004, -35.300000000000004, -55.2, -51.5, -35.8, -49.60000000000001, -42.2, -34.6, -37.800000000000004, -39.6, -62.00000000000001, -37.5, -40.800000000000004, -43.00000000000001, -45.30000000000001, -38.400000000000006, -41.300000000000004], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13620148623588382, "mean_inference_ms": 1.2353380383620645, "mean_action_processing_ms": 0.05540163757448082, "mean_env_wait_ms": 2.181442062922154, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 204000, "agent_timesteps_total": 204000, "timers": {"sample_time_ms": 7535.661, "sample_throughput": 530.809, "load_time_ms": 0.047, "load_throughput": 85206785.17, "learn_time_ms": 8274.439, "learn_throughput": 483.416, "update_time_ms": 1.709}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 164.57076777796593, "policy_loss": -0.026664669557364396, "vf_loss": 164.59541963966944, "vf_explained_var": [0.06836757063865662], "kl": 0.010063582351011513, "entropy": 0.8221790266934261, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 204000, "num_agent_steps_sampled": 204000, "num_steps_trained": 204000, "num_agent_steps_trained": 204000}, "done": false, "episodes_total": 13600, "training_iteration": 51, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-23-14", "timestamp": 1632518594, "time_this_iter_s": 14.134443044662476, "time_total_s": 759.9390685558319, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 759.9390685558319, "timesteps_since_restore": 0, "iterations_since_restore": 51, "perf": {"cpu_util_percent": 34.894999999999996, "ram_util_percent": 16.0}}
{"episode_reward_max": -19.799999999999997, "episode_reward_min": -73.7, "episode_reward_mean": -42.0515037593985, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-60.600000000000016, -41.900000000000006, -44.0, -37.00000000000001, -50.80000000000001, -43.2, -32.1, -40.300000000000004, -42.4, -33.1, -51.10000000000001, -55.8, -43.400000000000006, -25.2, -42.900000000000006, -40.60000000000001, -64.9, -35.7, -45.2, -52.70000000000001, -44.00000000000001, -46.5, -22.900000000000002, -38.5, -41.800000000000004, -40.9, -39.2, -43.400000000000006, -37.900000000000006, -39.2, -27.8, -45.10000000000001, -44.900000000000006, -45.400000000000006, -20.900000000000002, -39.6, -42.60000000000001, -40.199999999999996, -32.7, -67.19999999999999, -34.900000000000006, -47.5, -38.10000000000001, -41.6, -39.50000000000001, -32.9, -40.9, -55.400000000000006, -66.3, -46.300000000000004, -26.000000000000004, -36.6, -38.6, -49.30000000000001, -42.6, -49.0, -35.300000000000004, -52.900000000000006, -35.900000000000006, -50.0, -41.900000000000006, -36.00000000000001, -66.70000000000002, -47.3, -43.20000000000001, -36.5, -37.60000000000001, -24.000000000000004, -46.10000000000001, -50.300000000000004, -50.400000000000006, -44.300000000000004, -48.599999999999994, -43.2, -36.2, -43.800000000000004, -36.5, -53.1, -47.20000000000001, -41.900000000000006, -27.400000000000002, -33.300000000000004, -39.50000000000001, -55.5, -34.7, -33.9, -32.900000000000006, -48.7, -54.49999999999999, -65.2, -39.7, -45.4, -33.00000000000001, -39.300000000000004, -50.9, -45.9, -19.799999999999997, -41.3, -44.9, -45.8, -44.00000000000001, -22.600000000000005, -51.300000000000004, -44.1, -44.00000000000001, -45.7, -43.800000000000004, -27.700000000000003, -51.80000000000002, -40.50000000000001, -32.7, -48.3, -56.900000000000006, -50.800000000000004, -58.4, -31.0, -39.1, -42.90000000000001, -42.70000000000001, -31.400000000000002, -61.699999999999996, -41.50000000000001, -25.700000000000003, -58.60000000000001, -30.900000000000002, -44.900000000000006, -37.300000000000004, -51.2, -36.6, -42.300000000000004, -34.400000000000006, -51.50000000000001, -48.4, -37.5, -53.00000000000001, -58.8, -33.9, -49.9, -38.900000000000006, -43.5, -44.199999999999996, -48.4, -37.6, -47.0, -41.1, -37.199999999999996, -65.4, -42.099999999999994, -48.70000000000001, -37.00000000000001, -45.199999999999996, -31.2, -38.400000000000006, -55.60000000000001, -38.5, -42.0, -47.300000000000004, -73.7, -49.00000000000001, -46.300000000000004, -44.10000000000001, -47.800000000000004, -34.7, -42.6, -40.400000000000006, -32.2, -41.8, -52.2, -34.00000000000001, -47.900000000000006, -40.30000000000001, -31.0, -39.900000000000006, -47.0, -28.1, -49.0, -43.4, -43.00000000000001, -48.80000000000001, -47.800000000000004, -26.7, -47.1, -32.2, -56.20000000000001, -38.0, -59.50000000000001, -48.9, -33.6, -40.1, -37.7, -26.700000000000006, -57.400000000000006, -44.4, -37.9, -47.50000000000001, -29.3, -36.1, -35.7, -37.7, -39.8, -37.6, -52.80000000000001, -31.700000000000003, -33.60000000000001, -37.400000000000006, -32.2, -41.00000000000001, -40.5, -24.0, -28.900000000000002, -56.7, -27.700000000000006, -25.900000000000002, -49.2, -34.9, -37.1, -35.8, -37.400000000000006, -29.300000000000004, -47.7, -48.50000000000001, -35.800000000000004, -33.7, -34.4, -49.50000000000001, -48.7, -41.5, -32.199999999999996, -50.00000000000001, -38.699999999999996, -35.7, -29.3, -37.800000000000004, -38.9, -29.400000000000002, -34.0, -28.000000000000004, -49.40000000000001, -37.3, -53.400000000000006, -41.20000000000001, -50.099999999999994, -45.50000000000001, -35.0, -48.000000000000014, -35.7, -42.400000000000006, -42.5, -43.1, -45.0, -46.00000000000001, -47.0, -51.100000000000016, -48.599999999999994, -40.7, -27.000000000000004, -53.60000000000001, -55.7, -41.1, -31.900000000000002, -41.00000000000001, -55.3, -33.9, -46.10000000000001, -28.4, -38.0], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13606841584283377, "mean_inference_ms": 1.2339230352907855, "mean_action_processing_ms": 0.055343697556413066, "mean_env_wait_ms": 2.1783656335159214, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 208000, "agent_timesteps_total": 208000, "timers": {"sample_time_ms": 7429.339, "sample_throughput": 538.406, "load_time_ms": 0.047, "load_throughput": 85163532.995, "learn_time_ms": 8122.665, "learn_throughput": 492.449, "update_time_ms": 1.629}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 160.06402169504474, "policy_loss": -0.02419827757553468, "vf_loss": 160.08647581531156, "vf_explained_var": [0.07114501297473907], "kl": 0.008718003387381103, "entropy": 0.8391064358654843, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 208000, "num_agent_steps_sampled": 208000, "num_steps_trained": 208000, "num_agent_steps_trained": 208000}, "done": false, "episodes_total": 13866, "training_iteration": 52, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-23-28", "timestamp": 1632518608, "time_this_iter_s": 14.37632942199707, "time_total_s": 774.315397977829, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 774.315397977829, "timesteps_since_restore": 0, "iterations_since_restore": 52, "perf": {"cpu_util_percent": 35.28571428571428, "ram_util_percent": 16.0}}
{"episode_reward_max": -19.9, "episode_reward_min": -74.4, "episode_reward_mean": -42.285714285714285, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-33.2, -45.0, -57.80000000000001, -28.6, -51.49999999999999, -28.400000000000002, -58.9, -36.9, -44.40000000000001, -45.400000000000006, -50.80000000000001, -33.0, -40.900000000000006, -54.400000000000006, -45.50000000000001, -38.4, -54.7, -32.199999999999996, -59.60000000000001, -50.10000000000001, -35.7, -53.6, -48.000000000000014, -42.4, -30.799999999999997, -38.0, -32.3, -32.9, -42.5, -39.20000000000001, -27.400000000000002, -37.50000000000001, -35.6, -49.10000000000001, -37.900000000000006, -40.7, -35.7, -42.7, -45.10000000000001, -55.70000000000001, -45.1, -45.0, -47.6, -44.50000000000001, -39.4, -49.5, -41.400000000000006, -50.1, -41.400000000000006, -34.0, -40.80000000000001, -41.8, -36.6, -30.200000000000003, -30.3, -40.300000000000004, -45.0, -41.900000000000006, -30.1, -58.20000000000001, -45.800000000000004, -38.400000000000006, -46.0, -46.199999999999996, -52.7, -46.40000000000001, -33.99999999999999, -41.6, -31.1, -29.900000000000002, -50.90000000000001, -33.4, -41.9, -45.2, -40.7, -36.8, -31.600000000000005, -50.300000000000004, -34.0, -31.500000000000007, -32.4, -45.50000000000001, -43.0, -35.699999999999996, -28.8, -44.9, -34.4, -38.6, -31.900000000000006, -42.9, -31.800000000000004, -51.90000000000001, -56.1, -40.300000000000004, -48.1, -39.0, -46.3, -43.0, -29.500000000000004, -51.400000000000006, -35.0, -48.7, -32.400000000000006, -46.5, -54.10000000000002, -34.9, -50.6, -37.0, -41.400000000000006, -58.30000000000001, -50.800000000000004, -42.1, -32.300000000000004, -24.700000000000003, -36.6, -37.4, -47.400000000000006, -36.6, -43.30000000000001, -45.60000000000001, -42.4, -47.60000000000001, -38.60000000000001, -43.50000000000001, -44.0, -45.50000000000001, -36.0, -31.700000000000003, -40.800000000000004, -33.0, -45.2, -37.300000000000004, -38.400000000000006, -50.9, -49.6, -37.0, -49.900000000000006, -45.900000000000006, -20.300000000000004, -48.70000000000001, -59.900000000000006, -46.300000000000004, -46.0, -38.0, -35.60000000000001, -47.70000000000002, -49.6, -37.3, -44.00000000000001, -28.400000000000006, -33.6, -34.60000000000001, -47.300000000000004, -44.9, -46.90000000000001, -50.0, -74.4, -39.00000000000001, -40.4, -44.300000000000004, -39.3, -48.300000000000004, -55.30000000000001, -47.7, -45.5, -34.2, -50.40000000000001, -50.60000000000001, -46.4, -42.9, -25.5, -34.900000000000006, -47.40000000000001, -30.1, -31.700000000000003, -50.0, -41.7, -57.10000000000001, -47.00000000000001, -38.199999999999996, -37.900000000000006, -34.099999999999994, -48.50000000000001, -42.6, -48.70000000000001, -44.6, -38.1, -37.00000000000001, -38.300000000000004, -34.0, -49.20000000000001, -44.8, -29.9, -36.7, -44.300000000000004, -36.60000000000001, -42.10000000000001, -45.1, -51.6, -45.0, -41.4, -46.000000000000014, -42.7, -58.0, -46.70000000000001, -39.900000000000006, -57.2, -51.300000000000004, -43.00000000000001, -49.800000000000004, -43.60000000000001, -42.0, -46.500000000000014, -34.3, -47.50000000000001, -44.10000000000001, -68.00000000000001, -43.7, -52.599999999999994, -36.4, -57.500000000000014, -36.7, -53.30000000000002, -48.00000000000001, -32.8, -32.699999999999996, -36.400000000000006, -38.7, -53.40000000000001, -45.20000000000001, -32.9, -41.60000000000001, -46.00000000000001, -39.199999999999996, -39.50000000000001, -49.10000000000001, -52.800000000000004, -45.60000000000001, -40.300000000000004, -27.7, -34.400000000000006, -41.7, -33.0, -35.6, -34.400000000000006, -64.70000000000002, -19.9, -46.400000000000006, -39.5, -31.1, -52.400000000000006, -32.300000000000004, -47.00000000000001, -33.7, -44.50000000000001, -31.5, -29.7, -40.90000000000001, -45.6, -44.6, -39.699999999999996, -54.1, -28.200000000000003, -54.800000000000004, -59.20000000000002, -51.900000000000006], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13669561925253187, "mean_inference_ms": 1.23925449980856, "mean_action_processing_ms": 0.05558670321156028, "mean_env_wait_ms": 2.18250558153213, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 212000, "agent_timesteps_total": 212000, "timers": {"sample_time_ms": 7501.547, "sample_throughput": 533.223, "load_time_ms": 0.047, "load_throughput": 85860880.246, "learn_time_ms": 8184.878, "learn_throughput": 488.706, "update_time_ms": 1.832}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 159.90545476277669, "policy_loss": -0.031681975735832126, "vf_loss": 159.9353746803858, "vf_explained_var": [0.059296466410160065], "kl": 0.00880835616336442, "entropy": 0.8277940259825799, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 212000, "num_agent_steps_sampled": 212000, "num_steps_trained": 212000, "num_agent_steps_trained": 212000}, "done": false, "episodes_total": 14132, "training_iteration": 53, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-23-46", "timestamp": 1632518626, "time_this_iter_s": 18.44362211227417, "time_total_s": 792.7590200901031, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 792.7590200901031, "timesteps_since_restore": 0, "iterations_since_restore": 53, "perf": {"cpu_util_percent": 35.926923076923075, "ram_util_percent": 15.996153846153845}}
{"episode_reward_max": -22.200000000000006, "episode_reward_min": -70.20000000000002, "episode_reward_mean": -42.07611940298508, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 268, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-43.7, -30.3, -36.4, -37.800000000000004, -58.400000000000006, -52.599999999999994, -36.1, -46.40000000000001, -34.4, -43.1, -41.50000000000001, -50.0, -43.5, -45.800000000000004, -46.10000000000001, -42.10000000000001, -31.9, -48.5, -39.5, -41.1, -39.60000000000001, -38.7, -39.300000000000004, -43.60000000000001, -33.10000000000001, -44.79999999999999, -43.7, -48.10000000000001, -41.300000000000004, -35.6, -38.3, -34.6, -43.8, -30.800000000000004, -41.3, -49.2, -42.900000000000006, -34.00000000000001, -51.00000000000001, -48.7, -40.7, -40.300000000000004, -41.9, -41.900000000000006, -43.6, -36.5, -38.9, -40.800000000000004, -50.70000000000001, -51.7, -50.7, -48.00000000000001, -51.2, -36.4, -70.20000000000002, -39.5, -37.800000000000004, -35.0, -51.900000000000006, -49.7, -45.0, -41.7, -37.5, -27.600000000000005, -39.5, -42.0, -33.0, -52.20000000000001, -49.99999999999999, -46.100000000000016, -38.8, -33.5, -26.8, -60.1, -43.20000000000001, -46.300000000000004, -42.80000000000001, -38.2, -31.6, -40.5, -53.60000000000001, -32.2, -36.50000000000001, -35.2, -39.1, -39.7, -48.5, -41.900000000000006, -37.5, -40.5, -38.6, -50.599999999999994, -41.0, -46.500000000000014, -36.699999999999996, -37.10000000000001, -46.900000000000006, -46.800000000000004, -39.9, -60.00000000000001, -38.3, -35.300000000000004, -44.0, -30.400000000000002, -62.4, -45.0, -23.499999999999996, -31.3, -41.800000000000004, -46.900000000000006, -38.8, -37.2, -39.9, -43.70000000000001, -48.1, -54.80000000000001, -53.20000000000001, -44.400000000000006, -40.1, -31.900000000000006, -51.9, -43.800000000000004, -30.8, -35.900000000000006, -40.70000000000001, -38.5, -33.00000000000001, -37.6, -35.599999999999994, -47.2, -47.10000000000001, -38.5, -32.800000000000004, -51.5, -55.900000000000006, -52.900000000000006, -52.1, -29.200000000000003, -46.7, -36.20000000000001, -36.7, -35.0, -34.400000000000006, -38.6, -57.30000000000001, -31.000000000000004, -34.1, -31.100000000000005, -46.7, -47.70000000000001, -40.80000000000001, -42.900000000000006, -26.900000000000002, -54.1, -38.6, -52.400000000000006, -55.800000000000004, -34.1, -42.5, -49.900000000000006, -39.300000000000004, -46.2, -42.80000000000001, -36.70000000000001, -52.50000000000001, -27.5, -39.5, -41.7, -49.400000000000006, -45.800000000000004, -47.099999999999994, -35.900000000000006, -41.6, -41.900000000000006, -32.300000000000004, -27.300000000000004, -47.1, -28.500000000000007, -43.9, -47.0, -59.30000000000001, -37.0, -38.5, -40.60000000000001, -41.9, -36.900000000000006, -39.00000000000001, -48.400000000000006, -28.6, -52.0, -43.00000000000001, -49.40000000000001, -38.70000000000001, -37.300000000000004, -43.300000000000004, -38.7, -23.9, -35.5, -54.50000000000001, -64.2, -50.60000000000001, -43.30000000000001, -44.5, -69.19999999999999, -38.400000000000006, -39.900000000000006, -43.5, -53.50000000000001, -37.1, -43.7, -43.9, -36.9, -22.200000000000006, -29.2, -26.4, -48.00000000000001, -37.7, -33.50000000000001, -32.50000000000001, -46.50000000000001, -32.9, -50.6, -41.0, -41.4, -39.800000000000004, -37.300000000000004, -47.80000000000001, -42.00000000000001, -36.400000000000006, -34.7, -54.50000000000001, -39.800000000000004, -46.9, -51.40000000000001, -37.5, -38.50000000000001, -43.00000000000001, -39.800000000000004, -45.3, -59.5, -31.799999999999997, -46.60000000000001, -38.599999999999994, -39.599999999999994, -50.900000000000006, -44.1, -52.900000000000006, -46.99999999999999, -34.10000000000001, -31.100000000000005, -39.2, -50.9, -38.0, -28.0, -39.800000000000004, -48.0, -50.300000000000004, -38.099999999999994, -33.400000000000006, -38.199999999999996, -53.5, -42.5, -43.3, -49.80000000000001, -44.10000000000001, -45.9, -58.20000000000002, -39.5], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1374376693139117, "mean_inference_ms": 1.246350183373117, "mean_action_processing_ms": 0.055892847353455684, "mean_env_wait_ms": 2.1878524091108837, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 216000, "agent_timesteps_total": 216000, "timers": {"sample_time_ms": 7551.736, "sample_throughput": 529.68, "load_time_ms": 0.048, "load_throughput": 84054188.377, "learn_time_ms": 8190.812, "learn_throughput": 488.352, "update_time_ms": 1.807}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 154.7125497797484, "policy_loss": -0.02575414643813205, "vf_loss": 154.7365618387858, "vf_explained_var": [0.06558743864297867], "kl": 0.008710543071669945, "entropy": 0.8130763494840232, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 216000, "num_agent_steps_sampled": 216000, "num_steps_trained": 216000, "num_agent_steps_trained": 216000}, "done": false, "episodes_total": 14400, "training_iteration": 54, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-24-03", "timestamp": 1632518643, "time_this_iter_s": 16.92676305770874, "time_total_s": 809.6857831478119, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 809.6857831478119, "timesteps_since_restore": 0, "iterations_since_restore": 54, "perf": {"cpu_util_percent": 33.60833333333333, "ram_util_percent": 16.0}}
{"episode_reward_max": -19.8, "episode_reward_min": -63.30000000000002, "episode_reward_mean": -41.90413533834587, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-39.3, -44.0, -22.300000000000004, -41.800000000000004, -48.90000000000001, -28.900000000000002, -51.8, -29.0, -53.000000000000014, -37.20000000000001, -34.400000000000006, -27.300000000000004, -53.6, -34.699999999999996, -47.1, -33.1, -32.1, -42.2, -36.800000000000004, -52.7, -45.400000000000006, -38.10000000000001, -36.2, -42.0, -35.8, -46.5, -43.6, -45.00000000000001, -31.8, -42.4, -37.4, -36.3, -39.2, -54.60000000000001, -47.9, -43.6, -43.5, -41.4, -48.2, -42.0, -19.8, -35.599999999999994, -47.800000000000004, -51.4, -38.6, -46.2, -44.300000000000004, -41.3, -26.0, -43.7, -39.20000000000001, -53.30000000000001, -44.300000000000004, -59.2, -45.99999999999999, -40.9, -45.2, -34.1, -49.400000000000006, -47.400000000000006, -37.4, -47.6, -29.7, -44.900000000000006, -45.60000000000001, -40.199999999999996, -51.800000000000004, -35.7, -33.0, -26.000000000000004, -40.6, -43.300000000000004, -37.1, -35.10000000000001, -46.900000000000006, -40.7, -56.4, -50.7, -51.60000000000001, -37.300000000000004, -48.1, -25.3, -50.0, -37.300000000000004, -57.90000000000001, -39.300000000000004, -31.400000000000002, -37.7, -59.10000000000001, -44.5, -40.5, -52.199999999999996, -36.5, -33.50000000000001, -50.00000000000001, -41.5, -54.400000000000006, -38.7, -42.9, -51.3, -34.0, -56.599999999999994, -35.400000000000006, -33.2, -42.800000000000004, -50.1, -41.00000000000001, -56.70000000000002, -28.6, -40.9, -30.200000000000003, -29.900000000000002, -26.5, -49.300000000000004, -39.300000000000004, -56.60000000000001, -40.199999999999996, -35.599999999999994, -41.00000000000001, -42.400000000000006, -38.6, -53.20000000000001, -33.7, -49.8, -34.699999999999996, -45.50000000000001, -45.00000000000001, -28.3, -39.4, -52.0, -52.90000000000001, -37.6, -41.40000000000001, -59.90000000000001, -35.300000000000004, -48.1, -41.10000000000001, -31.8, -35.2, -45.9, -49.10000000000001, -36.8, -32.10000000000001, -47.90000000000001, -37.400000000000006, -40.400000000000006, -43.60000000000001, -56.7, -44.800000000000004, -43.900000000000006, -35.0, -51.900000000000006, -41.199999999999996, -28.3, -38.60000000000001, -37.00000000000001, -41.2, -41.300000000000004, -40.6, -49.400000000000006, -29.6, -45.8, -45.19999999999999, -42.300000000000004, -43.20000000000001, -54.0, -34.300000000000004, -33.3, -40.50000000000001, -54.99999999999999, -40.2, -56.000000000000014, -40.7, -54.2, -56.60000000000001, -38.400000000000006, -55.800000000000004, -38.5, -47.50000000000001, -50.80000000000001, -43.500000000000014, -41.900000000000006, -46.0, -48.800000000000004, -35.900000000000006, -35.10000000000001, -51.00000000000001, -52.900000000000006, -41.4, -48.5, -39.50000000000001, -36.0, -44.30000000000001, -40.900000000000006, -32.7, -40.0, -46.800000000000004, -37.7, -32.5, -52.400000000000006, -35.9, -25.3, -50.00000000000001, -45.599999999999994, -36.9, -43.400000000000006, -28.300000000000004, -36.7, -63.30000000000002, -46.20000000000001, -34.7, -44.900000000000006, -39.300000000000004, -51.50000000000001, -35.400000000000006, -51.60000000000001, -35.0, -44.5, -36.2, -45.5, -36.7, -37.800000000000004, -47.099999999999994, -47.4, -49.3, -40.800000000000004, -33.4, -50.0, -45.50000000000001, -38.3, -35.00000000000001, -46.300000000000004, -43.90000000000001, -30.400000000000002, -37.6, -31.900000000000006, -44.400000000000006, -53.599999999999994, -53.1, -47.3, -35.900000000000006, -37.8, -46.3, -43.900000000000006, -36.1, -32.0, -60.3, -31.000000000000004, -30.800000000000004, -52.9, -40.5, -39.7, -43.800000000000004, -31.1, -48.4, -47.9, -58.40000000000001, -21.2, -43.7, -34.6, -27.700000000000003, -32.50000000000001, -35.8, -55.699999999999996, -29.0, -34.4], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1374323835520396, "mean_inference_ms": 1.2462553063877786, "mean_action_processing_ms": 0.055888143643759734, "mean_env_wait_ms": 2.185788799713513, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 220000, "agent_timesteps_total": 220000, "timers": {"sample_time_ms": 7526.273, "sample_throughput": 531.472, "load_time_ms": 0.049, "load_throughput": 80854053.012, "learn_time_ms": 8162.564, "learn_throughput": 490.042, "update_time_ms": 1.793}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 156.16740135274907, "policy_loss": -0.02374275030007446, "vf_loss": 156.1891249543877, "vf_explained_var": [0.07313696295022964], "kl": 0.010098958418979776, "entropy": 0.8101491865932301, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 220000, "num_agent_steps_sampled": 220000, "num_steps_trained": 220000, "num_agent_steps_trained": 220000}, "done": false, "episodes_total": 14666, "training_iteration": 55, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-24-18", "timestamp": 1632518658, "time_this_iter_s": 14.559277534484863, "time_total_s": 824.2450606822968, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 824.2450606822968, "timesteps_since_restore": 0, "iterations_since_restore": 55, "perf": {"cpu_util_percent": 35.32857142857143, "ram_util_percent": 16.0}}
{"episode_reward_max": -19.900000000000002, "episode_reward_min": -64.9, "episode_reward_mean": -41.43984962406016, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-47.70000000000001, -34.5, -54.2, -22.099999999999998, -46.00000000000001, -39.300000000000004, -45.900000000000006, -48.6, -47.300000000000004, -32.9, -42.2, -32.300000000000004, -39.400000000000006, -54.0, -36.6, -32.9, -40.60000000000001, -35.7, -34.900000000000006, -43.300000000000004, -32.7, -52.50000000000001, -52.6, -39.900000000000006, -43.70000000000001, -37.5, -31.7, -42.1, -34.1, -43.3, -38.70000000000001, -46.90000000000001, -59.000000000000014, -44.7, -45.20000000000001, -52.7, -45.800000000000004, -33.900000000000006, -39.1, -41.10000000000001, -45.50000000000001, -34.30000000000001, -34.4, -34.3, -47.300000000000004, -30.700000000000003, -46.7, -37.0, -32.6, -46.70000000000001, -34.60000000000001, -50.70000000000002, -55.50000000000001, -43.900000000000006, -51.70000000000001, -36.3, -38.900000000000006, -36.2, -45.90000000000001, -38.00000000000001, -34.400000000000006, -37.00000000000001, -35.2, -33.2, -50.800000000000004, -47.7, -42.900000000000006, -35.400000000000006, -54.70000000000001, -47.4, -34.800000000000004, -36.2, -19.900000000000002, -39.10000000000001, -29.200000000000003, -46.400000000000006, -33.8, -43.900000000000006, -52.2, -37.699999999999996, -33.8, -38.5, -47.10000000000001, -44.300000000000004, -41.3, -35.7, -42.50000000000001, -43.099999999999994, -31.8, -40.900000000000006, -30.600000000000005, -31.800000000000008, -30.4, -57.20000000000001, -24.7, -53.800000000000004, -57.70000000000001, -38.9, -39.0, -51.800000000000004, -44.8, -44.0, -32.7, -37.4, -57.90000000000001, -39.10000000000001, -48.300000000000004, -44.00000000000001, -37.0, -23.699999999999996, -35.900000000000006, -27.400000000000002, -40.10000000000001, -49.00000000000001, -37.8, -36.7, -58.00000000000001, -38.6, -41.00000000000001, -45.1, -32.5, -59.6, -33.900000000000006, -44.7, -42.199999999999996, -43.00000000000001, -43.80000000000001, -64.9, -39.5, -40.400000000000006, -28.400000000000002, -46.00000000000001, -40.3, -34.9, -48.7, -35.00000000000001, -51.6, -45.1, -42.70000000000001, -29.3, -30.700000000000003, -36.900000000000006, -40.30000000000001, -43.599999999999994, -47.800000000000004, -33.7, -41.400000000000006, -47.2, -54.50000000000002, -40.300000000000004, -33.1, -50.3, -35.2, -55.7, -46.400000000000006, -39.2, -51.900000000000006, -31.300000000000004, -48.6, -45.10000000000001, -41.80000000000001, -38.2, -48.7, -47.300000000000004, -41.4, -30.500000000000004, -41.800000000000004, -39.7, -48.300000000000004, -38.70000000000001, -45.50000000000001, -47.5, -38.1, -36.2, -48.60000000000001, -53.0, -31.700000000000003, -34.900000000000006, -51.900000000000006, -45.300000000000004, -47.90000000000001, -34.400000000000006, -43.2, -42.2, -27.2, -44.10000000000001, -37.8, -53.300000000000004, -40.300000000000004, -55.30000000000001, -52.4, -58.60000000000001, -53.7, -39.10000000000001, -47.60000000000001, -61.000000000000014, -34.0, -41.199999999999996, -34.8, -28.5, -40.2, -27.200000000000003, -43.400000000000006, -43.9, -41.800000000000004, -33.2, -39.10000000000001, -33.2, -40.300000000000004, -42.1, -33.400000000000006, -50.00000000000001, -32.50000000000001, -51.9, -39.300000000000004, -20.900000000000002, -32.199999999999996, -21.9, -46.699999999999996, -56.800000000000004, -53.80000000000001, -37.300000000000004, -35.2, -39.00000000000001, -35.7, -39.10000000000001, -54.70000000000001, -39.2, -55.800000000000004, -42.6, -31.7, -28.1, -39.3, -42.2, -43.7, -43.2, -47.10000000000001, -26.2, -45.6, -51.99999999999999, -54.300000000000004, -43.0, -43.9, -47.90000000000001, -34.6, -50.599999999999994, -48.70000000000001, -31.800000000000008, -46.2, -32.900000000000006, -47.89999999999999, -32.5, -48.7, -41.0, -35.300000000000004, -46.2, -34.800000000000004, -41.800000000000004, -43.30000000000001, -36.70000000000001, -36.0, -33.800000000000004, -43.900000000000006, -42.0, -54.10000000000001, -30.1], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13746253814085557, "mean_inference_ms": 1.2462193688688883, "mean_action_processing_ms": 0.05587787102635854, "mean_env_wait_ms": 2.1840408741759947, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 224000, "agent_timesteps_total": 224000, "timers": {"sample_time_ms": 7541.328, "sample_throughput": 530.411, "load_time_ms": 0.055, "load_throughput": 72660095.279, "learn_time_ms": 8157.347, "learn_throughput": 490.355, "update_time_ms": 1.771}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 154.56054605463498, "policy_loss": -0.02385538804985743, "vf_loss": 154.58272111954227, "vf_explained_var": [0.07469454407691956], "kl": 0.008400402166783737, "entropy": 0.7765391532451876, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 224000, "num_agent_steps_sampled": 224000, "num_steps_trained": 224000, "num_agent_steps_trained": 224000}, "done": false, "episodes_total": 14932, "training_iteration": 56, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-24-33", "timestamp": 1632518673, "time_this_iter_s": 15.041324138641357, "time_total_s": 839.2863848209381, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 839.2863848209381, "timesteps_since_restore": 0, "iterations_since_restore": 56, "perf": {"cpu_util_percent": 35.70909090909092, "ram_util_percent": 15.995454545454544}}
{"episode_reward_max": -19.6, "episode_reward_min": -66.79999999999998, "episode_reward_mean": -42.570149253731344, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 268, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-46.300000000000004, -42.400000000000006, -60.99999999999999, -31.400000000000002, -38.6, -36.00000000000001, -43.00000000000001, -50.5, -47.1, -50.3, -41.1, -44.50000000000001, -38.30000000000001, -51.60000000000001, -31.4, -39.00000000000001, -63.70000000000002, -41.3, -51.60000000000001, -34.7, -40.00000000000001, -40.6, -39.5, -40.7, -44.800000000000004, -40.2, -34.4, -46.40000000000001, -30.000000000000004, -37.6, -35.4, -30.800000000000004, -38.400000000000006, -35.2, -46.800000000000004, -48.0, -33.300000000000004, -42.80000000000001, -43.20000000000001, -30.700000000000003, -35.9, -49.10000000000001, -55.7, -42.699999999999996, -35.800000000000004, -48.7, -32.6, -54.7, -37.7, -28.300000000000008, -44.3, -45.7, -59.40000000000001, -50.5, -28.4, -46.70000000000001, -32.6, -24.8, -35.1, -34.6, -51.20000000000001, -33.2, -42.1, -51.7, -45.300000000000004, -45.20000000000001, -49.000000000000014, -35.400000000000006, -56.80000000000001, -38.90000000000001, -46.800000000000004, -42.20000000000001, -42.099999999999994, -51.400000000000006, -45.500000000000014, -43.300000000000004, -43.50000000000001, -20.700000000000003, -37.400000000000006, -48.300000000000004, -30.699999999999996, -41.1, -32.1, -46.20000000000001, -51.7, -28.900000000000002, -39.300000000000004, -42.50000000000001, -45.0, -35.9, -38.70000000000001, -66.79999999999998, -37.50000000000001, -43.6, -45.10000000000001, -45.10000000000001, -52.00000000000001, -55.400000000000006, -42.400000000000006, -35.2, -49.5, -26.9, -44.8, -35.6, -33.199999999999996, -38.00000000000001, -48.6, -39.5, -31.8, -32.3, -48.79999999999999, -40.800000000000004, -65.40000000000002, -42.800000000000004, -22.5, -48.60000000000001, -35.60000000000001, -49.50000000000001, -35.900000000000006, -32.800000000000004, -39.50000000000001, -44.300000000000004, -53.7, -47.6, -50.8, -39.8, -49.20000000000001, -50.10000000000001, -50.7, -43.6, -48.6, -56.20000000000001, -53.00000000000001, -37.5, -56.900000000000006, -58.20000000000001, -38.800000000000004, -44.60000000000001, -51.80000000000001, -50.50000000000001, -48.400000000000006, -47.7, -51.900000000000006, -29.800000000000004, -43.60000000000001, -34.300000000000004, -45.90000000000001, -34.7, -27.200000000000003, -46.80000000000001, -46.800000000000004, -40.300000000000004, -28.6, -37.7, -31.5, -37.300000000000004, -43.900000000000006, -47.2, -36.800000000000004, -34.5, -49.0, -34.10000000000001, -32.7, -59.800000000000004, -48.3, -33.6, -47.80000000000001, -44.10000000000001, -38.7, -28.8, -50.4, -58.400000000000006, -44.10000000000001, -46.00000000000001, -42.199999999999996, -34.20000000000001, -37.6, -50.50000000000001, -41.300000000000004, -35.6, -42.60000000000001, -34.099999999999994, -36.7, -37.00000000000001, -29.0, -19.6, -29.700000000000003, -42.70000000000002, -48.4, -33.300000000000004, -48.7, -42.40000000000001, -47.0, -32.4, -35.5, -38.6, -34.7, -37.400000000000006, -46.400000000000006, -34.6, -56.90000000000001, -37.5, -52.400000000000006, -48.800000000000004, -31.500000000000004, -40.300000000000004, -32.6, -42.6, -48.30000000000001, -59.60000000000001, -50.60000000000001, -45.6, -38.30000000000001, -47.60000000000001, -46.100000000000016, -38.7, -39.7, -65.0, -51.2, -54.900000000000006, -60.6, -28.4, -48.8, -35.2, -42.300000000000004, -31.7, -39.9, -52.800000000000004, -37.1, -42.0, -62.90000000000002, -47.20000000000002, -44.70000000000001, -53.500000000000014, -41.6, -29.700000000000006, -41.90000000000001, -35.6, -38.6, -42.300000000000004, -54.500000000000014, -37.800000000000004, -52.7, -48.400000000000006, -44.80000000000002, -45.10000000000001, -46.800000000000004, -51.00000000000001, -51.60000000000001, -55.3, -39.10000000000001, -48.7, -46.7, -33.0, -37.300000000000004, -52.1, -50.00000000000001, -39.8, -30.200000000000003, -40.7, -33.800000000000004, -52.900000000000006, -48.6, -50.0, -45.0, -37.5, -34.8, -33.300000000000004], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13758977025575023, "mean_inference_ms": 1.2468555481994086, "mean_action_processing_ms": 0.055911730233422975, "mean_env_wait_ms": 2.183110615392345, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 228000, "agent_timesteps_total": 228000, "timers": {"sample_time_ms": 7483.774, "sample_throughput": 534.49, "load_time_ms": 0.055, "load_throughput": 72976146.151, "learn_time_ms": 8091.992, "learn_throughput": 494.316, "update_time_ms": 1.782}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 163.6007154813377, "policy_loss": -0.022256105989017474, "vf_loss": 163.62103347778321, "vf_explained_var": [0.06232203170657158], "kl": 0.0096924682798838, "entropy": 0.7551396771143841, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 228000, "num_agent_steps_sampled": 228000, "num_steps_trained": 228000, "num_agent_steps_trained": 228000}, "done": false, "episodes_total": 15200, "training_iteration": 57, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-24-49", "timestamp": 1632518689, "time_this_iter_s": 15.839146375656128, "time_total_s": 855.1255311965942, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 855.1255311965942, "timesteps_since_restore": 0, "iterations_since_restore": 57, "perf": {"cpu_util_percent": 35.51363636363636, "ram_util_percent": 15.986363636363636}}
{"episode_reward_max": -23.599999999999998, "episode_reward_min": -67.39999999999999, "episode_reward_mean": -42.214285714285715, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-42.800000000000004, -58.9, -61.400000000000006, -32.5, -44.80000000000001, -39.2, -41.6, -31.700000000000003, -48.00000000000001, -48.89999999999999, -26.200000000000003, -34.5, -37.0, -40.300000000000004, -46.0, -33.3, -39.7, -35.5, -26.900000000000002, -49.70000000000001, -53.50000000000001, -41.4, -43.800000000000004, -39.50000000000001, -38.60000000000001, -38.400000000000006, -47.80000000000001, -32.6, -60.80000000000001, -36.1, -44.60000000000001, -55.10000000000001, -44.00000000000001, -43.300000000000004, -49.60000000000001, -33.0, -45.80000000000001, -47.400000000000006, -40.800000000000004, -44.900000000000006, -39.8, -34.7, -35.10000000000001, -34.300000000000004, -43.3, -33.3, -39.60000000000001, -35.6, -33.00000000000001, -52.6, -39.2, -37.7, -41.30000000000001, -35.9, -57.8, -28.699999999999996, -40.4, -37.0, -48.2, -38.80000000000001, -39.5, -36.6, -41.199999999999996, -41.1, -39.400000000000006, -48.4, -35.5, -38.900000000000006, -42.5, -36.4, -31.2, -30.4, -62.4, -39.800000000000004, -45.100000000000016, -44.300000000000004, -44.20000000000001, -46.400000000000006, -52.9, -46.10000000000001, -47.0, -37.300000000000004, -35.800000000000004, -41.60000000000001, -49.10000000000001, -43.0, -42.8, -44.50000000000001, -32.0, -30.3, -31.900000000000002, -49.800000000000004, -38.5, -38.0, -33.5, -47.2, -41.2, -56.1, -50.400000000000006, -42.2, -40.1, -32.00000000000001, -42.70000000000001, -47.40000000000001, -43.900000000000006, -29.599999999999998, -25.900000000000002, -47.5, -57.50000000000001, -38.00000000000001, -49.5, -36.599999999999994, -39.5, -47.7, -48.20000000000001, -46.400000000000006, -47.60000000000001, -42.800000000000004, -37.0, -40.900000000000006, -41.2, -54.30000000000001, -45.400000000000006, -30.300000000000004, -65.10000000000001, -40.900000000000006, -46.7, -27.3, -40.7, -46.2, -32.00000000000001, -49.60000000000001, -42.1, -50.5, -49.0, -61.30000000000001, -43.10000000000001, -45.00000000000001, -45.8, -27.800000000000004, -66.20000000000002, -43.70000000000001, -40.5, -30.9, -33.7, -52.000000000000014, -24.2, -38.3, -29.7, -49.6, -39.3, -43.00000000000001, -49.800000000000004, -37.8, -30.900000000000006, -39.0, -54.500000000000014, -41.7, -47.900000000000006, -37.0, -40.7, -42.3, -49.400000000000006, -31.500000000000004, -37.3, -44.5, -46.7, -23.599999999999998, -57.50000000000001, -40.4, -45.1, -47.30000000000001, -42.300000000000004, -46.40000000000002, -35.1, -34.1, -33.3, -52.20000000000001, -34.3, -53.70000000000001, -39.7, -35.1, -42.10000000000001, -50.10000000000001, -39.300000000000004, -34.2, -45.80000000000001, -49.100000000000016, -28.700000000000003, -41.1, -26.600000000000005, -43.400000000000006, -38.30000000000001, -40.60000000000001, -34.300000000000004, -52.4, -41.00000000000001, -37.400000000000006, -30.2, -33.50000000000001, -31.500000000000007, -40.2, -42.800000000000004, -67.39999999999999, -35.2, -34.60000000000001, -33.9, -45.400000000000006, -40.7, -54.80000000000001, -43.600000000000016, -38.1, -45.0, -42.099999999999994, -31.300000000000004, -36.0, -41.2, -65.9, -28.4, -49.400000000000006, -34.900000000000006, -45.80000000000001, -36.6, -55.20000000000001, -41.2, -48.20000000000001, -50.2, -36.60000000000001, -45.70000000000001, -44.10000000000001, -55.1, -51.900000000000006, -50.400000000000006, -34.400000000000006, -54.000000000000014, -38.70000000000001, -46.2, -46.7, -34.5, -54.300000000000004, -42.1, -38.699999999999996, -52.30000000000001, -44.30000000000001, -46.900000000000006, -52.0, -47.2, -44.2, -31.0, -45.2, -42.00000000000001, -39.199999999999996, -38.599999999999994, -45.2, -57.10000000000001, -39.7, -57.400000000000006, -56.900000000000006, -42.8, -33.300000000000004, -43.800000000000004, -27.200000000000003, -52.60000000000001, -36.7, -38.1, -46.2], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13799977546517148, "mean_inference_ms": 1.2503696599284821, "mean_action_processing_ms": 0.0560716253283879, "mean_env_wait_ms": 2.1861683141476025, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 232000, "agent_timesteps_total": 232000, "timers": {"sample_time_ms": 7549.912, "sample_throughput": 529.808, "load_time_ms": 0.054, "load_throughput": 73843380.282, "learn_time_ms": 8142.754, "learn_throughput": 491.234, "update_time_ms": 1.781}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 158.77585934874833, "policy_loss": -0.024938816796006857, "vf_loss": 158.79887947164556, "vf_explained_var": [0.06532207876443863], "kl": 0.009593067612707841, "entropy": 0.7109450106979698, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 232000, "num_agent_steps_sampled": 232000, "num_steps_trained": 232000, "num_agent_steps_trained": 232000}, "done": false, "episodes_total": 15466, "training_iteration": 58, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-25-06", "timestamp": 1632518706, "time_this_iter_s": 16.672178745269775, "time_total_s": 871.797709941864, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 871.797709941864, "timesteps_since_restore": 0, "iterations_since_restore": 58, "perf": {"cpu_util_percent": 34.854166666666664, "ram_util_percent": 16.0}}
{"episode_reward_max": -25.0, "episode_reward_min": -72.10000000000001, "episode_reward_mean": -41.88082706766918, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-48.5, -36.6, -41.800000000000004, -51.900000000000006, -45.6, -39.8, -34.7, -47.80000000000001, -25.0, -37.0, -38.800000000000004, -46.50000000000001, -37.800000000000004, -32.099999999999994, -42.5, -30.300000000000004, -43.900000000000006, -36.2, -29.000000000000004, -31.099999999999998, -44.7, -31.900000000000002, -39.00000000000001, -47.199999999999996, -40.7, -56.10000000000001, -58.30000000000001, -43.199999999999996, -40.900000000000006, -39.20000000000001, -34.900000000000006, -48.600000000000016, -43.4, -34.6, -44.10000000000001, -57.30000000000001, -50.40000000000001, -51.10000000000001, -41.6, -38.300000000000004, -34.699999999999996, -31.500000000000004, -53.400000000000006, -35.0, -39.9, -43.8, -31.700000000000006, -42.7, -42.1, -52.9, -46.900000000000006, -39.4, -32.50000000000001, -48.60000000000001, -33.0, -55.8, -62.600000000000016, -28.5, -42.7, -44.900000000000006, -30.6, -32.800000000000004, -39.50000000000001, -48.7, -36.400000000000006, -52.00000000000001, -45.60000000000001, -53.60000000000001, -38.60000000000001, -44.1, -64.90000000000002, -55.80000000000001, -41.1, -44.1, -47.8, -40.70000000000001, -47.5, -61.400000000000006, -33.1, -46.300000000000004, -48.500000000000014, -46.3, -39.900000000000006, -37.3, -35.8, -36.3, -32.3, -36.4, -44.900000000000006, -46.699999999999996, -28.400000000000002, -51.500000000000014, -38.6, -39.00000000000001, -38.8, -44.6, -41.00000000000001, -43.30000000000002, -42.400000000000006, -42.0, -33.5, -33.7, -40.10000000000001, -35.8, -41.60000000000001, -37.3, -46.7, -43.5, -32.0, -38.400000000000006, -48.9, -47.70000000000001, -54.60000000000001, -39.8, -31.0, -37.1, -44.800000000000004, -33.0, -45.800000000000004, -45.300000000000004, -42.900000000000006, -35.900000000000006, -59.300000000000004, -48.9, -35.5, -47.39999999999999, -36.6, -49.300000000000004, -50.800000000000004, -49.900000000000006, -39.300000000000004, -35.300000000000004, -41.7, -27.6, -29.500000000000007, -41.80000000000001, -36.400000000000006, -37.800000000000004, -38.800000000000004, -35.900000000000006, -38.7, -37.6, -44.400000000000006, -46.0, -40.6, -41.50000000000001, -35.9, -46.800000000000004, -36.0, -44.30000000000001, -35.6, -33.50000000000001, -48.6, -38.599999999999994, -31.800000000000004, -39.6, -32.800000000000004, -44.7, -40.0, -55.80000000000001, -41.4, -39.900000000000006, -50.800000000000004, -48.20000000000001, -47.60000000000001, -45.20000000000001, -46.50000000000001, -31.7, -37.5, -47.50000000000001, -33.1, -55.2, -49.4, -34.800000000000004, -39.4, -36.800000000000004, -43.0, -45.5, -54.599999999999994, -40.800000000000004, -51.60000000000001, -41.800000000000004, -34.1, -35.00000000000001, -53.00000000000002, -57.80000000000001, -47.400000000000006, -36.800000000000004, -42.400000000000006, -33.400000000000006, -34.7, -72.10000000000001, -42.800000000000004, -29.5, -32.6, -39.5, -34.1, -48.50000000000001, -42.80000000000001, -47.6, -36.7, -54.10000000000001, -31.6, -44.30000000000001, -44.50000000000001, -37.99999999999999, -47.3, -42.800000000000004, -34.900000000000006, -50.70000000000001, -34.2, -51.8, -32.50000000000001, -43.0, -40.1, -38.900000000000006, -47.0, -43.7, -71.8, -43.9, -41.00000000000001, -44.6, -46.900000000000006, -30.000000000000004, -47.5, -45.60000000000001, -31.6, -45.19999999999999, -34.5, -29.5, -45.5, -40.5, -60.10000000000001, -46.900000000000006, -40.800000000000004, -42.900000000000006, -40.30000000000001, -42.7, -52.80000000000001, -29.5, -35.900000000000006, -44.3, -38.300000000000004, -38.2, -31.5, -36.8, -41.900000000000006, -36.400000000000006, -45.80000000000001, -48.6, -36.900000000000006, -41.50000000000001, -32.1, -50.7, -44.300000000000004, -39.400000000000006, -38.800000000000004, -31.8, -39.60000000000001, -32.3, -49.0, -43.10000000000001, -39.4, -39.10000000000001, -44.6, -35.800000000000004], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13846878625541612, "mean_inference_ms": 1.2546671912718244, "mean_action_processing_ms": 0.056276276879768806, "mean_env_wait_ms": 2.1894916480000197, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 236000, "agent_timesteps_total": 236000, "timers": {"sample_time_ms": 7656.35, "sample_throughput": 522.442, "load_time_ms": 0.055, "load_throughput": 72881042.572, "learn_time_ms": 8247.658, "learn_throughput": 484.986, "update_time_ms": 1.981}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 153.60802788683162, "policy_loss": -0.026830833219492468, "vf_loss": 153.6334837144421, "vf_explained_var": [0.06933185458183289], "kl": 0.006876858280767898, "entropy": 0.7125941169518296, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 236000, "num_agent_steps_sampled": 236000, "num_steps_trained": 236000, "num_agent_steps_trained": 236000}, "done": false, "episodes_total": 15732, "training_iteration": 59, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-25-24", "timestamp": 1632518724, "time_this_iter_s": 17.81975269317627, "time_total_s": 889.6174626350403, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 889.6174626350403, "timesteps_since_restore": 0, "iterations_since_restore": 59, "perf": {"cpu_util_percent": 35.93076923076923, "ram_util_percent": 16.0}}
{"episode_reward_max": -24.5, "episode_reward_min": -70.89999999999999, "episode_reward_mean": -41.28656716417912, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 268, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-45.2, -41.8, -41.50000000000001, -43.6, -36.900000000000006, -26.8, -49.7, -33.5, -31.999999999999996, -40.70000000000001, -50.6, -34.800000000000004, -29.5, -41.80000000000001, -41.800000000000004, -41.50000000000001, -32.9, -40.70000000000001, -44.900000000000006, -33.5, -35.80000000000001, -29.6, -50.50000000000001, -42.5, -35.60000000000001, -40.10000000000001, -50.60000000000001, -41.300000000000004, -35.2, -47.7, -42.9, -42.4, -29.100000000000005, -38.400000000000006, -42.00000000000001, -25.5, -42.50000000000001, -28.900000000000002, -32.00000000000001, -41.60000000000001, -44.7, -43.1, -45.3, -51.00000000000001, -29.900000000000002, -46.30000000000001, -42.2, -39.8, -52.20000000000001, -29.3, -39.300000000000004, -38.8, -46.4, -51.9, -35.800000000000004, -33.400000000000006, -39.400000000000006, -47.90000000000001, -38.400000000000006, -39.4, -45.4, -44.400000000000006, -52.49999999999999, -37.300000000000004, -55.599999999999994, -54.500000000000014, -42.400000000000006, -34.8, -36.90000000000001, -40.8, -28.499999999999996, -57.40000000000001, -43.10000000000001, -41.800000000000004, -41.1, -38.400000000000006, -44.300000000000004, -35.3, -44.6, -67.70000000000002, -30.3, -33.6, -35.2, -41.4, -35.8, -48.900000000000006, -39.6, -37.199999999999996, -40.10000000000001, -39.300000000000004, -35.900000000000006, -30.599999999999998, -40.4, -56.00000000000001, -53.10000000000001, -24.5, -40.00000000000001, -42.7, -31.900000000000006, -31.7, -24.700000000000003, -37.3, -51.30000000000001, -48.2, -45.5, -37.5, -43.2, -44.5, -43.8, -41.3, -55.900000000000006, -52.30000000000001, -51.5, -39.0, -50.7, -38.70000000000001, -62.400000000000006, -27.299999999999997, -28.600000000000005, -46.90000000000001, -28.3, -39.300000000000004, -47.6, -40.7, -47.50000000000001, -46.900000000000006, -39.7, -49.9, -41.199999999999996, -54.900000000000006, -38.9, -33.0, -25.000000000000004, -49.10000000000001, -46.50000000000001, -49.099999999999994, -46.10000000000001, -38.6, -39.400000000000006, -34.7, -46.60000000000001, -40.0, -41.5, -29.5, -42.900000000000006, -41.900000000000006, -33.400000000000006, -44.400000000000006, -47.900000000000006, -47.00000000000001, -53.400000000000006, -47.4, -35.7, -47.100000000000016, -46.2, -44.20000000000001, -43.800000000000004, -46.400000000000006, -24.9, -39.7, -42.80000000000001, -43.0, -51.000000000000014, -39.400000000000006, -44.300000000000004, -35.6, -66.60000000000001, -47.7, -52.1, -49.1, -39.300000000000004, -28.4, -70.89999999999999, -42.300000000000004, -35.4, -31.400000000000002, -37.800000000000004, -34.2, -41.800000000000004, -33.5, -41.7, -53.800000000000004, -44.50000000000001, -32.7, -33.300000000000004, -34.7, -43.5, -52.0, -39.60000000000001, -43.900000000000006, -43.8, -42.40000000000001, -34.7, -30.500000000000004, -39.20000000000001, -38.1, -35.5, -35.900000000000006, -43.1, -36.800000000000004, -39.4, -40.500000000000014, -26.3, -47.400000000000006, -32.7, -25.9, -38.5, -47.80000000000001, -33.5, -41.1, -49.60000000000001, -33.9, -33.900000000000006, -25.700000000000006, -48.300000000000004, -43.20000000000001, -34.7, -46.50000000000001, -35.7, -32.400000000000006, -32.7, -33.900000000000006, -62.2, -46.10000000000001, -41.5, -44.90000000000001, -37.900000000000006, -45.10000000000001, -40.300000000000004, -42.2, -33.7, -43.3, -46.400000000000006, -54.800000000000004, -36.300000000000004, -48.00000000000001, -43.4, -28.4, -36.0, -51.60000000000001, -55.60000000000001, -35.7, -39.49999999999999, -32.6, -28.200000000000003, -46.3, -38.1, -49.40000000000001, -32.5, -29.900000000000002, -26.900000000000002, -64.89999999999999, -40.50000000000001, -50.800000000000004, -33.900000000000006, -43.10000000000001, -44.00000000000001, -39.900000000000006, -48.30000000000001, -43.400000000000006, -47.800000000000004, -41.60000000000001, -44.1, -70.7, -33.900000000000006, -37.3, -47.60000000000001, -48.00000000000001], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.138920177671399, "mean_inference_ms": 1.2586616770233585, "mean_action_processing_ms": 0.056445261342157084, "mean_env_wait_ms": 2.1923263673320386, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 240000, "agent_timesteps_total": 240000, "timers": {"sample_time_ms": 7724.962, "sample_throughput": 517.802, "load_time_ms": 0.055, "load_throughput": 72377981.018, "learn_time_ms": 8470.102, "learn_throughput": 472.249, "update_time_ms": 1.935}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 150.28681352676884, "policy_loss": -0.024715404940508705, "vf_loss": 150.30997842768187, "vf_explained_var": [0.06540312618017197], "kl": 0.007752657029084504, "entropy": 0.6789546836447972, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 240000, "num_agent_steps_sampled": 240000, "num_steps_trained": 240000, "num_agent_steps_trained": 240000}, "done": false, "episodes_total": 16000, "training_iteration": 60, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-25-42", "timestamp": 1632518742, "time_this_iter_s": 18.264373779296875, "time_total_s": 907.8818364143372, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 907.8818364143372, "timesteps_since_restore": 0, "iterations_since_restore": 60, "perf": {"cpu_util_percent": 36.14615384615385, "ram_util_percent": 16.0}}
{"episode_reward_max": -23.1, "episode_reward_min": -61.300000000000004, "episode_reward_mean": -41.62218045112782, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-29.300000000000004, -26.1, -37.0, -49.50000000000001, -39.1, -35.900000000000006, -42.60000000000001, -32.400000000000006, -35.7, -38.0, -33.0, -35.800000000000004, -52.70000000000001, -31.60000000000001, -44.7, -43.599999999999994, -35.50000000000001, -55.50000000000001, -41.9, -47.0, -41.7, -35.6, -43.49999999999999, -50.0, -31.200000000000003, -41.60000000000001, -38.0, -45.10000000000001, -56.60000000000001, -23.1, -34.9, -40.900000000000006, -45.60000000000001, -36.300000000000004, -33.2, -40.0, -57.7, -43.10000000000001, -40.9, -57.400000000000006, -39.400000000000006, -48.900000000000006, -27.5, -45.80000000000001, -61.300000000000004, -36.1, -45.20000000000001, -35.5, -43.5, -57.50000000000001, -41.699999999999996, -34.10000000000001, -42.300000000000004, -36.5, -60.0, -40.90000000000001, -43.00000000000001, -43.40000000000001, -29.900000000000002, -49.300000000000004, -34.10000000000001, -35.4, -51.099999999999994, -48.900000000000006, -35.900000000000006, -46.800000000000004, -41.3, -41.80000000000001, -33.6, -35.4, -43.900000000000006, -36.1, -38.4, -26.100000000000005, -48.30000000000001, -36.5, -44.800000000000004, -27.900000000000006, -32.300000000000004, -34.7, -40.2, -46.300000000000004, -34.2, -41.00000000000001, -28.7, -59.7, -44.0, -41.0, -52.8, -37.20000000000001, -41.10000000000001, -37.2, -41.8, -51.6, -37.00000000000001, -40.7, -39.800000000000004, -45.80000000000001, -49.000000000000014, -31.6, -50.99999999999999, -45.7, -34.199999999999996, -40.50000000000001, -49.300000000000004, -26.5, -47.900000000000006, -39.4, -49.20000000000001, -37.2, -35.800000000000004, -31.300000000000004, -38.1, -43.2, -36.300000000000004, -47.7, -46.400000000000006, -41.2, -46.3, -40.199999999999996, -42.90000000000001, -36.7, -39.6, -37.1, -38.10000000000001, -32.9, -36.7, -37.5, -48.90000000000001, -47.20000000000001, -41.6, -47.1, -43.300000000000004, -30.700000000000003, -37.000000000000014, -45.00000000000001, -49.5, -40.50000000000001, -35.9, -47.6, -54.30000000000001, -28.3, -48.2, -32.6, -46.2, -36.5, -29.2, -40.7, -30.8, -31.700000000000003, -43.2, -38.199999999999996, -56.99999999999999, -37.400000000000006, -37.0, -30.400000000000006, -41.1, -53.20000000000001, -44.80000000000001, -39.70000000000001, -41.6, -46.699999999999996, -50.80000000000001, -43.60000000000001, -50.300000000000004, -29.300000000000004, -49.300000000000004, -37.9, -53.5, -37.8, -33.0, -34.7, -43.0, -43.50000000000001, -32.0, -43.699999999999996, -29.000000000000004, -52.10000000000001, -53.60000000000001, -59.30000000000002, -41.8, -42.6, -47.199999999999996, -47.9, -48.0, -50.2, -39.39999999999999, -42.1, -58.10000000000001, -42.300000000000004, -42.8, -37.3, -49.900000000000006, -45.70000000000001, -51.7, -38.8, -55.900000000000006, -49.4, -56.5, -46.0, -51.5, -35.3, -45.20000000000001, -51.7, -49.900000000000006, -46.5, -51.60000000000001, -39.00000000000001, -52.80000000000001, -30.100000000000005, -47.800000000000004, -28.100000000000005, -37.800000000000004, -41.8, -27.400000000000002, -41.2, -37.1, -35.800000000000004, -54.50000000000001, -44.00000000000001, -37.2, -50.2, -38.00000000000001, -33.99999999999999, -34.6, -33.0, -43.6, -36.7, -50.400000000000006, -27.7, -42.4, -43.70000000000001, -36.4, -52.30000000000001, -38.7, -41.3, -26.700000000000006, -55.00000000000001, -26.000000000000004, -44.6, -34.50000000000001, -35.00000000000001, -42.099999999999994, -45.400000000000006, -48.20000000000001, -40.1, -34.3, -44.7, -52.6, -42.2, -29.700000000000003, -42.699999999999996, -34.800000000000004, -49.7, -36.60000000000001, -52.30000000000001, -40.7, -36.6, -43.3, -42.800000000000004, -43.6, -41.60000000000001, -51.1, -45.9, -36.699999999999996, -41.6], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13958411439870347, "mean_inference_ms": 1.2644001552733652, "mean_action_processing_ms": 0.05667653881402591, "mean_env_wait_ms": 2.1954401607524217, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 244000, "agent_timesteps_total": 244000, "timers": {"sample_time_ms": 7914.637, "sample_throughput": 505.393, "load_time_ms": 0.056, "load_throughput": 71059788.225, "learn_time_ms": 8522.804, "learn_throughput": 469.329, "update_time_ms": 1.999}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 152.59263334376837, "policy_loss": -0.021893524239340458, "vf_loss": 152.61310515044838, "vf_explained_var": [0.06734142452478409], "kl": 0.007108568119865585, "entropy": 0.6509795069053609, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 244000, "num_agent_steps_sampled": 244000, "num_steps_trained": 244000, "num_agent_steps_trained": 244000}, "done": false, "episodes_total": 16266, "training_iteration": 61, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-25-59", "timestamp": 1632518759, "time_this_iter_s": 16.558582305908203, "time_total_s": 924.4404187202454, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 924.4404187202454, "timesteps_since_restore": 0, "iterations_since_restore": 61, "perf": {"cpu_util_percent": 33.108695652173914, "ram_util_percent": 15.995652173913042}}
{"episode_reward_max": -19.400000000000002, "episode_reward_min": -62.8, "episode_reward_mean": -40.13308270676692, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-44.8, -37.900000000000006, -49.50000000000001, -46.900000000000006, -62.8, -30.500000000000004, -27.900000000000002, -47.40000000000001, -54.6, -38.1, -50.6, -41.400000000000006, -21.9, -30.400000000000002, -54.10000000000001, -51.80000000000001, -36.60000000000001, -52.1, -56.000000000000014, -38.300000000000004, -25.2, -44.2, -26.8, -42.7, -30.200000000000006, -50.99999999999999, -28.0, -33.4, -47.699999999999996, -37.2, -31.600000000000005, -45.300000000000004, -45.199999999999996, -29.0, -40.900000000000006, -56.300000000000004, -33.6, -44.8, -28.3, -46.5, -35.0, -33.5, -39.80000000000001, -32.7, -54.90000000000001, -40.5, -51.50000000000001, -47.10000000000001, -39.300000000000004, -40.300000000000004, -38.6, -40.400000000000006, -41.6, -32.400000000000006, -40.900000000000006, -32.7, -25.6, -36.6, -31.0, -48.5, -46.800000000000004, -27.700000000000003, -40.400000000000006, -28.2, -39.6, -36.7, -38.70000000000001, -45.20000000000001, -47.2, -23.6, -46.00000000000001, -36.300000000000004, -33.7, -38.400000000000006, -36.1, -28.8, -40.5, -44.3, -42.29999999999999, -33.9, -43.10000000000001, -43.2, -26.400000000000006, -38.800000000000004, -33.5, -43.800000000000004, -34.800000000000004, -39.3, -42.8, -43.70000000000001, -41.1, -39.5, -55.90000000000001, -47.80000000000001, -35.6, -35.6, -40.1, -38.10000000000001, -32.699999999999996, -34.7, -36.400000000000006, -46.900000000000006, -21.599999999999998, -44.300000000000004, -33.0, -46.0, -39.4, -42.4, -48.599999999999994, -24.4, -40.9, -46.0, -27.900000000000006, -42.300000000000004, -35.6, -33.0, -41.1, -57.10000000000001, -48.1, -41.900000000000006, -36.0, -34.900000000000006, -49.80000000000001, -36.4, -48.6, -27.800000000000004, -45.900000000000006, -36.00000000000001, -32.2, -44.4, -40.900000000000006, -40.00000000000001, -38.300000000000004, -36.400000000000006, -42.50000000000001, -40.1, -52.1, -38.300000000000004, -42.6, -35.400000000000006, -37.9, -45.30000000000001, -41.7, -43.800000000000004, -47.50000000000001, -26.000000000000004, -45.800000000000004, -46.10000000000001, -37.2, -36.3, -42.599999999999994, -53.90000000000001, -38.50000000000001, -53.70000000000001, -42.8, -47.5, -46.99999999999999, -50.3, -51.0, -33.8, -39.2, -35.300000000000004, -35.300000000000004, -35.800000000000004, -33.3, -27.299999999999997, -30.2, -39.1, -46.6, -51.5, -52.900000000000006, -43.2, -24.2, -39.10000000000001, -35.300000000000004, -50.6, -37.6, -38.8, -37.20000000000001, -40.2, -39.10000000000001, -41.099999999999994, -36.1, -48.500000000000014, -30.600000000000005, -39.2, -41.000000000000014, -38.1, -42.400000000000006, -39.9, -45.1, -35.7, -30.1, -36.3, -48.60000000000001, -33.2, -60.00000000000001, -41.900000000000006, -31.6, -51.6, -47.300000000000004, -49.8, -47.00000000000001, -48.900000000000006, -31.599999999999998, -43.50000000000001, -36.900000000000006, -44.400000000000006, -50.400000000000006, -37.6, -40.50000000000001, -44.0, -29.0, -22.0, -49.1, -40.300000000000004, -36.599999999999994, -31.800000000000004, -27.2, -53.900000000000006, -40.699999999999996, -40.4, -26.1, -44.10000000000001, -46.00000000000001, -40.6, -26.3, -49.6, -43.00000000000001, -33.400000000000006, -38.2, -38.6, -39.599999999999994, -49.5, -28.4, -35.300000000000004, -46.1, -36.50000000000001, -51.80000000000001, -40.0, -36.1, -34.400000000000006, -36.7, -58.400000000000006, -19.400000000000002, -45.8, -30.2, -25.5, -50.599999999999994, -37.4, -39.1, -38.1, -29.700000000000003, -49.20000000000001, -51.80000000000001, -36.6, -35.6, -39.7, -39.50000000000001, -49.30000000000001, -54.30000000000001, -41.400000000000006, -51.2, -38.800000000000004, -46.400000000000006, -37.9], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13942345153066332, "mean_inference_ms": 1.2630035513430884, "mean_action_processing_ms": 0.056617299452586416, "mean_env_wait_ms": 2.1924252938874695, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 248000, "agent_timesteps_total": 248000, "timers": {"sample_time_ms": 7913.68, "sample_throughput": 505.454, "load_time_ms": 0.059, "load_throughput": 68200065.041, "learn_time_ms": 8508.949, "learn_throughput": 470.093, "update_time_ms": 2.0}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 142.81281049995013, "policy_loss": -0.02350708839072976, "vf_loss": 142.83511058028026, "vf_explained_var": [0.0683068335056305], "kl": 0.006036441977255138, "entropy": 0.6589238013631554, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 248000, "num_agent_steps_sampled": 248000, "num_steps_trained": 248000, "num_agent_steps_trained": 248000}, "done": false, "episodes_total": 16532, "training_iteration": 62, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-26-13", "timestamp": 1632518773, "time_this_iter_s": 14.228184938430786, "time_total_s": 938.6686036586761, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 938.6686036586761, "timesteps_since_restore": 0, "iterations_since_restore": 62, "perf": {"cpu_util_percent": 35.37142857142857, "ram_util_percent": 16.0}}
{"episode_reward_max": -22.5, "episode_reward_min": -72.20000000000002, "episode_reward_mean": -42.1044776119403, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 268, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.2, -47.000000000000014, -48.099999999999994, -53.6, -44.2, -35.400000000000006, -46.0, -38.300000000000004, -41.4, -40.60000000000001, -42.7, -49.000000000000014, -51.7, -36.400000000000006, -38.800000000000004, -36.10000000000001, -35.400000000000006, -52.199999999999996, -44.3, -62.4, -30.300000000000004, -36.50000000000001, -37.6, -42.7, -31.900000000000002, -36.7, -45.900000000000006, -48.100000000000016, -34.6, -40.400000000000006, -63.2, -46.599999999999994, -29.200000000000003, -38.2, -37.4, -34.5, -47.2, -51.10000000000001, -55.80000000000002, -46.10000000000001, -52.90000000000001, -43.3, -39.300000000000004, -40.7, -50.5, -44.3, -48.70000000000001, -50.00000000000001, -51.10000000000001, -39.199999999999996, -49.70000000000001, -24.1, -39.50000000000001, -35.400000000000006, -41.800000000000004, -41.50000000000001, -37.5, -31.900000000000006, -32.2, -35.800000000000004, -63.30000000000001, -30.6, -43.60000000000001, -42.0, -41.900000000000006, -38.60000000000001, -38.1, -72.20000000000002, -25.200000000000003, -43.3, -35.7, -41.10000000000001, -55.800000000000004, -49.6, -42.00000000000001, -26.599999999999998, -43.599999999999994, -32.800000000000004, -40.90000000000001, -42.8, -45.500000000000014, -38.60000000000001, -36.8, -50.300000000000004, -41.1, -43.00000000000001, -48.8, -42.50000000000001, -30.0, -32.9, -35.7, -44.59999999999999, -43.000000000000014, -36.1, -40.1, -58.900000000000006, -45.800000000000004, -43.1, -33.4, -53.90000000000001, -36.699999999999996, -38.7, -32.900000000000006, -48.800000000000004, -59.69999999999999, -53.900000000000006, -52.400000000000006, -42.900000000000006, -46.70000000000001, -42.7, -38.3, -47.10000000000001, -45.7, -43.300000000000004, -38.300000000000004, -33.900000000000006, -39.0, -42.2, -28.3, -39.300000000000004, -53.6, -43.800000000000004, -48.30000000000001, -51.300000000000004, -38.300000000000004, -37.1, -41.400000000000006, -49.10000000000001, -55.2, -34.4, -28.6, -41.1, -46.800000000000004, -33.6, -38.1, -46.00000000000001, -38.00000000000001, -39.5, -40.2, -26.599999999999998, -46.9, -45.300000000000004, -32.7, -39.0, -50.6, -48.7, -43.7, -45.50000000000001, -46.800000000000004, -46.90000000000001, -23.900000000000002, -35.9, -36.6, -43.60000000000001, -39.60000000000001, -36.5, -32.7, -34.7, -49.20000000000001, -53.199999999999996, -38.9, -45.0, -36.3, -45.900000000000006, -35.5, -60.7, -50.70000000000001, -40.6, -42.10000000000001, -22.5, -47.00000000000001, -42.0, -39.30000000000001, -51.9, -59.10000000000001, -52.7, -37.6, -53.90000000000001, -32.0, -35.80000000000001, -34.800000000000004, -48.30000000000001, -49.7, -27.0, -37.2, -36.0, -49.2, -53.30000000000001, -55.00000000000001, -46.8, -40.2, -47.8, -42.2, -40.8, -43.1, -50.400000000000006, -31.800000000000004, -41.9, -35.099999999999994, -37.8, -42.00000000000001, -52.0, -41.4, -47.900000000000006, -44.400000000000006, -43.00000000000001, -48.6, -49.30000000000001, -50.00000000000001, -37.9, -31.700000000000003, -36.300000000000004, -40.1, -35.50000000000001, -40.50000000000001, -37.7, -48.80000000000001, -45.199999999999996, -32.5, -42.1, -43.1, -26.4, -36.5, -41.80000000000001, -26.3, -39.699999999999996, -39.1, -46.00000000000001, -40.5, -41.0, -49.400000000000006, -38.1, -51.000000000000014, -33.5, -46.70000000000001, -35.1, -45.70000000000001, -50.70000000000001, -53.90000000000001, -39.3, -51.5, -42.6, -32.5, -34.20000000000001, -43.60000000000001, -44.300000000000004, -37.2, -45.1, -50.300000000000004, -41.8, -40.60000000000001, -35.5, -33.900000000000006, -54.20000000000001, -55.60000000000001, -33.6, -44.800000000000004, -32.7, -36.6, -44.7, -31.3, -38.70000000000001, -50.1, -26.0, -38.7, -49.7, -35.900000000000006, -34.900000000000006], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13933385571118698, "mean_inference_ms": 1.2621821733207204, "mean_action_processing_ms": 0.056589372852429674, "mean_env_wait_ms": 2.1907014487890035, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 252000, "agent_timesteps_total": 252000, "timers": {"sample_time_ms": 7779.064, "sample_throughput": 514.201, "load_time_ms": 0.058, "load_throughput": 69528454.206, "learn_time_ms": 8221.594, "learn_throughput": 486.524, "update_time_ms": 1.797}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 154.51474157353883, "policy_loss": -0.022376485515926633, "vf_loss": 154.5354398255707, "vf_explained_var": [0.07273802161216736], "kl": 0.00839118144706691, "entropy": 0.6464974096385382, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 252000, "num_agent_steps_sampled": 252000, "num_steps_trained": 252000, "num_agent_steps_trained": 252000}, "done": false, "episodes_total": 16800, "training_iteration": 63, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-26-27", "timestamp": 1632518787, "time_this_iter_s": 14.218061447143555, "time_total_s": 952.8866651058197, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 952.8866651058197, "timesteps_since_restore": 0, "iterations_since_restore": 63, "perf": {"cpu_util_percent": 34.135000000000005, "ram_util_percent": 16.0}}
{"episode_reward_max": -18.8, "episode_reward_min": -67.49999999999997, "episode_reward_mean": -40.74699248120301, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.50000000000001, -38.0, -55.30000000000001, -45.50000000000001, -38.5, -33.400000000000006, -31.900000000000002, -35.9, -47.800000000000004, -44.50000000000001, -38.300000000000004, -36.2, -42.900000000000006, -48.1, -39.1, -34.2, -30.6, -40.1, -39.80000000000001, -39.00000000000001, -35.8, -36.2, -55.2, -33.9, -43.5, -37.2, -30.500000000000004, -33.7, -58.800000000000004, -39.900000000000006, -38.6, -32.6, -42.00000000000001, -29.799999999999997, -41.5, -57.00000000000001, -27.8, -42.6, -21.6, -55.1, -38.4, -32.400000000000006, -30.8, -51.80000000000001, -45.6, -41.6, -35.5, -36.800000000000004, -34.400000000000006, -49.50000000000001, -43.60000000000001, -42.800000000000004, -42.00000000000001, -51.00000000000001, -38.3, -35.2, -29.5, -50.300000000000004, -50.00000000000001, -53.2, -39.2, -27.600000000000005, -38.6, -36.400000000000006, -34.5, -57.2, -37.6, -31.5, -39.1, -37.5, -33.50000000000001, -39.60000000000001, -44.50000000000001, -32.400000000000006, -37.5, -56.400000000000006, -32.9, -47.70000000000001, -48.800000000000004, -57.90000000000001, -57.00000000000001, -32.3, -37.400000000000006, -27.700000000000003, -36.0, -36.00000000000001, -31.200000000000003, -41.7, -47.90000000000001, -32.099999999999994, -67.49999999999997, -28.1, -38.800000000000004, -43.7, -29.200000000000006, -47.10000000000001, -34.6, -38.7, -36.5, -50.800000000000004, -33.9, -37.70000000000001, -49.9, -49.80000000000001, -30.8, -30.700000000000003, -36.60000000000001, -34.6, -34.0, -36.1, -34.5, -43.2, -41.6, -42.6, -41.00000000000001, -37.400000000000006, -31.300000000000004, -46.900000000000006, -32.4, -47.800000000000004, -20.7, -53.10000000000001, -38.300000000000004, -38.50000000000001, -45.4, -39.0, -44.2, -39.5, -35.3, -41.10000000000001, -39.400000000000006, -29.799999999999997, -41.2, -50.19999999999999, -33.70000000000001, -32.4, -40.3, -52.900000000000006, -32.7, -51.900000000000006, -36.800000000000004, -32.6, -30.4, -56.500000000000014, -53.000000000000014, -41.400000000000006, -44.29999999999999, -44.7, -54.300000000000004, -50.6, -46.8, -43.599999999999994, -36.900000000000006, -39.900000000000006, -29.9, -50.20000000000001, -48.7, -45.20000000000001, -35.0, -36.1, -36.00000000000001, -38.60000000000001, -41.800000000000004, -46.8, -49.2, -63.4, -42.7, -45.10000000000001, -37.300000000000004, -38.3, -39.00000000000001, -35.4, -44.2, -52.9, -26.8, -42.7, -47.3, -34.7, -42.400000000000006, -54.30000000000001, -34.9, -36.2, -30.299999999999997, -46.60000000000001, -48.9, -40.6, -41.1, -40.20000000000001, -41.199999999999996, -39.50000000000001, -47.099999999999994, -58.000000000000014, -42.4, -51.1, -33.0, -39.900000000000006, -43.800000000000004, -49.2, -44.4, -53.0, -47.5, -33.2, -38.3, -43.00000000000001, -38.800000000000004, -35.0, -39.50000000000001, -35.1, -47.400000000000006, -47.099999999999994, -38.4, -39.0, -48.2, -37.5, -38.0, -38.800000000000004, -42.80000000000001, -53.699999999999996, -55.10000000000001, -52.30000000000001, -34.900000000000006, -60.7, -45.300000000000004, -27.100000000000005, -31.299999999999997, -35.1, -35.0, -37.099999999999994, -45.10000000000001, -35.6, -33.0, -40.5, -33.9, -39.60000000000001, -40.900000000000006, -41.4, -18.8, -47.900000000000006, -45.00000000000001, -28.0, -32.800000000000004, -65.10000000000001, -33.0, -26.599999999999998, -35.0, -57.90000000000001, -46.40000000000001, -41.9, -45.00000000000001, -46.400000000000006, -31.000000000000004, -37.00000000000001, -36.199999999999996, -47.2, -36.3, -52.300000000000004, -28.8, -52.50000000000001, -36.300000000000004, -41.7, -36.50000000000001, -44.39999999999999, -40.5, -36.2, -30.3, -36.6], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13915180108518174, "mean_inference_ms": 1.2603589830385076, "mean_action_processing_ms": 0.05651424724993614, "mean_env_wait_ms": 2.1876628227104846, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 256000, "agent_timesteps_total": 256000, "timers": {"sample_time_ms": 7575.642, "sample_throughput": 528.008, "load_time_ms": 0.057, "load_throughput": 70492504.202, "learn_time_ms": 8122.594, "learn_throughput": 492.454, "update_time_ms": 1.807}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 148.02630330567717, "policy_loss": -0.022440228670314755, "vf_loss": 148.04730715187648, "vf_explained_var": [0.07120116800069809], "kl": 0.007180042069780264, "entropy": 0.6369190450637571, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 256000, "num_agent_steps_sampled": 256000, "num_steps_trained": 256000, "num_agent_steps_trained": 256000}, "done": false, "episodes_total": 17066, "training_iteration": 64, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-26-41", "timestamp": 1632518801, "time_this_iter_s": 13.90168046951294, "time_total_s": 966.7883455753326, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 966.7883455753326, "timesteps_since_restore": 0, "iterations_since_restore": 64, "perf": {"cpu_util_percent": 34.285, "ram_util_percent": 16.0}}
{"episode_reward_max": -20.5, "episode_reward_min": -72.50000000000001, "episode_reward_mean": -41.11278195488722, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-28.8, -36.800000000000004, -63.20000000000002, -28.700000000000003, -46.300000000000004, -32.900000000000006, -51.8, -39.800000000000004, -34.60000000000001, -72.50000000000001, -39.9, -52.0, -32.9, -45.7, -40.7, -53.1, -33.1, -39.300000000000004, -37.1, -41.000000000000014, -38.1, -40.900000000000006, -37.49999999999999, -36.79999999999999, -48.3, -42.1, -36.8, -45.7, -49.90000000000001, -50.00000000000001, -34.7, -42.7, -41.2, -31.700000000000003, -50.30000000000001, -56.4, -35.1, -24.0, -33.400000000000006, -31.1, -51.20000000000001, -33.5, -49.80000000000001, -50.0, -51.800000000000004, -50.900000000000006, -38.70000000000001, -34.2, -48.60000000000001, -49.400000000000006, -42.300000000000004, -31.900000000000002, -34.900000000000006, -37.7, -46.1, -35.800000000000004, -28.800000000000004, -27.0, -32.3, -59.20000000000001, -29.5, -31.200000000000003, -40.1, -45.2, -35.7, -45.30000000000001, -50.1, -47.30000000000001, -36.9, -41.5, -41.300000000000004, -53.10000000000001, -52.0, -29.0, -37.7, -32.4, -46.900000000000006, -45.0, -31.400000000000002, -40.2, -33.199999999999996, -33.2, -38.5, -46.2, -38.50000000000001, -51.80000000000001, -47.0, -34.0, -40.80000000000001, -39.6, -27.7, -42.4, -45.0, -40.0, -48.900000000000006, -36.7, -37.7, -31.4, -39.400000000000006, -45.699999999999996, -54.1, -56.10000000000001, -36.300000000000004, -52.2, -40.00000000000001, -31.200000000000003, -45.5, -47.1, -45.800000000000004, -25.3, -27.9, -58.20000000000002, -34.5, -40.4, -20.5, -36.2, -49.099999999999994, -44.300000000000004, -40.800000000000004, -38.6, -25.8, -34.00000000000001, -39.5, -40.900000000000006, -47.2, -37.10000000000001, -47.800000000000004, -47.400000000000006, -38.00000000000001, -32.20000000000001, -51.50000000000001, -55.1, -40.199999999999996, -49.4, -51.1, -52.2, -31.5, -46.4, -44.699999999999996, -40.50000000000001, -26.7, -41.0, -55.20000000000001, -42.1, -25.9, -34.6, -41.1, -46.400000000000006, -45.2, -44.400000000000006, -44.9, -43.9, -36.5, -29.599999999999998, -43.0, -48.0, -49.50000000000001, -39.20000000000001, -38.300000000000004, -40.50000000000001, -34.50000000000001, -59.3, -34.6, -39.00000000000001, -48.9, -27.200000000000003, -34.400000000000006, -34.8, -32.3, -38.1, -35.80000000000001, -37.7, -47.400000000000006, -40.900000000000006, -42.0, -38.1, -40.800000000000004, -34.2, -37.000000000000014, -42.199999999999996, -49.70000000000001, -42.9, -41.099999999999994, -54.800000000000004, -32.5, -38.30000000000001, -47.10000000000001, -36.6, -55.500000000000014, -49.00000000000001, -27.400000000000002, -37.800000000000004, -44.30000000000001, -40.599999999999994, -41.9, -39.1, -48.40000000000001, -38.50000000000001, -39.9, -57.49999999999999, -34.8, -58.20000000000001, -37.2, -37.8, -32.4, -52.300000000000004, -40.900000000000006, -43.60000000000001, -42.0, -34.3, -39.00000000000001, -35.300000000000004, -57.10000000000001, -37.2, -27.700000000000003, -35.1, -29.700000000000003, -45.400000000000006, -40.800000000000004, -37.400000000000006, -39.9, -36.6, -40.20000000000001, -31.1, -40.20000000000001, -36.50000000000001, -53.0, -39.6, -32.9, -44.4, -39.00000000000001, -40.900000000000006, -37.4, -37.800000000000004, -39.099999999999994, -42.2, -23.700000000000003, -34.900000000000006, -51.49999999999999, -52.49999999999999, -39.3, -28.400000000000006, -50.800000000000004, -47.30000000000001, -45.900000000000006, -42.2, -36.50000000000001, -39.2, -49.0, -36.3, -44.2, -41.199999999999996, -35.10000000000001, -38.300000000000004, -42.099999999999994, -49.500000000000014, -46.00000000000001, -41.2, -56.400000000000006, -35.800000000000004, -51.10000000000001, -36.80000000000001, -48.500000000000014, -35.400000000000006, -43.7, -49.0], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13896885949346974, "mean_inference_ms": 1.2586665103435901, "mean_action_processing_ms": 0.056438004570468894, "mean_env_wait_ms": 2.185025876003464, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 260000, "agent_timesteps_total": 260000, "timers": {"sample_time_ms": 7541.867, "sample_throughput": 530.373, "load_time_ms": 0.055, "load_throughput": 72723086.259, "learn_time_ms": 8127.288, "learn_throughput": 492.169, "update_time_ms": 1.806}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 145.2997268348612, "policy_loss": -0.02341511749126698, "vf_loss": 145.32179161810106, "vf_explained_var": [0.074247807264328], "kl": 0.006748810667286482, "entropy": 0.6157464983642742, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 260000, "num_agent_steps_sampled": 260000, "num_steps_trained": 260000, "num_agent_steps_trained": 260000}, "done": false, "episodes_total": 17332, "training_iteration": 65, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-26-55", "timestamp": 1632518815, "time_this_iter_s": 14.268199443817139, "time_total_s": 981.0565450191498, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 981.0565450191498, "timesteps_since_restore": 0, "iterations_since_restore": 65, "perf": {"cpu_util_percent": 34.545, "ram_util_percent": 16.0}}
{"episode_reward_max": -20.6, "episode_reward_min": -72.19999999999997, "episode_reward_mean": -41.32462686567164, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 268, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.400000000000006, -46.90000000000001, -34.800000000000004, -47.2, -62.89999999999999, -41.9, -30.8, -51.3, -36.50000000000001, -50.900000000000006, -43.2, -31.9, -34.800000000000004, -41.6, -35.0, -42.6, -33.9, -42.1, -46.400000000000006, -35.8, -36.7, -41.400000000000006, -52.00000000000001, -45.4, -33.300000000000004, -55.300000000000004, -31.1, -36.60000000000001, -27.899999999999995, -29.0, -59.60000000000001, -38.5, -49.40000000000001, -52.20000000000001, -58.300000000000004, -49.7, -41.400000000000006, -48.2, -37.1, -36.400000000000006, -34.2, -71.80000000000001, -54.800000000000004, -50.70000000000001, -44.20000000000001, -36.900000000000006, -41.300000000000004, -47.80000000000001, -34.4, -40.60000000000001, -44.9, -50.5, -51.400000000000006, -33.300000000000004, -41.900000000000006, -40.300000000000004, -44.0, -36.6, -40.4, -41.6, -43.0, -37.10000000000001, -36.2, -59.7, -40.2, -44.80000000000001, -55.00000000000001, -38.80000000000001, -30.200000000000003, -45.5, -35.6, -35.7, -42.900000000000006, -46.20000000000001, -37.1, -53.9, -52.70000000000001, -32.800000000000004, -49.20000000000001, -33.699999999999996, -39.699999999999996, -37.9, -48.4, -52.100000000000016, -47.7, -46.0, -28.6, -59.30000000000002, -37.1, -33.1, -41.1, -35.900000000000006, -31.400000000000006, -36.5, -41.6, -26.200000000000003, -42.20000000000001, -37.0, -26.7, -50.80000000000001, -47.10000000000001, -32.00000000000001, -40.0, -43.300000000000004, -45.7, -37.5, -48.800000000000004, -45.00000000000001, -60.400000000000006, -39.2, -36.7, -47.7, -47.4, -72.19999999999997, -38.5, -37.300000000000004, -34.6, -37.9, -31.6, -36.2, -40.300000000000004, -53.50000000000001, -33.3, -29.800000000000004, -48.10000000000001, -26.5, -43.7, -44.900000000000006, -39.400000000000006, -37.5, -34.400000000000006, -24.3, -44.60000000000001, -23.5, -42.10000000000001, -36.70000000000001, -35.900000000000006, -43.0, -37.3, -42.2, -52.70000000000001, -56.7, -43.400000000000006, -29.6, -39.2, -42.3, -39.5, -29.9, -45.10000000000001, -38.8, -40.800000000000004, -35.300000000000004, -42.60000000000001, -35.2, -37.4, -32.9, -46.50000000000001, -30.900000000000002, -34.7, -47.3, -29.200000000000003, -41.699999999999996, -39.5, -38.400000000000006, -32.7, -27.700000000000006, -40.8, -39.400000000000006, -35.9, -45.0, -42.0, -31.0, -29.8, -42.3, -46.9, -31.900000000000002, -40.1, -46.40000000000001, -43.30000000000001, -35.7, -35.5, -31.6, -51.70000000000002, -39.20000000000001, -38.599999999999994, -44.6, -30.5, -52.0, -37.800000000000004, -46.800000000000004, -56.30000000000001, -35.400000000000006, -41.7, -28.700000000000003, -39.0, -37.4, -48.400000000000006, -32.9, -47.400000000000006, -34.50000000000001, -45.00000000000001, -36.50000000000001, -48.5, -39.3, -44.8, -30.000000000000004, -71.1, -53.6, -51.500000000000014, -40.6, -32.300000000000004, -28.2, -36.5, -31.4, -53.20000000000001, -34.1, -42.6, -50.80000000000001, -43.2, -30.299999999999997, -38.5, -47.60000000000001, -32.300000000000004, -47.40000000000001, -61.00000000000001, -34.800000000000004, -55.90000000000001, -39.300000000000004, -44.00000000000001, -54.300000000000004, -48.50000000000001, -52.300000000000004, -45.2, -34.300000000000004, -43.20000000000001, -30.8, -42.9, -48.0, -43.9, -33.00000000000001, -46.900000000000006, -39.0, -37.4, -49.60000000000001, -36.400000000000006, -40.300000000000004, -33.1, -39.4, -39.7, -20.6, -36.800000000000004, -46.2, -36.50000000000001, -50.800000000000004, -33.9, -53.1, -41.0, -46.699999999999996, -36.0, -51.00000000000001, -38.2, -23.700000000000003, -39.5, -43.7, -47.900000000000006, -44.3, -33.7, -56.70000000000001], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13915139139920016, "mean_inference_ms": 1.2603853327952677, "mean_action_processing_ms": 0.05650617136366335, "mean_env_wait_ms": 2.184165671820327, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 264000, "agent_timesteps_total": 264000, "timers": {"sample_time_ms": 7579.608, "sample_throughput": 527.732, "load_time_ms": 0.053, "load_throughput": 75505022.502, "learn_time_ms": 8187.648, "learn_throughput": 488.541, "update_time_ms": 1.833}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 152.70702751733924, "policy_loss": -0.02513249369578496, "vf_loss": 152.73084462483723, "vf_explained_var": [0.06874142587184906], "kl": 0.006576643675462655, "entropy": 0.593494943200901, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 264000, "num_agent_steps_sampled": 264000, "num_steps_trained": 264000, "num_agent_steps_trained": 264000}, "done": false, "episodes_total": 17600, "training_iteration": 66, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-27-11", "timestamp": 1632518831, "time_this_iter_s": 16.022175550460815, "time_total_s": 997.0787205696106, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 997.0787205696106, "timesteps_since_restore": 0, "iterations_since_restore": 66, "perf": {"cpu_util_percent": 35.791304347826085, "ram_util_percent": 16.0}}
{"episode_reward_max": -20.400000000000006, "episode_reward_min": -73.79999999999998, "episode_reward_mean": -40.536466165413536, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-36.400000000000006, -40.400000000000006, -27.2, -35.50000000000001, -38.300000000000004, -40.60000000000001, -39.4, -46.4, -32.7, -36.3, -43.4, -45.0, -45.1, -38.900000000000006, -20.400000000000006, -45.9, -30.500000000000004, -33.7, -47.80000000000001, -43.5, -50.10000000000001, -31.100000000000005, -46.9, -39.39999999999999, -31.100000000000005, -38.400000000000006, -26.2, -28.4, -47.3, -46.70000000000001, -28.1, -34.2, -39.5, -39.0, -32.0, -36.50000000000001, -38.10000000000001, -40.6, -22.3, -24.8, -49.6, -56.10000000000001, -31.4, -55.0, -48.20000000000001, -50.6, -43.300000000000004, -36.7, -42.40000000000001, -54.50000000000001, -40.50000000000001, -28.600000000000005, -37.6, -38.900000000000006, -42.2, -46.80000000000002, -40.1, -37.4, -48.50000000000001, -41.6, -39.4, -32.4, -57.5, -21.5, -51.800000000000004, -42.300000000000004, -44.8, -51.50000000000001, -36.300000000000004, -42.10000000000001, -37.6, -43.300000000000004, -51.5, -38.60000000000001, -39.6, -28.4, -37.6, -34.4, -44.900000000000006, -45.0, -65.10000000000001, -50.10000000000001, -40.0, -33.0, -34.8, -36.5, -28.9, -29.4, -69.60000000000001, -42.400000000000006, -47.1, -36.6, -39.8, -30.3, -41.3, -48.40000000000001, -39.89999999999999, -41.300000000000004, -28.4, -28.200000000000003, -43.800000000000004, -44.400000000000006, -43.70000000000001, -31.8, -40.9, -43.80000000000001, -32.599999999999994, -30.500000000000004, -55.300000000000004, -41.7, -42.50000000000001, -40.800000000000004, -32.8, -49.0, -29.400000000000002, -30.300000000000004, -47.40000000000001, -35.1, -40.00000000000001, -44.300000000000004, -35.9, -45.00000000000001, -52.900000000000006, -46.50000000000001, -36.7, -31.9, -45.800000000000004, -54.10000000000001, -39.7, -35.7, -39.3, -34.300000000000004, -43.2, -38.6, -51.7, -44.0, -58.6, -38.900000000000006, -46.2, -36.4, -33.900000000000006, -23.400000000000002, -42.1, -73.79999999999998, -51.000000000000014, -43.0, -53.5, -33.5, -22.199999999999996, -31.700000000000003, -41.300000000000004, -35.1, -41.300000000000004, -30.900000000000006, -32.099999999999994, -46.50000000000001, -39.10000000000001, -49.900000000000006, -48.60000000000001, -39.80000000000001, -41.2, -39.4, -47.300000000000004, -27.4, -48.60000000000001, -37.400000000000006, -32.9, -29.6, -35.60000000000001, -36.2, -39.8, -42.300000000000004, -49.7, -35.699999999999996, -46.900000000000006, -32.50000000000001, -36.7, -35.900000000000006, -48.800000000000004, -28.4, -32.1, -51.70000000000001, -38.599999999999994, -34.70000000000001, -43.50000000000001, -29.300000000000004, -45.2, -42.9, -45.300000000000004, -36.400000000000006, -46.300000000000004, -47.400000000000006, -46.6, -47.900000000000006, -38.80000000000001, -42.300000000000004, -39.300000000000004, -40.5, -32.3, -33.6, -29.200000000000003, -40.8, -43.5, -31.700000000000003, -49.800000000000004, -47.90000000000001, -40.6, -34.800000000000004, -29.2, -40.9, -58.80000000000001, -26.9, -46.10000000000001, -43.0, -29.599999999999998, -35.9, -45.3, -32.10000000000001, -46.7, -44.599999999999994, -41.500000000000014, -42.2, -45.400000000000006, -40.300000000000004, -48.80000000000001, -40.7, -36.7, -42.10000000000001, -49.3, -41.00000000000001, -39.7, -53.800000000000004, -32.50000000000001, -35.800000000000004, -49.800000000000004, -46.20000000000002, -53.099999999999994, -53.4, -43.900000000000006, -30.500000000000004, -54.300000000000004, -43.70000000000001, -28.5, -44.70000000000001, -39.3, -51.0, -41.10000000000001, -21.3, -51.6, -33.7, -52.2, -51.80000000000001, -37.3, -29.300000000000004, -33.4, -40.1, -47.10000000000001, -50.400000000000006, -42.70000000000002, -25.8, -52.00000000000001, -30.400000000000002, -43.2, -54.50000000000001, -40.1, -34.2], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13910697830798813, "mean_inference_ms": 1.2599073791956543, "mean_action_processing_ms": 0.05649423518466129, "mean_env_wait_ms": 2.182346415298556, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 268000, "agent_timesteps_total": 268000, "timers": {"sample_time_ms": 7552.035, "sample_throughput": 529.659, "load_time_ms": 0.053, "load_throughput": 75641190.261, "learn_time_ms": 8093.625, "learn_throughput": 494.216, "update_time_ms": 1.77}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 145.72639240552022, "policy_loss": -0.020083292223693382, "vf_loss": 145.74512337305214, "vf_explained_var": [0.07690507918596268], "kl": 0.006761204444400471, "entropy": 0.5759588322331829, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 268000, "num_agent_steps_sampled": 268000, "num_steps_trained": 268000, "num_agent_steps_trained": 268000}, "done": false, "episodes_total": 17866, "training_iteration": 67, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-27-26", "timestamp": 1632518846, "time_this_iter_s": 14.617833375930786, "time_total_s": 1011.6965539455414, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1011.6965539455414, "timesteps_since_restore": 0, "iterations_since_restore": 67, "perf": {"cpu_util_percent": 35.05238095238095, "ram_util_percent": 16.0}}
{"episode_reward_max": -18.0, "episode_reward_min": -66.3, "episode_reward_mean": -40.1109022556391, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-38.1, -45.70000000000001, -36.4, -27.5, -32.400000000000006, -24.200000000000003, -41.5, -29.7, -51.5, -39.800000000000004, -38.6, -30.2, -39.50000000000001, -41.2, -36.800000000000004, -40.3, -32.900000000000006, -38.1, -44.80000000000001, -35.7, -48.400000000000006, -47.3, -33.2, -35.800000000000004, -41.900000000000006, -45.8, -28.0, -42.6, -42.10000000000001, -51.5, -45.300000000000004, -59.1, -36.2, -41.400000000000006, -44.60000000000001, -43.50000000000001, -40.50000000000001, -46.8, -38.5, -29.5, -42.0, -44.0, -37.0, -41.400000000000006, -36.900000000000006, -31.7, -38.7, -41.10000000000001, -35.300000000000004, -25.8, -53.000000000000014, -64.40000000000002, -31.799999999999997, -38.4, -40.0, -44.800000000000004, -43.50000000000001, -42.699999999999996, -44.60000000000001, -40.800000000000004, -50.900000000000006, -37.1, -28.200000000000003, -36.800000000000004, -51.300000000000004, -40.300000000000004, -45.00000000000001, -56.7, -36.6, -59.7, -44.400000000000006, -43.2, -45.599999999999994, -29.300000000000004, -40.400000000000006, -30.9, -31.700000000000003, -50.1, -44.70000000000001, -29.0, -29.900000000000002, -50.800000000000004, -29.5, -54.300000000000004, -53.90000000000001, -42.9, -49.20000000000001, -46.699999999999996, -44.3, -41.60000000000001, -43.6, -32.1, -44.300000000000004, -38.60000000000001, -55.2, -38.1, -32.3, -43.80000000000001, -25.5, -46.199999999999996, -53.100000000000016, -35.900000000000006, -44.300000000000004, -33.900000000000006, -42.300000000000004, -41.6, -30.599999999999998, -45.60000000000001, -48.00000000000001, -34.7, -37.900000000000006, -45.20000000000001, -40.50000000000001, -41.4, -34.0, -32.3, -34.6, -33.5, -50.900000000000006, -43.50000000000001, -33.900000000000006, -39.3, -39.400000000000006, -39.599999999999994, -38.400000000000006, -34.8, -27.299999999999997, -42.900000000000006, -31.8, -32.9, -45.2, -36.3, -42.6, -45.7, -46.10000000000001, -59.7, -18.0, -47.10000000000001, -27.699999999999996, -56.000000000000014, -25.400000000000006, -29.5, -41.4, -44.9, -56.900000000000006, -32.2, -40.5, -34.8, -34.8, -44.50000000000001, -45.2, -66.3, -42.00000000000001, -42.0, -47.3, -37.60000000000001, -30.1, -57.50000000000001, -31.9, -37.2, -47.2, -39.400000000000006, -43.900000000000006, -31.799999999999997, -42.7, -35.00000000000001, -35.900000000000006, -38.2, -55.20000000000002, -20.8, -39.900000000000006, -49.40000000000001, -38.5, -33.2, -45.4, -35.2, -48.0, -37.0, -34.1, -32.9, -38.8, -61.6, -46.9, -47.7, -42.5, -33.300000000000004, -26.200000000000003, -30.099999999999994, -46.3, -32.4, -50.50000000000001, -48.6, -43.800000000000004, -35.3, -34.50000000000001, -51.0, -35.9, -38.7, -40.7, -44.6, -36.2, -41.6, -38.3, -25.6, -37.5, -27.500000000000004, -37.00000000000001, -36.9, -34.0, -31.400000000000002, -41.60000000000001, -43.400000000000006, -32.3, -35.900000000000006, -35.900000000000006, -37.89999999999999, -35.2, -39.8, -35.3, -40.9, -40.70000000000001, -37.20000000000001, -48.30000000000001, -37.3, -29.099999999999998, -46.1, -39.9, -38.5, -30.9, -21.4, -40.40000000000001, -28.799999999999997, -37.1, -48.300000000000004, -30.300000000000004, -39.7, -32.2, -53.10000000000001, -37.4, -40.900000000000006, -45.4, -41.800000000000004, -34.800000000000004, -43.30000000000001, -51.2, -40.4, -56.2, -40.300000000000004, -41.800000000000004, -40.7, -36.1, -51.70000000000001, -37.8, -44.800000000000004, -36.900000000000006, -32.900000000000006, -32.800000000000004, -40.800000000000004, -47.60000000000001, -33.800000000000004, -34.6, -52.50000000000001, -41.699999999999996, -36.8, -38.99999999999999, -48.9], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1389953310197366, "mean_inference_ms": 1.2587860020974737, "mean_action_processing_ms": 0.05644964248474683, "mean_env_wait_ms": 2.1797674953805615, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 272000, "agent_timesteps_total": 272000, "timers": {"sample_time_ms": 7422.327, "sample_throughput": 538.915, "load_time_ms": 0.053, "load_throughput": 75437122.302, "learn_time_ms": 7979.554, "learn_throughput": 501.281, "update_time_ms": 1.779}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 137.6044549511325, "policy_loss": -0.023222968807964716, "vf_loss": 137.62653226134597, "vf_explained_var": [0.08561273664236069], "kl": 0.005728347152327702, "entropy": 0.5866982403942334, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 272000, "num_agent_steps_sampled": 272000, "num_steps_trained": 272000, "num_agent_steps_trained": 272000}, "done": false, "episodes_total": 18132, "training_iteration": 68, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-27-40", "timestamp": 1632518860, "time_this_iter_s": 14.23347806930542, "time_total_s": 1025.9300320148468, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1025.9300320148468, "timesteps_since_restore": 0, "iterations_since_restore": 68, "perf": {"cpu_util_percent": 34.99523809523809, "ram_util_percent": 15.966666666666665}}
{"episode_reward_max": -18.7, "episode_reward_min": -72.0, "episode_reward_mean": -40.61044776119404, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 268, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-33.3, -41.5, -31.400000000000002, -36.2, -47.10000000000001, -33.7, -36.0, -42.1, -30.200000000000003, -49.6, -40.3, -42.40000000000001, -34.0, -25.8, -51.5, -44.50000000000001, -36.800000000000004, -53.800000000000004, -45.10000000000001, -34.800000000000004, -37.10000000000001, -35.50000000000001, -50.70000000000001, -29.800000000000004, -53.900000000000006, -39.900000000000006, -54.20000000000001, -35.00000000000001, -36.0, -46.70000000000001, -47.0, -51.90000000000001, -25.200000000000003, -36.300000000000004, -40.300000000000004, -37.2, -50.800000000000004, -42.3, -31.3, -35.1, -40.4, -42.500000000000014, -47.0, -45.800000000000004, -41.900000000000006, -23.400000000000002, -51.600000000000016, -43.5, -44.7, -47.199999999999996, -40.1, -35.800000000000004, -47.199999999999996, -44.400000000000006, -51.50000000000001, -42.30000000000001, -32.400000000000006, -44.50000000000001, -36.800000000000004, -52.5, -42.1, -38.60000000000001, -47.00000000000001, -55.00000000000001, -30.8, -40.5, -35.60000000000001, -30.0, -32.3, -53.00000000000001, -26.3, -28.6, -31.8, -46.8, -49.400000000000006, -37.3, -41.800000000000004, -31.9, -31.900000000000006, -38.5, -39.7, -39.800000000000004, -36.6, -28.8, -52.7, -29.600000000000005, -32.6, -32.4, -42.3, -30.100000000000005, -41.8, -42.1, -50.2, -46.800000000000004, -30.6, -23.700000000000003, -47.70000000000001, -44.70000000000001, -29.699999999999996, -37.3, -44.7, -55.70000000000001, -44.0, -44.400000000000006, -41.800000000000004, -47.20000000000001, -27.599999999999998, -41.300000000000004, -33.2, -40.9, -49.30000000000001, -28.8, -29.8, -34.2, -43.50000000000001, -36.800000000000004, -29.9, -51.300000000000004, -72.0, -43.500000000000014, -39.0, -41.400000000000006, -37.800000000000004, -42.7, -38.39999999999999, -40.0, -49.20000000000001, -50.60000000000001, -64.0, -34.400000000000006, -41.2, -38.7, -48.6, -48.60000000000001, -33.50000000000001, -18.7, -40.70000000000001, -40.7, -28.000000000000004, -63.2, -44.900000000000006, -41.1, -51.900000000000006, -44.699999999999996, -36.900000000000006, -42.300000000000004, -43.50000000000001, -44.400000000000006, -52.300000000000004, -45.4, -34.400000000000006, -48.5, -33.599999999999994, -46.60000000000001, -32.1, -43.5, -44.80000000000001, -48.60000000000001, -49.40000000000001, -35.0, -42.099999999999994, -45.30000000000001, -31.6, -29.3, -33.300000000000004, -35.4, -29.799999999999997, -46.7, -48.80000000000001, -27.6, -40.7, -64.20000000000002, -41.8, -29.1, -32.1, -32.9, -41.6, -34.9, -42.300000000000004, -40.900000000000006, -29.5, -32.8, -38.4, -59.00000000000001, -41.6, -41.0, -50.1, -38.50000000000001, -46.500000000000014, -39.5, -38.900000000000006, -30.3, -38.7, -38.6, -29.1, -39.00000000000001, -27.700000000000003, -32.1, -30.400000000000002, -33.800000000000004, -43.0, -53.70000000000001, -39.7, -45.800000000000004, -58.5, -58.400000000000006, -48.300000000000004, -46.10000000000001, -25.1, -44.1, -36.2, -38.6, -44.90000000000001, -41.300000000000004, -63.9, -29.200000000000003, -24.8, -48.9, -39.5, -65.4, -39.400000000000006, -39.0, -59.00000000000001, -34.400000000000006, -44.0, -36.50000000000001, -47.900000000000006, -39.7, -38.3, -21.6, -30.2, -41.0, -28.9, -38.70000000000001, -41.900000000000006, -36.9, -49.20000000000001, -43.400000000000006, -33.2, -31.400000000000002, -32.6, -52.70000000000001, -40.400000000000006, -45.00000000000001, -45.2, -33.3, -35.1, -49.000000000000014, -31.900000000000006, -46.5, -30.200000000000003, -50.80000000000001, -39.40000000000001, -37.8, -39.8, -40.10000000000001, -41.400000000000006, -36.6, -45.90000000000001, -36.1, -47.300000000000004, -36.3, -30.5, -49.00000000000001, -44.400000000000006, -43.9, -45.60000000000001, -47.500000000000014], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13885733371218004, "mean_inference_ms": 1.257352004506377, "mean_action_processing_ms": 0.056389225542451606, "mean_env_wait_ms": 2.17696647478326, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 276000, "agent_timesteps_total": 276000, "timers": {"sample_time_ms": 7265.581, "sample_throughput": 550.541, "load_time_ms": 0.051, "load_throughput": 77744281.742, "learn_time_ms": 7777.296, "learn_throughput": 514.318, "update_time_ms": 1.583}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 147.82527544575353, "policy_loss": -0.022512946163694706, "vf_loss": 147.84651712397093, "vf_explained_var": [0.07777571678161621], "kl": 0.006354334217063599, "entropy": 0.5685096307467389, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 276000, "num_agent_steps_sampled": 276000, "num_steps_trained": 276000, "num_agent_steps_trained": 276000}, "done": false, "episodes_total": 18400, "training_iteration": 69, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-27-55", "timestamp": 1632518875, "time_this_iter_s": 14.222554922103882, "time_total_s": 1040.1525869369507, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1040.1525869369507, "timesteps_since_restore": 0, "iterations_since_restore": 69, "perf": {"cpu_util_percent": 35.33, "ram_util_percent": 16.0}}
{"episode_reward_max": -23.4, "episode_reward_min": -66.5, "episode_reward_mean": -41.17706766917294, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-34.8, -39.900000000000006, -44.699999999999996, -45.300000000000004, -39.50000000000001, -40.5, -62.3, -45.300000000000004, -43.8, -51.0, -52.100000000000016, -57.6, -32.9, -40.900000000000006, -52.400000000000006, -36.2, -52.600000000000016, -46.8, -43.00000000000001, -38.2, -49.099999999999994, -41.2, -34.7, -39.50000000000001, -42.800000000000004, -49.5, -66.5, -59.3, -35.2, -47.1, -40.3, -41.2, -32.00000000000001, -48.00000000000001, -40.6, -40.6, -45.60000000000001, -33.0, -41.3, -41.70000000000001, -38.4, -47.300000000000004, -32.8, -42.6, -43.6, -31.700000000000006, -38.9, -31.200000000000006, -41.10000000000001, -31.2, -37.7, -51.5, -38.300000000000004, -54.80000000000001, -35.300000000000004, -40.7, -36.9, -50.400000000000006, -55.60000000000001, -43.8, -44.7, -35.300000000000004, -41.60000000000001, -28.3, -47.0, -50.8, -31.1, -38.4, -28.0, -42.00000000000001, -23.5, -41.1, -30.400000000000002, -51.40000000000001, -31.000000000000004, -38.599999999999994, -45.70000000000001, -28.900000000000002, -42.300000000000004, -38.10000000000001, -47.50000000000001, -31.900000000000006, -53.30000000000001, -40.900000000000006, -43.199999999999996, -28.0, -42.3, -49.50000000000001, -44.7, -42.800000000000004, -40.300000000000004, -58.900000000000006, -31.8, -43.5, -34.9, -38.1, -57.60000000000001, -32.800000000000004, -25.7, -48.099999999999994, -52.8, -46.20000000000001, -45.40000000000001, -51.800000000000004, -38.7, -29.700000000000003, -40.4, -33.2, -39.6, -56.70000000000001, -42.2, -52.9, -37.900000000000006, -39.10000000000001, -37.0, -57.30000000000001, -32.00000000000001, -41.300000000000004, -39.6, -43.10000000000001, -42.39999999999999, -43.0, -42.7, -38.5, -49.40000000000001, -38.40000000000001, -40.39999999999999, -32.6, -47.10000000000001, -43.0, -44.00000000000001, -36.900000000000006, -53.400000000000006, -46.0, -38.2, -49.900000000000006, -46.5, -43.8, -40.1, -32.0, -34.1, -48.30000000000001, -42.300000000000004, -46.0, -39.900000000000006, -51.90000000000002, -42.199999999999996, -41.0, -45.400000000000006, -30.3, -35.50000000000001, -39.0, -42.60000000000001, -56.30000000000001, -43.900000000000006, -42.50000000000001, -35.8, -37.400000000000006, -48.49999999999999, -38.70000000000001, -34.900000000000006, -29.200000000000003, -25.700000000000003, -57.500000000000014, -34.2, -40.6, -35.400000000000006, -51.5, -44.900000000000006, -43.1, -36.6, -36.0, -46.60000000000001, -26.500000000000004, -33.1, -40.5, -53.800000000000004, -56.80000000000001, -31.900000000000006, -41.80000000000001, -53.10000000000001, -38.1, -36.5, -31.9, -27.3, -38.800000000000004, -32.7, -57.70000000000001, -41.0, -40.900000000000006, -33.099999999999994, -36.2, -38.7, -42.300000000000004, -29.099999999999998, -34.10000000000001, -37.60000000000001, -41.80000000000001, -41.1, -35.6, -52.60000000000001, -34.400000000000006, -23.4, -41.9, -47.400000000000006, -39.60000000000001, -41.7, -50.2, -49.000000000000014, -35.6, -44.60000000000001, -50.60000000000001, -32.1, -43.0, -46.099999999999994, -47.0, -48.60000000000001, -36.8, -36.5, -39.5, -44.00000000000001, -38.800000000000004, -34.1, -28.0, -50.40000000000001, -45.300000000000004, -43.400000000000006, -40.4, -33.400000000000006, -46.400000000000006, -30.400000000000002, -42.1, -29.500000000000004, -37.6, -45.70000000000001, -26.000000000000004, -64.40000000000002, -41.400000000000006, -31.3, -35.1, -38.0, -34.2, -36.5, -40.6, -39.1, -39.300000000000004, -30.700000000000003, -42.9, -44.50000000000001, -34.5, -42.9, -62.60000000000001, -49.00000000000001, -46.0, -51.400000000000006, -31.400000000000002, -42.8, -30.200000000000003, -27.1, -40.4, -24.700000000000003, -32.6, -34.8, -27.6, -49.300000000000004, -49.90000000000001], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13875973650299167, "mean_inference_ms": 1.2561141396853575, "mean_action_processing_ms": 0.05633805002670872, "mean_env_wait_ms": 2.1747016142782494, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 280000, "agent_timesteps_total": 280000, "timers": {"sample_time_ms": 7121.572, "sample_throughput": 561.674, "load_time_ms": 0.051, "load_throughput": 78655489.92, "learn_time_ms": 7504.69, "learn_throughput": 533.0, "update_time_ms": 1.553}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 148.6007422744587, "policy_loss": -0.02206382232277544, "vf_loss": 148.62173223187847, "vf_explained_var": [0.060517407953739166], "kl": 0.005372758964998043, "entropy": 0.5453526991349394, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 280000, "num_agent_steps_sampled": 280000, "num_steps_trained": 280000, "num_agent_steps_trained": 280000}, "done": false, "episodes_total": 18666, "training_iteration": 70, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-28-09", "timestamp": 1632518889, "time_this_iter_s": 14.09749436378479, "time_total_s": 1054.2500813007355, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1054.2500813007355, "timesteps_since_restore": 0, "iterations_since_restore": 70, "perf": {"cpu_util_percent": 34.434999999999995, "ram_util_percent": 16.0}}
{"episode_reward_max": -20.700000000000003, "episode_reward_min": -70.9, "episode_reward_mean": -39.47293233082707, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-41.70000000000002, -45.1, -46.8, -45.300000000000004, -43.50000000000001, -50.300000000000004, -28.8, -48.7, -41.9, -41.9, -38.8, -37.5, -47.5, -48.80000000000001, -37.4, -57.2, -38.2, -34.1, -43.70000000000001, -46.20000000000001, -33.800000000000004, -36.199999999999996, -35.900000000000006, -37.699999999999996, -42.20000000000001, -42.49999999999999, -40.50000000000001, -33.5, -40.3, -56.5, -32.00000000000001, -39.400000000000006, -40.300000000000004, -30.600000000000005, -45.70000000000001, -38.6, -38.8, -39.2, -48.00000000000001, -22.900000000000002, -38.900000000000006, -41.300000000000004, -45.9, -33.1, -42.300000000000004, -41.6, -39.5, -45.400000000000006, -21.700000000000003, -31.1, -35.2, -39.8, -32.2, -39.800000000000004, -61.599999999999994, -36.5, -39.00000000000001, -49.40000000000001, -37.7, -37.00000000000001, -64.9, -32.800000000000004, -34.8, -40.2, -47.7, -36.599999999999994, -38.20000000000001, -40.00000000000001, -33.900000000000006, -32.699999999999996, -30.400000000000006, -42.0, -26.1, -47.2, -32.5, -36.60000000000001, -43.6, -55.2, -38.900000000000006, -24.8, -47.1, -44.2, -26.900000000000002, -43.900000000000006, -48.4, -45.4, -70.9, -48.5, -29.6, -48.1, -35.400000000000006, -51.3, -27.900000000000002, -35.699999999999996, -33.199999999999996, -38.1, -27.800000000000004, -25.199999999999996, -22.8, -55.5, -35.300000000000004, -30.1, -40.60000000000001, -34.0, -23.700000000000003, -39.0, -50.5, -29.200000000000006, -54.70000000000001, -34.599999999999994, -36.7, -36.1, -45.400000000000006, -37.7, -38.00000000000001, -40.800000000000004, -34.699999999999996, -37.800000000000004, -44.000000000000014, -37.3, -33.099999999999994, -38.8, -25.9, -53.10000000000001, -40.5, -36.0, -53.100000000000016, -55.90000000000001, -31.600000000000005, -35.1, -30.900000000000002, -52.40000000000001, -47.7, -54.10000000000001, -32.7, -29.099999999999998, -31.500000000000004, -36.7, -56.00000000000001, -44.6, -37.2, -37.00000000000001, -26.700000000000003, -42.2, -50.10000000000001, -38.400000000000006, -31.700000000000003, -31.700000000000003, -33.2, -53.90000000000001, -33.3, -50.00000000000001, -53.80000000000001, -33.5, -35.400000000000006, -37.800000000000004, -38.300000000000004, -42.1, -49.80000000000001, -38.800000000000004, -39.3, -34.7, -40.2, -42.0, -30.8, -33.3, -36.1, -31.6, -34.300000000000004, -42.80000000000001, -28.0, -44.00000000000001, -33.6, -35.300000000000004, -49.80000000000001, -40.900000000000006, -40.0, -34.7, -42.5, -35.3, -54.30000000000001, -41.10000000000001, -48.900000000000006, -28.2, -44.6, -41.900000000000006, -39.0, -40.5, -49.2, -32.60000000000001, -43.89999999999999, -37.6, -37.5, -33.400000000000006, -47.1, -31.1, -43.1, -39.50000000000001, -27.799999999999997, -30.5, -27.5, -25.0, -39.300000000000004, -31.700000000000003, -39.300000000000004, -35.0, -44.0, -44.4, -30.1, -36.1, -33.800000000000004, -30.700000000000003, -24.200000000000003, -35.7, -44.400000000000006, -34.300000000000004, -32.0, -42.699999999999996, -47.40000000000001, -46.800000000000004, -34.10000000000001, -40.60000000000001, -49.1, -32.800000000000004, -37.300000000000004, -44.400000000000006, -20.700000000000003, -51.0, -43.6, -41.50000000000001, -39.3, -35.400000000000006, -34.9, -43.8, -39.1, -37.60000000000001, -38.9, -42.9, -38.10000000000001, -33.800000000000004, -32.800000000000004, -40.3, -40.3, -42.99999999999999, -48.5, -53.500000000000014, -43.1, -44.2, -40.10000000000001, -41.6, -26.900000000000002, -53.10000000000001, -35.6, -42.900000000000006, -37.400000000000006, -43.00000000000001, -29.3, -56.6, -34.099999999999994, -33.2, -37.1, -40.7, -36.1, -47.3, -43.2, -45.699999999999996], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1387167466858651, "mean_inference_ms": 1.2554135371496637, "mean_action_processing_ms": 0.05631052913216205, "mean_env_wait_ms": 2.1724493186022755, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 284000, "agent_timesteps_total": 284000, "timers": {"sample_time_ms": 6947.892, "sample_throughput": 575.714, "load_time_ms": 0.05, "load_throughput": 80698489.658, "learn_time_ms": 7443.985, "learn_throughput": 537.347, "update_time_ms": 1.512}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 136.22894731747206, "policy_loss": -0.023283685069851658, "vf_loss": 136.25114023352182, "vf_explained_var": [0.08760390430688858], "kl": 0.005454709217853114, "entropy": 0.5333133668989264, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 284000, "num_agent_steps_sampled": 284000, "num_steps_trained": 284000, "num_agent_steps_trained": 284000}, "done": false, "episodes_total": 18932, "training_iteration": 71, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-28-23", "timestamp": 1632518903, "time_this_iter_s": 14.21266222000122, "time_total_s": 1068.4627435207367, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1068.4627435207367, "timesteps_since_restore": 0, "iterations_since_restore": 71, "perf": {"cpu_util_percent": 35.15238095238095, "ram_util_percent": 16.028571428571436}}
{"episode_reward_max": -17.7, "episode_reward_min": -80.09999999999998, "episode_reward_mean": -40.03992537313433, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 268, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-38.00000000000001, -41.300000000000004, -36.900000000000006, -38.3, -53.0, -35.6, -58.800000000000004, -43.7, -46.70000000000001, -28.6, -41.400000000000006, -33.5, -35.5, -46.10000000000001, -44.1, -43.5, -21.400000000000002, -33.3, -51.900000000000006, -43.800000000000004, -34.2, -39.20000000000001, -38.0, -37.0, -47.5, -41.4, -48.49999999999999, -35.400000000000006, -42.1, -36.400000000000006, -32.7, -42.800000000000004, -37.90000000000001, -41.7, -27.8, -46.900000000000006, -36.5, -31.900000000000006, -30.3, -44.2, -35.2, -29.4, -36.400000000000006, -40.800000000000004, -30.1, -38.400000000000006, -42.099999999999994, -46.5, -29.1, -52.400000000000006, -58.300000000000004, -45.5, -38.800000000000004, -34.800000000000004, -54.9, -34.300000000000004, -47.7, -39.800000000000004, -41.4, -36.2, -41.50000000000001, -37.7, -48.70000000000001, -43.49999999999999, -34.1, -51.8, -31.9, -36.9, -34.00000000000001, -45.400000000000006, -42.50000000000001, -51.2, -50.6, -36.50000000000001, -38.400000000000006, -32.6, -32.4, -36.8, -48.300000000000004, -32.4, -36.6, -47.2, -46.60000000000001, -29.2, -44.70000000000001, -45.6, -17.7, -27.1, -44.800000000000004, -33.7, -27.9, -28.0, -38.99999999999999, -34.2, -32.900000000000006, -37.8, -43.10000000000001, -44.0, -39.400000000000006, -48.10000000000001, -31.700000000000003, -52.00000000000001, -32.6, -39.0, -37.9, -43.400000000000006, -36.7, -44.0, -48.00000000000001, -40.5, -47.400000000000006, -23.099999999999998, -44.60000000000001, -34.800000000000004, -26.500000000000004, -39.60000000000001, -46.20000000000002, -35.3, -35.1, -46.900000000000006, -42.5, -33.5, -22.7, -32.2, -30.900000000000002, -47.10000000000001, -42.5, -40.800000000000004, -30.900000000000002, -31.900000000000002, -37.8, -30.4, -34.80000000000001, -54.3, -46.10000000000001, -34.6, -39.300000000000004, -26.9, -42.5, -31.700000000000003, -46.10000000000001, -46.7, -56.40000000000001, -47.9, -41.90000000000001, -37.2, -32.1, -36.80000000000001, -51.2, -55.80000000000001, -45.400000000000006, -30.0, -30.8, -40.6, -45.800000000000004, -36.800000000000004, -47.10000000000001, -50.5, -80.09999999999998, -36.900000000000006, -40.800000000000004, -39.3, -29.500000000000004, -33.4, -60.4, -32.5, -35.3, -29.900000000000002, -49.6, -30.400000000000002, -41.4, -65.20000000000002, -37.70000000000001, -49.000000000000014, -39.5, -39.1, -44.5, -48.0, -39.1, -41.400000000000006, -52.30000000000001, -33.8, -46.400000000000006, -38.0, -32.900000000000006, -46.900000000000006, -47.20000000000001, -31.400000000000002, -35.4, -39.60000000000001, -39.2, -33.800000000000004, -47.50000000000001, -34.9, -34.0, -40.2, -61.6, -48.3, -53.900000000000006, -43.8, -44.70000000000001, -35.7, -52.70000000000001, -40.80000000000001, -38.800000000000004, -46.900000000000006, -30.500000000000004, -45.099999999999994, -23.9, -51.7, -23.000000000000004, -39.6, -43.8, -36.699999999999996, -40.6, -35.1, -38.80000000000001, -51.70000000000001, -51.60000000000001, -42.900000000000006, -38.6, -35.5, -41.0, -26.900000000000002, -41.1, -32.800000000000004, -45.500000000000014, -51.5, -37.5, -41.6, -35.4, -44.400000000000006, -39.9, -42.6, -37.4, -49.4, -68.6, -34.800000000000004, -37.900000000000006, -33.3, -50.000000000000014, -51.00000000000001, -31.299999999999997, -43.2, -39.900000000000006, -56.6, -25.999999999999993, -37.0, -32.6, -26.1, -42.6, -46.4, -35.800000000000004, -50.50000000000001, -25.1, -38.99999999999999, -33.5, -40.300000000000004, -41.800000000000004, -32.9, -22.900000000000002, -31.000000000000004, -44.500000000000014, -43.300000000000004, -28.700000000000003, -41.900000000000006, -36.400000000000006, -33.5], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13860588296385384, "mean_inference_ms": 1.2542620056931384, "mean_action_processing_ms": 0.0562632307657039, "mean_env_wait_ms": 2.1702123490798195, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 288000, "agent_timesteps_total": 288000, "timers": {"sample_time_ms": 6945.43, "sample_throughput": 575.918, "load_time_ms": 0.047, "load_throughput": 84434906.895, "learn_time_ms": 7426.099, "learn_throughput": 538.641, "update_time_ms": 1.543}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 143.59605446272, "policy_loss": -0.01863643139831081, "vf_loss": 143.6135251117009, "vf_explained_var": [0.06432578712701797], "kl": 0.005828002275222192, "entropy": 0.525023462118641, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 288000, "num_agent_steps_sampled": 288000, "num_steps_trained": 288000, "num_agent_steps_trained": 288000}, "done": false, "episodes_total": 19200, "training_iteration": 72, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-28-37", "timestamp": 1632518917, "time_this_iter_s": 14.025548934936523, "time_total_s": 1082.4882924556732, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1082.4882924556732, "timesteps_since_restore": 0, "iterations_since_restore": 72, "perf": {"cpu_util_percent": 34.925, "ram_util_percent": 16.100000000000005}}
{"episode_reward_max": -22.3, "episode_reward_min": -68.9, "episode_reward_mean": -40.45, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-42.4, -38.3, -33.7, -46.699999999999996, -41.50000000000001, -32.6, -31.7, -40.400000000000006, -34.1, -32.7, -33.800000000000004, -48.7, -45.800000000000004, -31.3, -36.900000000000006, -44.300000000000004, -30.400000000000006, -36.60000000000001, -44.1, -32.0, -34.6, -53.400000000000006, -59.400000000000006, -30.8, -31.3, -39.400000000000006, -47.10000000000001, -49.10000000000001, -30.1, -46.300000000000004, -36.300000000000004, -43.800000000000004, -37.6, -46.100000000000016, -54.7, -39.0, -35.1, -40.2, -41.800000000000004, -35.2, -35.7, -55.400000000000006, -29.799999999999997, -38.400000000000006, -50.400000000000006, -38.9, -32.6, -42.1, -59.900000000000006, -39.30000000000001, -48.300000000000004, -48.1, -39.7, -39.7, -42.900000000000006, -59.6, -31.1, -45.0, -50.4, -36.199999999999996, -24.700000000000003, -38.0, -36.50000000000001, -28.0, -33.00000000000001, -42.800000000000004, -28.400000000000002, -44.6, -39.6, -41.300000000000004, -45.900000000000006, -53.199999999999996, -30.700000000000003, -35.400000000000006, -48.70000000000001, -35.900000000000006, -45.70000000000001, -31.000000000000004, -26.5, -39.8, -36.7, -39.300000000000004, -26.699999999999996, -43.2, -42.10000000000001, -50.9, -26.2, -56.60000000000001, -35.300000000000004, -42.7, -41.9, -68.9, -35.4, -33.1, -47.8, -43.1, -43.5, -49.40000000000001, -39.400000000000006, -23.1, -62.400000000000006, -35.50000000000001, -31.8, -46.90000000000001, -43.5, -41.0, -43.70000000000001, -31.6, -34.3, -26.4, -52.199999999999996, -41.1, -42.6, -35.099999999999994, -27.700000000000003, -39.5, -44.8, -42.800000000000004, -48.0, -35.0, -41.0, -40.2, -40.300000000000004, -44.300000000000004, -39.0, -35.699999999999996, -67.9, -40.5, -31.6, -43.300000000000004, -40.5, -42.900000000000006, -44.3, -31.700000000000003, -39.9, -50.900000000000006, -38.2, -44.0, -43.10000000000001, -35.800000000000004, -47.4, -32.8, -43.8, -41.7, -60.89999999999999, -31.5, -47.80000000000001, -31.0, -54.8, -37.6, -52.00000000000001, -57.20000000000002, -29.3, -55.800000000000004, -42.50000000000001, -53.5, -49.30000000000001, -49.5, -45.60000000000001, -32.1, -44.500000000000014, -33.4, -44.00000000000001, -49.8, -38.3, -44.4, -34.699999999999996, -40.7, -45.9, -32.0, -43.1, -32.300000000000004, -56.800000000000004, -27.9, -37.6, -47.2, -39.4, -28.700000000000003, -38.699999999999996, -45.099999999999994, -45.100000000000016, -47.400000000000006, -52.000000000000014, -33.7, -42.900000000000006, -52.400000000000006, -41.000000000000014, -30.800000000000004, -35.300000000000004, -41.7, -42.8, -39.10000000000001, -56.7, -34.4, -44.0, -34.599999999999994, -40.199999999999996, -33.4, -35.300000000000004, -37.900000000000006, -22.3, -41.00000000000001, -36.2, -34.800000000000004, -46.60000000000001, -22.7, -45.7, -47.7, -39.1, -41.90000000000001, -33.2, -38.400000000000006, -47.300000000000004, -26.800000000000004, -31.700000000000003, -24.600000000000005, -35.900000000000006, -37.5, -41.5, -49.80000000000001, -42.6, -38.00000000000001, -28.100000000000005, -42.800000000000004, -29.9, -44.3, -35.5, -43.5, -37.00000000000001, -47.7, -46.50000000000001, -41.6, -30.000000000000004, -45.400000000000006, -31.6, -40.30000000000001, -31.6, -45.2, -48.2, -42.2, -26.900000000000006, -46.30000000000001, -43.00000000000001, -49.6, -49.7, -45.100000000000016, -54.0, -27.7, -38.60000000000001, -29.0, -53.00000000000001, -43.7, -30.8, -34.0, -32.400000000000006, -33.2, -40.7, -38.5, -30.700000000000003, -38.10000000000001, -52.30000000000001, -37.5, -36.70000000000001, -39.00000000000001, -46.2, -36.2], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1384716559889862, "mean_inference_ms": 1.2530120480330915, "mean_action_processing_ms": 0.056213069003411886, "mean_env_wait_ms": 2.167804165360565, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 292000, "agent_timesteps_total": 292000, "timers": {"sample_time_ms": 6917.071, "sample_throughput": 578.279, "load_time_ms": 0.047, "load_throughput": 84776230.419, "learn_time_ms": 7466.318, "learn_throughput": 535.739, "update_time_ms": 1.494}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 144.87734454575406, "policy_loss": -0.02341428146827766, "vf_loss": 144.89939781927293, "vf_explained_var": [0.06943631917238235], "kl": 0.006803246790169407, "entropy": 0.5037722875674565, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 292000, "num_agent_steps_sampled": 292000, "num_steps_trained": 292000, "num_agent_steps_trained": 292000}, "done": false, "episodes_total": 19466, "training_iteration": 73, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-28-52", "timestamp": 1632518932, "time_this_iter_s": 14.33760952949524, "time_total_s": 1096.8259019851685, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1096.8259019851685, "timesteps_since_restore": 0, "iterations_since_restore": 73, "perf": {"cpu_util_percent": 34.669999999999995, "ram_util_percent": 16.100000000000005}}
{"episode_reward_max": -17.2, "episode_reward_min": -61.900000000000006, "episode_reward_mean": -40.71992481203007, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-56.80000000000001, -17.2, -33.2, -32.3, -39.10000000000001, -42.3, -30.000000000000004, -31.900000000000006, -30.000000000000004, -27.400000000000002, -34.800000000000004, -56.0, -44.400000000000006, -38.0, -61.900000000000006, -36.8, -47.900000000000006, -49.00000000000001, -37.10000000000001, -39.900000000000006, -48.0, -28.90000000000001, -43.300000000000004, -43.800000000000004, -40.70000000000001, -46.0, -46.400000000000006, -40.7, -45.9, -39.40000000000001, -45.2, -26.5, -24.3, -41.6, -31.900000000000002, -43.2, -31.900000000000002, -41.9, -36.1, -49.7, -43.400000000000006, -28.200000000000003, -46.80000000000002, -37.400000000000006, -29.199999999999996, -45.6, -34.800000000000004, -51.00000000000001, -29.300000000000004, -50.500000000000014, -47.50000000000001, -43.10000000000001, -36.89999999999999, -31.900000000000006, -33.5, -50.60000000000001, -30.6, -51.800000000000004, -46.50000000000001, -48.3, -45.800000000000004, -56.1, -42.90000000000001, -28.5, -47.900000000000006, -43.60000000000001, -48.80000000000001, -43.10000000000001, -60.5, -33.4, -37.800000000000004, -37.9, -33.300000000000004, -48.60000000000001, -59.50000000000001, -39.4, -33.60000000000001, -42.0, -42.6, -42.5, -38.900000000000006, -47.0, -49.30000000000001, -32.5, -48.99999999999999, -45.800000000000004, -32.5, -42.699999999999996, -33.7, -53.10000000000001, -34.800000000000004, -53.10000000000001, -33.800000000000004, -45.90000000000001, -27.5, -42.30000000000001, -52.50000000000001, -26.5, -38.800000000000004, -46.80000000000001, -37.300000000000004, -37.3, -46.5, -32.8, -42.60000000000001, -47.9, -41.7, -40.50000000000001, -47.6, -46.10000000000001, -56.800000000000004, -34.0, -37.300000000000004, -34.800000000000004, -47.7, -44.400000000000006, -53.1, -37.50000000000001, -41.1, -41.0, -35.20000000000001, -41.4, -49.800000000000004, -44.2, -37.1, -42.699999999999996, -32.7, -32.900000000000006, -40.0, -36.2, -49.20000000000001, -39.7, -51.90000000000001, -41.400000000000006, -29.4, -43.1, -35.60000000000001, -34.7, -37.10000000000001, -30.0, -35.00000000000001, -56.1, -45.7, -44.800000000000004, -41.7, -40.900000000000006, -43.10000000000001, -37.0, -42.199999999999996, -38.7, -44.400000000000006, -25.5, -43.7, -36.4, -39.6, -39.70000000000001, -35.1, -38.2, -51.400000000000006, -39.800000000000004, -52.900000000000006, -30.2, -25.6, -49.7, -42.2, -36.900000000000006, -44.10000000000001, -21.1, -43.5, -27.5, -58.10000000000001, -39.50000000000001, -42.6, -46.3, -42.900000000000006, -49.0, -53.2, -30.500000000000004, -40.5, -44.699999999999996, -48.6, -25.1, -34.6, -55.70000000000001, -35.2, -36.2, -33.0, -27.000000000000007, -38.00000000000001, -42.900000000000006, -39.300000000000004, -41.00000000000001, -48.00000000000001, -47.6, -45.5, -52.90000000000001, -44.7, -44.80000000000001, -45.00000000000001, -40.5, -49.099999999999994, -32.50000000000001, -53.9, -28.1, -50.40000000000001, -19.3, -43.0, -40.3, -31.300000000000004, -33.5, -32.7, -46.1, -30.900000000000002, -45.6, -41.800000000000004, -26.8, -47.7, -43.2, -57.10000000000001, -38.9, -45.5, -33.2, -46.699999999999996, -40.800000000000004, -36.900000000000006, -40.6, -45.7, -41.70000000000001, -47.10000000000001, -60.2, -44.5, -43.7, -43.30000000000001, -33.1, -47.2, -31.0, -39.2, -52.900000000000006, -39.60000000000001, -28.700000000000003, -44.8, -40.2, -36.00000000000001, -28.0, -29.0, -43.1, -38.1, -41.6, -45.70000000000001, -42.8, -35.300000000000004, -38.2, -31.000000000000004, -35.6, -30.599999999999998, -53.2, -43.2, -48.39999999999999, -42.7, -43.900000000000006, -30.200000000000003, -33.7, -33.7, -45.00000000000001, -36.50000000000001, -36.7], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13844664082768893, "mean_inference_ms": 1.2528258832199943, "mean_action_processing_ms": 0.05621285168900892, "mean_env_wait_ms": 2.1663503456245885, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 296000, "agent_timesteps_total": 296000, "timers": {"sample_time_ms": 6948.102, "sample_throughput": 575.697, "load_time_ms": 0.047, "load_throughput": 84990962.513, "learn_time_ms": 7490.514, "learn_throughput": 534.009, "update_time_ms": 1.476}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 147.5954844320974, "policy_loss": -0.02140638248654463, "vf_loss": 147.61580715384534, "vf_explained_var": [0.07968860119581223], "kl": 0.0054192069501342, "entropy": 0.508696261304681, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 296000, "num_agent_steps_sampled": 296000, "num_steps_trained": 296000, "num_agent_steps_trained": 296000}, "done": false, "episodes_total": 19732, "training_iteration": 74, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-29-06", "timestamp": 1632518946, "time_this_iter_s": 14.452487230300903, "time_total_s": 1111.2783892154694, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1111.2783892154694, "timesteps_since_restore": 0, "iterations_since_restore": 74, "perf": {"cpu_util_percent": 34.938095238095244, "ram_util_percent": 16.100000000000005}}
{"episode_reward_max": -20.5, "episode_reward_min": -72.60000000000002, "episode_reward_mean": -41.082089552238806, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 268, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-35.900000000000006, -34.4, -50.900000000000006, -50.800000000000004, -46.1, -52.9, -38.8, -46.60000000000001, -51.7, -43.7, -39.2, -29.900000000000002, -53.2, -25.0, -33.2, -42.50000000000001, -39.6, -41.900000000000006, -54.20000000000001, -45.1, -33.1, -34.900000000000006, -27.900000000000002, -50.50000000000001, -38.60000000000001, -51.300000000000004, -56.70000000000001, -27.799999999999997, -34.2, -48.50000000000001, -36.4, -34.10000000000001, -53.10000000000001, -56.2, -44.9, -41.199999999999996, -43.2, -35.6, -47.900000000000006, -54.10000000000001, -39.5, -38.900000000000006, -39.400000000000006, -68.2, -30.1, -43.8, -40.400000000000006, -44.0, -46.699999999999996, -36.7, -44.900000000000006, -33.400000000000006, -40.4, -37.10000000000001, -37.90000000000001, -20.5, -38.0, -36.5, -32.20000000000001, -34.1, -45.300000000000004, -38.800000000000004, -55.00000000000001, -43.7, -43.900000000000006, -41.5, -36.5, -34.6, -39.4, -32.7, -37.300000000000004, -41.500000000000014, -32.6, -37.800000000000004, -34.800000000000004, -42.099999999999994, -32.50000000000001, -30.4, -49.300000000000004, -41.3, -42.900000000000006, -39.6, -55.30000000000001, -33.6, -47.40000000000002, -34.2, -36.00000000000001, -26.099999999999998, -46.60000000000001, -45.6, -43.00000000000001, -45.400000000000006, -36.800000000000004, -43.9, -49.00000000000001, -37.300000000000004, -49.5, -44.2, -35.5, -39.199999999999996, -43.2, -46.900000000000006, -51.70000000000001, -30.2, -41.800000000000004, -43.0, -35.1, -40.6, -36.6, -37.400000000000006, -38.900000000000006, -31.3, -54.80000000000001, -38.1, -45.2, -36.6, -37.3, -40.800000000000004, -36.0, -36.4, -41.2, -39.7, -51.80000000000001, -25.8, -50.7, -49.5, -36.099999999999994, -42.2, -29.900000000000002, -26.799999999999997, -37.800000000000004, -43.400000000000006, -27.2, -44.6, -37.99999999999999, -21.300000000000004, -40.5, -36.00000000000001, -34.300000000000004, -72.60000000000002, -38.800000000000004, -43.10000000000001, -52.300000000000004, -28.8, -45.900000000000006, -43.7, -49.10000000000002, -44.3, -39.3, -40.7, -36.99999999999999, -48.1, -35.6, -40.50000000000001, -39.10000000000001, -46.60000000000001, -54.300000000000004, -31.599999999999994, -42.5, -40.7, -39.5, -49.9, -43.80000000000001, -40.3, -27.0, -52.00000000000001, -32.6, -32.4, -49.00000000000001, -36.699999999999996, -36.400000000000006, -37.60000000000001, -49.300000000000004, -26.100000000000005, -34.900000000000006, -43.60000000000001, -59.10000000000002, -38.300000000000004, -31.900000000000006, -36.300000000000004, -55.100000000000016, -58.2, -33.3, -46.10000000000001, -44.00000000000001, -29.4, -45.20000000000001, -37.00000000000001, -43.00000000000001, -41.400000000000006, -42.400000000000006, -55.10000000000002, -34.400000000000006, -40.4, -43.4, -33.300000000000004, -25.7, -26.9, -33.7, -53.300000000000004, -46.6, -31.299999999999997, -55.70000000000001, -54.900000000000006, -41.7, -36.4, -29.5, -36.300000000000004, -56.60000000000001, -31.6, -26.9, -34.4, -43.80000000000001, -37.20000000000001, -46.400000000000006, -40.400000000000006, -40.5, -50.400000000000006, -50.900000000000006, -46.300000000000004, -37.900000000000006, -39.1, -38.900000000000006, -41.7, -50.30000000000001, -39.1, -44.3, -36.2, -48.400000000000006, -49.1, -48.400000000000006, -34.099999999999994, -37.2, -47.5, -41.900000000000006, -25.200000000000003, -43.1, -53.800000000000004, -48.5, -35.400000000000006, -39.800000000000004, -35.1, -52.8, -48.1, -45.00000000000001, -32.400000000000006, -37.1, -45.6, -45.099999999999994, -53.8, -52.5, -42.1, -34.199999999999996, -40.60000000000001, -45.0, -46.5, -28.000000000000004, -26.599999999999998, -40.900000000000006, -43.300000000000004, -59.800000000000004, -42.10000000000001, -32.300000000000004, -44.50000000000001, -28.200000000000003, -39.400000000000006, -44.900000000000006, -44.50000000000001], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13827819906742816, "mean_inference_ms": 1.2513223585663256, "mean_action_processing_ms": 0.05614742676516109, "mean_env_wait_ms": 2.1643101743462543, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 300000, "agent_timesteps_total": 300000, "timers": {"sample_time_ms": 6947.178, "sample_throughput": 575.773, "load_time_ms": 0.047, "load_throughput": 85250081.301, "learn_time_ms": 7651.829, "learn_throughput": 522.751, "update_time_ms": 1.529}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 149.987772082257, "policy_loss": -0.02109031515115852, "vf_loss": 150.00761029643397, "vf_explained_var": [0.07631801813840866], "kl": 0.006259230068663948, "entropy": 0.5102597744554602, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 300000, "num_agent_steps_sampled": 300000, "num_steps_trained": 300000, "num_agent_steps_trained": 300000}, "done": false, "episodes_total": 20000, "training_iteration": 75, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-29-22", "timestamp": 1632518962, "time_this_iter_s": 15.874038457870483, "time_total_s": 1127.1524276733398, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1127.1524276733398, "timesteps_since_restore": 0, "iterations_since_restore": 75, "perf": {"cpu_util_percent": 36.53478260869566, "ram_util_percent": 16.10000000000001}}
{"episode_reward_max": -18.2, "episode_reward_min": -61.90000000000001, "episode_reward_mean": -39.42819548872181, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-35.300000000000004, -31.3, -46.900000000000006, -45.0, -23.200000000000003, -39.1, -34.1, -34.6, -45.70000000000001, -28.6, -41.5, -36.10000000000001, -42.2, -38.2, -31.3, -45.800000000000004, -42.5, -51.10000000000001, -59.400000000000006, -55.4, -18.2, -40.10000000000001, -36.50000000000001, -36.5, -48.900000000000006, -38.50000000000001, -38.2, -36.800000000000004, -49.0, -38.00000000000001, -40.00000000000001, -32.300000000000004, -54.20000000000001, -40.199999999999996, -48.60000000000001, -49.5, -24.8, -51.7, -25.900000000000002, -22.799999999999997, -43.800000000000004, -32.39999999999999, -49.50000000000001, -38.00000000000001, -42.2, -39.800000000000004, -33.400000000000006, -27.4, -37.6, -26.000000000000004, -40.0, -23.9, -41.2, -42.7, -41.0, -50.400000000000006, -37.4, -25.2, -37.60000000000001, -54.699999999999996, -32.50000000000001, -38.800000000000004, -36.2, -46.099999999999994, -38.5, -26.1, -32.2, -35.50000000000001, -43.400000000000006, -37.7, -33.6, -58.400000000000006, -35.2, -59.5, -30.700000000000003, -36.199999999999996, -37.1, -49.800000000000004, -23.2, -33.7, -39.7, -30.500000000000004, -32.800000000000004, -44.50000000000001, -40.10000000000001, -42.300000000000004, -37.7, -38.699999999999996, -41.4, -37.5, -23.5, -39.50000000000001, -44.2, -41.900000000000006, -41.6, -41.5, -44.900000000000006, -37.199999999999996, -39.900000000000006, -39.8, -41.9, -38.0, -35.10000000000001, -37.4, -37.0, -35.800000000000004, -60.199999999999996, -43.9, -43.1, -43.7, -43.900000000000006, -54.800000000000004, -23.299999999999997, -44.50000000000001, -34.4, -28.099999999999998, -24.400000000000002, -48.80000000000001, -53.1, -34.7, -34.5, -33.7, -38.2, -42.699999999999996, -45.60000000000001, -36.4, -46.500000000000014, -41.3, -47.900000000000006, -28.200000000000003, -35.900000000000006, -40.900000000000006, -31.300000000000004, -40.1, -40.8, -41.300000000000004, -37.099999999999994, -35.1, -42.80000000000001, -53.1, -39.400000000000006, -45.5, -43.400000000000006, -46.60000000000001, -34.9, -35.0, -31.0, -27.9, -38.10000000000001, -45.8, -46.6, -40.7, -35.10000000000001, -45.80000000000001, -45.800000000000004, -31.400000000000002, -30.300000000000004, -34.199999999999996, -36.7, -29.200000000000003, -37.1, -46.20000000000001, -36.6, -28.200000000000003, -36.6, -43.2, -45.2, -40.6, -33.0, -35.8, -39.400000000000006, -41.4, -40.400000000000006, -42.9, -40.800000000000004, -45.2, -40.00000000000001, -35.599999999999994, -38.6, -41.199999999999996, -46.1, -31.2, -40.10000000000001, -45.60000000000001, -38.00000000000001, -29.599999999999998, -42.800000000000004, -33.800000000000004, -37.60000000000001, -42.199999999999996, -41.1, -48.0, -31.0, -37.800000000000004, -53.699999999999996, -37.00000000000001, -37.0, -30.700000000000003, -40.300000000000004, -38.00000000000001, -34.50000000000001, -45.00000000000001, -31.1, -54.199999999999996, -46.6, -39.5, -33.900000000000006, -31.700000000000003, -47.800000000000004, -61.90000000000001, -38.300000000000004, -56.00000000000001, -29.1, -43.900000000000006, -48.30000000000001, -45.00000000000001, -41.50000000000001, -37.60000000000001, -44.40000000000001, -22.6, -40.00000000000001, -37.0, -32.300000000000004, -37.8, -35.6, -45.2, -37.2, -23.200000000000003, -33.300000000000004, -20.5, -33.4, -42.500000000000014, -38.5, -50.5, -39.7, -33.9, -55.900000000000006, -42.3, -37.699999999999996, -45.900000000000006, -45.2, -37.800000000000004, -36.3, -43.7, -42.0, -44.900000000000006, -36.300000000000004, -38.00000000000001, -57.10000000000001, -33.900000000000006, -61.400000000000006, -52.800000000000004, -34.7, -34.9, -33.1, -47.80000000000001, -46.900000000000006, -31.5, -34.5, -39.4, -48.5, -33.6, -42.00000000000001, -46.70000000000001, -39.1, -32.2], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13904782940076044, "mean_inference_ms": 1.2584985196192406, "mean_action_processing_ms": 0.05644093417739242, "mean_env_wait_ms": 2.169377873555151, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 304000, "agent_timesteps_total": 304000, "timers": {"sample_time_ms": 7131.283, "sample_throughput": 560.909, "load_time_ms": 0.044, "load_throughput": 91032099.837, "learn_time_ms": 7571.685, "learn_throughput": 528.284, "update_time_ms": 1.483}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 141.0911520106818, "policy_loss": -0.017345401148001354, "vf_loss": 141.1073673535419, "vf_explained_var": [0.063516765832901], "kl": 0.0056502593003841, "entropy": 0.4989255203034288, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 304000, "num_agent_steps_sampled": 304000, "num_steps_trained": 304000, "num_agent_steps_trained": 304000}, "done": false, "episodes_total": 20266, "training_iteration": 76, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-29-39", "timestamp": 1632518979, "time_this_iter_s": 17.06143617630005, "time_total_s": 1144.21386384964, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1144.21386384964, "timesteps_since_restore": 0, "iterations_since_restore": 76, "perf": {"cpu_util_percent": 32.94583333333333, "ram_util_percent": 16.1}}
{"episode_reward_max": -16.9, "episode_reward_min": -68.1, "episode_reward_mean": -39.04812030075188, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-31.600000000000005, -40.800000000000004, -42.0, -44.5, -33.300000000000004, -31.5, -31.9, -25.3, -23.0, -31.6, -41.2, -37.300000000000004, -33.4, -31.900000000000002, -50.600000000000016, -43.300000000000004, -47.900000000000006, -37.5, -46.6, -32.5, -37.900000000000006, -46.7, -31.8, -50.60000000000001, -25.900000000000002, -33.0, -38.7, -44.800000000000004, -22.9, -40.9, -51.1, -37.800000000000004, -48.00000000000001, -33.6, -36.70000000000001, -34.900000000000006, -46.900000000000006, -33.5, -44.900000000000006, -42.6, -38.400000000000006, -51.39999999999999, -41.900000000000006, -36.5, -47.099999999999994, -39.900000000000006, -45.6, -42.800000000000004, -35.3, -44.800000000000004, -40.0, -34.300000000000004, -40.8, -26.000000000000004, -43.2, -49.1, -55.30000000000001, -41.10000000000001, -47.40000000000001, -53.0, -28.599999999999998, -31.6, -62.2, -34.50000000000001, -42.300000000000004, -43.49999999999999, -39.7, -45.400000000000006, -26.9, -45.300000000000004, -47.20000000000001, -41.800000000000004, -43.900000000000006, -32.0, -35.7, -46.10000000000001, -42.6, -30.500000000000004, -40.2, -30.700000000000006, -35.50000000000001, -44.800000000000004, -44.8, -36.900000000000006, -27.1, -35.8, -42.2, -42.00000000000001, -35.0, -29.5, -45.699999999999996, -40.500000000000014, -43.900000000000006, -46.60000000000001, -36.7, -38.3, -41.0, -33.400000000000006, -49.6, -49.3, -40.199999999999996, -39.1, -24.1, -30.000000000000004, -51.30000000000001, -24.700000000000003, -29.200000000000003, -31.9, -38.4, -46.0, -30.2, -28.1, -33.900000000000006, -49.7, -29.8, -51.4, -25.0, -47.0, -50.1, -42.400000000000006, -40.900000000000006, -32.2, -32.8, -39.2, -55.400000000000006, -44.2, -39.5, -39.5, -46.5, -32.4, -42.49999999999999, -41.30000000000001, -37.900000000000006, -37.6, -33.1, -39.3, -30.0, -29.299999999999997, -34.2, -37.900000000000006, -44.70000000000001, -30.1, -20.9, -45.800000000000004, -40.6, -31.599999999999998, -30.599999999999998, -61.000000000000014, -38.0, -46.20000000000001, -37.099999999999994, -32.099999999999994, -44.5, -42.400000000000006, -33.5, -36.500000000000014, -37.4, -40.8, -36.199999999999996, -39.599999999999994, -27.900000000000002, -34.8, -36.50000000000001, -41.2, -35.300000000000004, -49.2, -41.3, -30.9, -34.7, -35.6, -42.2, -33.300000000000004, -46.10000000000001, -33.4, -37.6, -32.2, -30.0, -30.800000000000004, -44.20000000000001, -37.5, -46.3, -57.500000000000014, -32.1, -45.70000000000001, -37.3, -68.1, -46.90000000000001, -57.699999999999996, -46.50000000000001, -51.00000000000001, -33.8, -31.900000000000006, -41.5, -46.300000000000004, -40.50000000000001, -51.000000000000014, -28.300000000000004, -30.8, -54.2, -37.39999999999999, -27.0, -44.0, -57.70000000000001, -24.8, -34.2, -43.300000000000004, -21.700000000000003, -52.10000000000001, -39.50000000000001, -46.39999999999999, -32.1, -45.70000000000001, -42.1, -23.900000000000002, -48.2, -58.50000000000001, -26.7, -28.7, -33.9, -38.7, -52.70000000000001, -31.0, -35.400000000000006, -43.800000000000004, -31.5, -55.20000000000001, -40.9, -52.400000000000006, -39.7, -21.900000000000006, -47.50000000000001, -27.700000000000006, -16.9, -38.1, -38.0, -32.6, -27.599999999999998, -33.4, -52.2, -29.200000000000003, -39.3, -32.900000000000006, -36.2, -41.10000000000001, -23.400000000000002, -29.9, -47.900000000000006, -39.10000000000001, -43.50000000000001, -36.8, -30.7, -31.900000000000006, -34.300000000000004, -45.30000000000001, -32.800000000000004, -46.9, -27.8, -38.4, -36.2, -46.0, -55.40000000000001, -36.2, -30.8, -61.60000000000001, -49.20000000000002, -34.900000000000006], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13893051082933525, "mean_inference_ms": 1.2575843989210085, "mean_action_processing_ms": 0.05640730518894415, "mean_env_wait_ms": 2.1669474037650907, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 308000, "agent_timesteps_total": 308000, "timers": {"sample_time_ms": 7102.133, "sample_throughput": 563.211, "load_time_ms": 0.044, "load_throughput": 90785800.866, "learn_time_ms": 7545.941, "learn_throughput": 530.086, "update_time_ms": 1.479}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 137.66535012850198, "policy_loss": -0.02026078519361314, "vf_loss": 137.68444596977645, "vf_explained_var": [0.06439986079931259], "kl": 0.0058215680627652375, "entropy": 0.4789773747485171, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 308000, "num_agent_steps_sampled": 308000, "num_steps_trained": 308000, "num_agent_steps_trained": 308000}, "done": false, "episodes_total": 20532, "training_iteration": 77, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-29-53", "timestamp": 1632518993, "time_this_iter_s": 14.068464994430542, "time_total_s": 1158.2823288440704, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1158.2823288440704, "timesteps_since_restore": 0, "iterations_since_restore": 77, "perf": {"cpu_util_percent": 35.084999999999994, "ram_util_percent": 16.100000000000005}}
{"episode_reward_max": -20.799999999999997, "episode_reward_min": -61.20000000000001, "episode_reward_mean": -40.424253731343285, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 268, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-57.7, -37.2, -32.6, -53.100000000000016, -42.400000000000006, -47.6, -39.6, -42.6, -48.70000000000002, -45.300000000000004, -54.800000000000004, -57.400000000000006, -42.800000000000004, -53.000000000000014, -56.50000000000002, -32.800000000000004, -38.1, -53.0, -29.200000000000003, -31.6, -26.1, -26.9, -29.800000000000004, -41.1, -44.60000000000001, -25.900000000000002, -44.5, -46.0, -40.6, -30.2, -40.0, -28.500000000000004, -39.00000000000001, -30.9, -49.30000000000001, -36.60000000000001, -37.800000000000004, -47.5, -36.900000000000006, -47.2, -38.900000000000006, -37.0, -26.600000000000005, -27.099999999999994, -45.00000000000001, -30.100000000000005, -42.2, -33.10000000000001, -29.5, -48.800000000000004, -34.9, -36.0, -41.099999999999994, -52.599999999999994, -42.400000000000006, -43.2, -29.400000000000002, -48.4, -38.400000000000006, -32.900000000000006, -27.300000000000004, -42.099999999999994, -28.400000000000006, -33.900000000000006, -42.199999999999996, -31.700000000000003, -49.100000000000016, -36.0, -36.50000000000001, -46.400000000000006, -36.4, -27.7, -33.599999999999994, -36.6, -43.1, -37.80000000000001, -37.10000000000001, -45.3, -53.900000000000006, -33.8, -53.39999999999999, -22.8, -44.60000000000001, -23.8, -47.50000000000001, -52.6, -40.2, -46.400000000000006, -29.0, -40.900000000000006, -41.6, -39.8, -36.4, -27.700000000000003, -31.8, -42.2, -32.6, -43.900000000000006, -39.1, -44.1, -52.50000000000001, -30.1, -48.300000000000004, -33.7, -39.400000000000006, -29.9, -51.60000000000001, -34.2, -51.99999999999999, -36.1, -31.900000000000002, -42.49999999999999, -45.7, -42.70000000000001, -34.6, -42.00000000000001, -37.7, -28.900000000000002, -43.7, -38.900000000000006, -57.300000000000004, -29.2, -44.1, -38.8, -44.50000000000001, -30.799999999999997, -37.0, -50.6, -37.2, -43.0, -52.400000000000006, -38.5, -41.2, -35.199999999999996, -28.100000000000005, -49.40000000000001, -40.5, -46.50000000000001, -46.400000000000006, -44.70000000000001, -49.4, -55.6, -36.7, -42.7, -35.50000000000001, -45.400000000000006, -37.3, -40.1, -46.30000000000001, -39.20000000000001, -52.8, -48.5, -55.70000000000001, -37.7, -36.6, -38.1, -40.50000000000001, -41.400000000000006, -45.800000000000004, -36.1, -27.6, -32.10000000000001, -47.9, -47.10000000000001, -43.50000000000001, -45.000000000000014, -53.6, -40.900000000000006, -45.800000000000004, -39.400000000000006, -37.6, -49.0, -48.10000000000001, -40.2, -40.7, -43.80000000000001, -35.5, -41.89999999999999, -44.7, -38.8, -40.9, -44.2, -33.9, -44.20000000000001, -38.10000000000001, -42.2, -49.800000000000004, -45.2, -51.100000000000016, -52.3, -30.300000000000004, -37.4, -52.60000000000001, -33.7, -44.6, -27.799999999999997, -32.3, -46.900000000000006, -37.0, -51.50000000000001, -48.80000000000001, -40.1, -56.6, -36.7, -31.800000000000008, -43.5, -36.800000000000004, -42.9, -39.50000000000001, -40.10000000000001, -35.1, -39.599999999999994, -32.00000000000001, -40.9, -32.2, -34.599999999999994, -48.60000000000001, -34.2, -49.400000000000006, -38.9, -36.5, -44.2, -58.1, -55.20000000000001, -52.5, -30.8, -41.0, -61.20000000000001, -35.400000000000006, -38.300000000000004, -50.50000000000001, -44.00000000000001, -20.799999999999997, -38.7, -38.1, -49.300000000000004, -32.9, -35.0, -30.200000000000003, -29.099999999999998, -35.5, -42.7, -25.6, -39.60000000000001, -47.7, -35.9, -32.3, -33.8, -32.6, -38.1, -42.5, -45.1, -43.7, -40.300000000000004, -35.5, -45.3, -45.9, -38.400000000000006, -39.4, -47.00000000000001, -43.6, -40.6, -44.40000000000001, -37.1, -41.5, -48.300000000000004, -31.6, -20.900000000000002], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13886946751404564, "mean_inference_ms": 1.2569355376718088, "mean_action_processing_ms": 0.05638078851857734, "mean_env_wait_ms": 2.1653403187477283, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 312000, "agent_timesteps_total": 312000, "timers": {"sample_time_ms": 7110.804, "sample_throughput": 562.524, "load_time_ms": 0.046, "load_throughput": 86703958.656, "learn_time_ms": 7563.319, "learn_throughput": 528.868, "update_time_ms": 1.467}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 145.26810838432723, "policy_loss": -0.01557660189967963, "vf_loss": 145.28248907109742, "vf_explained_var": [0.07453387975692749], "kl": 0.005978915989764587, "entropy": 0.4623175807537571, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 312000, "num_agent_steps_sampled": 312000, "num_steps_trained": 312000, "num_agent_steps_trained": 312000}, "done": false, "episodes_total": 20800, "training_iteration": 78, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-30-08", "timestamp": 1632519008, "time_this_iter_s": 14.492785215377808, "time_total_s": 1172.7751140594482, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1172.7751140594482, "timesteps_since_restore": 0, "iterations_since_restore": 78, "perf": {"cpu_util_percent": 35.40952380952381, "ram_util_percent": 16.100000000000005}}
{"episode_reward_max": -20.799999999999997, "episode_reward_min": -67.90000000000002, "episode_reward_mean": -40.56578947368421, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-50.7, -34.400000000000006, -59.30000000000001, -37.300000000000004, -37.800000000000004, -41.60000000000001, -46.5, -34.8, -35.5, -40.60000000000001, -34.00000000000001, -45.6, -36.30000000000001, -47.50000000000001, -31.400000000000002, -51.5, -46.8, -41.2, -42.400000000000006, -56.30000000000001, -47.300000000000004, -20.799999999999997, -61.00000000000001, -51.4, -44.5, -50.400000000000006, -38.8, -35.7, -53.900000000000006, -44.50000000000001, -42.10000000000001, -50.5, -35.2, -42.900000000000006, -48.80000000000001, -38.400000000000006, -41.7, -33.10000000000001, -42.50000000000001, -41.9, -40.1, -31.700000000000003, -34.300000000000004, -49.7, -39.1, -30.10000000000001, -63.400000000000006, -40.90000000000001, -29.9, -34.9, -30.900000000000002, -30.3, -32.699999999999996, -48.20000000000001, -39.400000000000006, -57.6, -40.099999999999994, -38.7, -44.20000000000001, -36.1, -30.799999999999997, -37.400000000000006, -54.30000000000001, -48.30000000000001, -42.800000000000004, -52.2, -38.300000000000004, -42.60000000000001, -35.400000000000006, -30.200000000000003, -40.8, -43.70000000000002, -34.400000000000006, -32.800000000000004, -38.5, -37.8, -37.9, -53.99999999999999, -39.9, -46.60000000000001, -41.2, -49.10000000000001, -49.30000000000001, -36.300000000000004, -40.300000000000004, -41.2, -28.600000000000005, -28.9, -41.300000000000004, -43.400000000000006, -54.800000000000004, -38.30000000000001, -53.0, -36.800000000000004, -34.2, -41.3, -33.6, -51.300000000000004, -49.50000000000001, -43.2, -48.3, -38.00000000000001, -32.900000000000006, -45.1, -38.2, -28.199999999999996, -50.30000000000001, -28.8, -32.00000000000001, -39.60000000000001, -39.70000000000001, -38.300000000000004, -34.2, -42.900000000000006, -29.699999999999996, -55.4, -27.700000000000006, -50.800000000000004, -37.600000000000016, -33.300000000000004, -51.000000000000014, -37.599999999999994, -36.5, -38.800000000000004, -41.1, -49.40000000000001, -53.7, -37.7, -56.500000000000014, -35.00000000000001, -25.500000000000004, -39.00000000000001, -32.00000000000001, -43.1, -54.9, -47.300000000000004, -50.1, -42.40000000000001, -46.7, -50.9, -33.900000000000006, -35.1, -51.20000000000002, -37.1, -44.6, -37.2, -40.0, -41.5, -39.8, -29.200000000000003, -38.900000000000006, -49.300000000000004, -40.50000000000001, -38.00000000000001, -35.3, -30.6, -36.800000000000004, -39.4, -46.300000000000004, -44.800000000000004, -29.500000000000004, -36.900000000000006, -33.9, -33.0, -30.200000000000003, -46.10000000000001, -30.800000000000004, -42.39999999999999, -29.6, -42.40000000000001, -40.60000000000001, -47.9, -39.3, -34.9, -45.7, -30.699999999999996, -49.6, -32.599999999999994, -32.7, -33.4, -46.60000000000001, -46.60000000000001, -44.7, -33.900000000000006, -47.3, -32.5, -40.5, -58.0, -41.400000000000006, -23.6, -40.900000000000006, -46.10000000000001, -39.0, -44.300000000000004, -42.9, -38.89999999999999, -33.0, -63.8, -26.1, -30.300000000000004, -32.4, -21.299999999999997, -28.400000000000006, -23.600000000000005, -43.9, -37.7, -37.6, -36.900000000000006, -29.1, -44.00000000000001, -67.90000000000002, -42.300000000000004, -38.5, -43.10000000000001, -50.2, -32.4, -49.2, -53.2, -43.699999999999996, -32.1, -45.599999999999994, -23.799999999999997, -33.2, -49.50000000000001, -36.3, -26.2, -38.199999999999996, -42.300000000000004, -47.60000000000001, -55.80000000000001, -33.0, -43.2, -51.000000000000014, -33.0, -62.90000000000001, -32.400000000000006, -29.5, -35.3, -41.30000000000001, -60.8, -35.300000000000004, -36.2, -36.699999999999996, -38.3, -33.300000000000004, -44.7, -38.800000000000004, -28.500000000000004, -36.3, -51.0, -66.3, -34.2, -42.1, -35.5, -43.500000000000014, -46.2, -43.50000000000001, -44.90000000000001, -25.0, -32.0, -36.800000000000004, -37.60000000000001, -38.3, -44.599999999999994, -41.2, -35.5], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13878745200246934, "mean_inference_ms": 1.2558072235957563, "mean_action_processing_ms": 0.05633717957137863, "mean_env_wait_ms": 2.1631719575640607, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 316000, "agent_timesteps_total": 316000, "timers": {"sample_time_ms": 7113.95, "sample_throughput": 562.276, "load_time_ms": 0.047, "load_throughput": 85163532.995, "learn_time_ms": 7557.498, "learn_throughput": 529.276, "update_time_ms": 1.438}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 149.28293410270444, "policy_loss": -0.017376044219840438, "vf_loss": 149.29925103956654, "vf_explained_var": [0.07425332069396973], "kl": 0.005299553711452522, "entropy": 0.4470622586306705, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 316000, "num_agent_steps_sampled": 316000, "num_steps_trained": 316000, "num_agent_steps_trained": 316000}, "done": false, "episodes_total": 21066, "training_iteration": 79, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-30-22", "timestamp": 1632519022, "time_this_iter_s": 14.19469165802002, "time_total_s": 1186.9698057174683, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1186.9698057174683, "timesteps_since_restore": 0, "iterations_since_restore": 79, "perf": {"cpu_util_percent": 34.945, "ram_util_percent": 16.100000000000005}}
{"episode_reward_max": -22.200000000000003, "episode_reward_min": -60.000000000000014, "episode_reward_mean": -39.73533834586466, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-33.0, -30.900000000000006, -36.2, -42.7, -24.700000000000003, -30.2, -45.7, -33.0, -47.400000000000006, -45.10000000000001, -49.0, -36.300000000000004, -47.49999999999999, -24.8, -39.1, -50.40000000000001, -32.3, -39.600000000000016, -36.2, -35.5, -48.1, -34.5, -29.300000000000004, -46.20000000000001, -35.50000000000001, -47.5, -51.00000000000001, -44.300000000000004, -24.0, -42.6, -36.6, -34.800000000000004, -41.50000000000001, -39.9, -25.3, -49.7, -48.0, -44.60000000000001, -32.6, -27.9, -23.1, -45.00000000000001, -30.099999999999998, -42.4, -45.7, -48.000000000000014, -46.8, -34.7, -50.20000000000001, -43.7, -30.6, -33.9, -33.4, -34.6, -49.30000000000001, -39.4, -44.6, -46.900000000000006, -39.7, -38.5, -44.2, -41.1, -28.700000000000003, -34.6, -46.1, -29.1, -31.700000000000003, -42.400000000000006, -42.6, -32.699999999999996, -29.800000000000004, -45.699999999999996, -35.2, -58.70000000000001, -50.500000000000014, -35.80000000000001, -49.199999999999996, -42.800000000000004, -34.7, -29.5, -31.6, -50.300000000000004, -35.5, -37.8, -34.5, -51.900000000000006, -60.000000000000014, -47.800000000000004, -36.0, -24.6, -53.60000000000001, -27.200000000000003, -38.0, -46.9, -31.3, -32.6, -45.4, -35.5, -31.7, -39.2, -41.30000000000001, -35.50000000000001, -52.900000000000006, -50.0, -34.199999999999996, -47.40000000000001, -46.10000000000001, -47.9, -29.5, -46.9, -31.5, -41.5, -53.20000000000001, -40.900000000000006, -38.7, -23.8, -42.1, -37.2, -53.7, -37.7, -40.400000000000006, -48.000000000000014, -40.3, -50.0, -40.9, -28.2, -43.5, -57.70000000000001, -30.2, -41.6, -57.6, -48.10000000000001, -41.30000000000001, -42.5, -37.8, -34.300000000000004, -31.8, -42.400000000000006, -35.0, -44.1, -53.1, -38.9, -32.49999999999999, -48.7, -59.80000000000001, -35.5, -47.5, -47.80000000000001, -39.9, -33.4, -34.50000000000001, -48.1, -41.4, -46.400000000000006, -36.7, -33.2, -42.300000000000004, -41.00000000000001, -50.1, -37.0, -48.70000000000001, -34.9, -38.2, -49.4, -39.800000000000004, -42.5, -51.60000000000001, -40.1, -47.7, -48.90000000000001, -37.3, -45.50000000000001, -43.699999999999996, -40.0, -42.7, -34.400000000000006, -34.400000000000006, -43.699999999999996, -43.800000000000004, -49.00000000000001, -33.3, -33.8, -40.5, -49.60000000000001, -46.0, -29.6, -43.400000000000006, -45.0, -29.6, -36.6, -37.3, -55.7, -35.2, -36.800000000000004, -51.300000000000004, -43.900000000000006, -27.5, -27.6, -40.50000000000001, -41.400000000000006, -35.0, -23.8, -26.400000000000002, -35.400000000000006, -43.40000000000001, -31.6, -33.5, -38.2, -36.800000000000004, -46.900000000000006, -30.000000000000004, -39.50000000000001, -36.1, -47.6, -29.9, -40.900000000000006, -48.199999999999996, -41.4, -30.799999999999997, -31.200000000000003, -41.699999999999996, -38.300000000000004, -43.0, -34.5, -56.100000000000016, -37.00000000000001, -41.2, -41.60000000000001, -43.60000000000001, -27.400000000000002, -29.4, -48.9, -31.1, -39.2, -42.1, -27.4, -32.5, -36.300000000000004, -44.300000000000004, -44.99999999999999, -55.70000000000002, -42.7, -31.8, -36.8, -40.099999999999994, -38.1, -41.900000000000006, -42.4, -22.200000000000003, -43.60000000000001, -34.2, -47.80000000000001, -40.80000000000001, -38.800000000000004, -46.00000000000001, -34.2, -39.9, -31.400000000000002, -24.600000000000005, -30.700000000000003, -34.4, -38.1, -48.3, -35.0, -27.2, -38.7], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13912361558267872, "mean_inference_ms": 1.2548978382005953, "mean_action_processing_ms": 0.05629913116146471, "mean_env_wait_ms": 2.1612539619860978, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 320000, "agent_timesteps_total": 320000, "timers": {"sample_time_ms": 7127.059, "sample_throughput": 561.241, "load_time_ms": 0.047, "load_throughput": 84990962.513, "learn_time_ms": 7589.294, "learn_throughput": 527.058, "update_time_ms": 1.435}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 138.1971457040438, "policy_loss": -0.018882245386159548, "vf_loss": 138.21484121507214, "vf_explained_var": [0.07279897481203079], "kl": 0.005933931481365934, "entropy": 0.4145491838134745, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 320000, "num_agent_steps_sampled": 320000, "num_steps_trained": 320000, "num_agent_steps_trained": 320000}, "done": false, "episodes_total": 21332, "training_iteration": 80, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-30-37", "timestamp": 1632519037, "time_this_iter_s": 14.546499013900757, "time_total_s": 1201.516304731369, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1201.516304731369, "timesteps_since_restore": 0, "iterations_since_restore": 80, "perf": {"cpu_util_percent": 35.509523809523806, "ram_util_percent": 16.100000000000005}}
{"episode_reward_max": -16.8, "episode_reward_min": -67.59999999999998, "episode_reward_mean": -39.985074626865675, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 268, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.5, -35.900000000000006, -34.1, -54.800000000000004, -48.300000000000004, -32.6, -38.60000000000001, -59.3, -43.0, -39.7, -24.400000000000002, -40.2, -28.6, -41.9, -49.10000000000001, -45.400000000000006, -32.60000000000001, -36.10000000000001, -39.7, -58.199999999999996, -46.40000000000001, -42.30000000000001, -41.6, -40.400000000000006, -32.6, -36.400000000000006, -51.80000000000001, -42.400000000000006, -31.000000000000004, -47.50000000000001, -27.700000000000003, -37.2, -46.60000000000001, -30.000000000000004, -34.1, -32.599999999999994, -35.800000000000004, -52.3, -32.1, -36.0, -37.300000000000004, -33.5, -41.90000000000001, -43.800000000000004, -29.200000000000003, -33.7, -57.400000000000006, -31.900000000000006, -44.2, -39.2, -42.900000000000006, -43.3, -50.50000000000001, -34.900000000000006, -50.5, -43.300000000000004, -40.400000000000006, -38.10000000000001, -43.70000000000002, -34.10000000000001, -31.900000000000002, -50.300000000000004, -43.10000000000001, -49.50000000000001, -30.1, -33.0, -39.7, -43.300000000000004, -30.3, -54.40000000000001, -51.60000000000001, -57.7, -51.2, -39.800000000000004, -34.0, -46.900000000000006, -37.2, -34.300000000000004, -56.5, -46.39999999999999, -26.7, -27.9, -46.50000000000001, -48.0, -40.5, -44.400000000000006, -44.400000000000006, -35.5, -32.7, -47.7, -41.60000000000001, -45.900000000000006, -31.800000000000004, -41.5, -43.00000000000001, -42.90000000000001, -50.5, -43.5, -40.199999999999996, -45.5, -28.0, -32.5, -35.2, -35.1, -39.9, -37.0, -33.0, -41.800000000000004, -37.49999999999999, -39.4, -27.8, -34.3, -53.300000000000004, -36.1, -52.300000000000004, -31.5, -24.6, -21.099999999999998, -51.5, -36.1, -49.500000000000014, -43.1, -67.59999999999998, -25.800000000000004, -41.2, -37.9, -40.60000000000001, -43.800000000000004, -42.2, -32.2, -31.9, -47.400000000000006, -37.9, -63.10000000000001, -37.599999999999994, -27.2, -45.7, -38.1, -37.0, -52.30000000000001, -29.5, -41.800000000000004, -29.2, -24.2, -36.800000000000004, -48.30000000000001, -65.70000000000002, -52.6, -31.700000000000003, -37.300000000000004, -28.9, -28.6, -32.8, -51.60000000000001, -32.4, -40.8, -44.300000000000004, -50.000000000000014, -50.400000000000006, -43.70000000000001, -43.000000000000014, -29.4, -42.099999999999994, -47.900000000000006, -35.2, -19.0, -31.800000000000004, -51.5, -16.8, -47.1, -26.799999999999997, -48.800000000000004, -39.800000000000004, -46.40000000000001, -31.8, -28.0, -34.5, -38.4, -30.400000000000002, -57.7, -44.7, -38.699999999999996, -33.5, -47.80000000000001, -35.800000000000004, -45.10000000000001, -41.1, -36.3, -53.800000000000004, -43.9, -43.4, -59.400000000000006, -29.500000000000004, -41.60000000000001, -40.400000000000006, -46.20000000000001, -20.8, -38.7, -54.300000000000004, -35.0, -35.800000000000004, -48.50000000000001, -46.9, -42.1, -36.6, -39.599999999999994, -21.0, -47.300000000000004, -35.0, -38.4, -30.800000000000004, -33.7, -37.1, -56.4, -31.800000000000004, -44.50000000000001, -38.3, -44.4, -31.200000000000003, -66.1, -44.300000000000004, -50.20000000000001, -34.1, -36.2, -33.900000000000006, -41.1, -25.400000000000002, -22.700000000000003, -40.0, -39.6, -49.9, -30.9, -25.5, -55.6, -41.4, -47.70000000000001, -39.10000000000001, -41.800000000000004, -25.4, -21.0, -37.20000000000001, -47.7, -40.400000000000006, -44.900000000000006, -43.400000000000006, -29.1, -35.900000000000006, -29.700000000000003, -26.6, -61.10000000000001, -39.300000000000004, -46.60000000000001, -35.1, -31.400000000000006, -50.80000000000001, -39.7, -38.300000000000004, -32.900000000000006, -36.7, -33.60000000000001, -40.400000000000006, -32.199999999999996, -37.300000000000004, -40.0, -47.5, -57.5, -50.60000000000001, -36.2], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1391154181922586, "mean_inference_ms": 1.2546235039316858, "mean_action_processing_ms": 0.05628857555007112, "mean_env_wait_ms": 2.1600199536330438, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 324000, "agent_timesteps_total": 324000, "timers": {"sample_time_ms": 7144.025, "sample_throughput": 559.908, "load_time_ms": 0.047, "load_throughput": 84265273.732, "learn_time_ms": 7587.699, "learn_throughput": 527.169, "update_time_ms": 1.442}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.20000000000000004, "cur_lr": 5.0000000000000016e-05, "total_loss": 142.04823941466628, "policy_loss": -0.019611400035360167, "vf_loss": 142.06689134003014, "vf_explained_var": [0.09929899871349335], "kl": 0.004799597180501976, "entropy": 0.4264590141593769, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 324000, "num_agent_steps_sampled": 324000, "num_steps_trained": 324000, "num_agent_steps_trained": 324000}, "done": false, "episodes_total": 21600, "training_iteration": 81, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-30-51", "timestamp": 1632519051, "time_this_iter_s": 14.366726160049438, "time_total_s": 1215.8830308914185, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1215.8830308914185, "timesteps_since_restore": 0, "iterations_since_restore": 81, "perf": {"cpu_util_percent": 34.78095238095238, "ram_util_percent": 16.100000000000005}}
{"episode_reward_max": -20.300000000000004, "episode_reward_min": -65.10000000000001, "episode_reward_mean": -40.295112781954884, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.599999999999994, -54.500000000000014, -42.400000000000006, -39.800000000000004, -44.5, -41.4, -38.3, -32.3, -25.8, -53.400000000000006, -36.7, -34.6, -44.70000000000001, -38.00000000000001, -49.3, -48.20000000000001, -32.5, -23.500000000000004, -36.6, -47.00000000000001, -44.900000000000006, -30.1, -26.9, -45.400000000000006, -58.50000000000001, -50.00000000000001, -50.00000000000001, -48.900000000000006, -47.80000000000001, -32.7, -41.4, -38.50000000000001, -32.7, -44.5, -31.6, -22.8, -23.300000000000004, -39.300000000000004, -36.7, -58.10000000000001, -38.5, -48.00000000000001, -46.400000000000006, -49.9, -41.2, -46.20000000000001, -52.4, -38.6, -35.1, -38.1, -39.80000000000001, -45.1, -35.7, -38.60000000000001, -35.6, -44.2, -42.800000000000004, -45.5, -41.5, -36.7, -39.1, -37.7, -24.8, -41.50000000000001, -26.500000000000007, -31.4, -56.400000000000006, -41.7, -38.800000000000004, -58.70000000000001, -47.7, -32.7, -31.400000000000002, -44.3, -40.60000000000001, -42.2, -33.00000000000001, -25.2, -38.1, -38.9, -43.5, -46.400000000000006, -46.599999999999994, -37.10000000000001, -34.7, -52.90000000000001, -45.900000000000006, -35.80000000000001, -32.5, -41.50000000000001, -40.699999999999996, -41.2, -42.60000000000001, -36.4, -40.80000000000001, -24.400000000000006, -42.300000000000004, -34.4, -55.500000000000014, -31.400000000000002, -20.300000000000004, -42.60000000000001, -40.6, -40.900000000000006, -35.3, -53.50000000000001, -33.300000000000004, -32.5, -32.3, -43.00000000000001, -42.900000000000006, -39.900000000000006, -41.400000000000006, -38.6, -47.50000000000001, -53.900000000000006, -45.6, -28.9, -44.6, -24.799999999999997, -40.00000000000001, -31.400000000000006, -32.7, -37.4, -55.6, -35.800000000000004, -48.500000000000014, -48.3, -33.900000000000006, -47.6, -33.300000000000004, -39.4, -42.10000000000001, -31.299999999999997, -36.4, -44.400000000000006, -26.2, -43.6, -39.6, -37.9, -36.9, -65.10000000000001, -30.300000000000004, -44.7, -44.10000000000001, -30.0, -42.0, -37.900000000000006, -45.900000000000006, -23.300000000000004, -35.1, -35.7, -63.400000000000006, -34.7, -43.3, -48.80000000000001, -44.2, -45.60000000000001, -57.099999999999994, -31.900000000000002, -31.3, -44.7, -51.0, -37.400000000000006, -41.4, -36.10000000000001, -35.5, -26.299999999999997, -34.4, -40.10000000000001, -40.9, -42.2, -34.0, -35.800000000000004, -28.400000000000002, -39.900000000000006, -25.300000000000004, -48.60000000000001, -40.900000000000006, -48.2, -42.8, -28.1, -35.6, -53.7, -52.20000000000001, -48.199999999999996, -30.3, -55.000000000000014, -37.6, -36.400000000000006, -36.70000000000001, -37.300000000000004, -49.5, -37.00000000000001, -39.2, -36.10000000000001, -38.4, -29.299999999999997, -42.900000000000006, -29.099999999999998, -53.70000000000001, -44.0, -41.2, -30.8, -51.50000000000001, -44.699999999999996, -37.10000000000001, -45.900000000000006, -48.300000000000004, -43.10000000000001, -55.30000000000001, -52.00000000000001, -35.6, -34.199999999999996, -36.5, -35.9, -38.5, -44.30000000000001, -31.1, -36.6, -63.40000000000001, -37.1, -34.400000000000006, -40.0, -51.10000000000001, -29.8, -36.300000000000004, -31.500000000000004, -45.900000000000006, -33.1, -39.70000000000001, -34.2, -60.599999999999994, -40.5, -53.300000000000004, -39.7, -41.1, -43.20000000000001, -41.3, -62.10000000000001, -42.300000000000004, -58.80000000000002, -45.10000000000001, -39.0, -37.800000000000004, -34.1, -54.900000000000006, -40.1, -32.699999999999996, -32.6, -41.500000000000014, -47.900000000000006, -33.5, -36.5, -36.3, -41.400000000000006, -28.6, -43.6, -37.300000000000004, -41.900000000000006, -40.4, -31.4, -44.699999999999996, -33.9, -32.300000000000004, -40.300000000000004], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13906623563233184, "mean_inference_ms": 1.254181941950705, "mean_action_processing_ms": 0.05626899511454848, "mean_env_wait_ms": 2.158587139160644, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 328000, "agent_timesteps_total": 328000, "timers": {"sample_time_ms": 7164.34, "sample_throughput": 558.321, "load_time_ms": 0.047, "load_throughput": 84819089.99, "learn_time_ms": 7598.384, "learn_throughput": 526.428, "update_time_ms": 1.404}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.10000000000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 144.64102173671927, "policy_loss": -0.016894450698358317, "vf_loss": 144.65734767298545, "vf_explained_var": [0.07062776386737823], "kl": 0.005684178791945478, "entropy": 0.4232362755524215, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 328000, "num_agent_steps_sampled": 328000, "num_steps_trained": 328000, "num_agent_steps_trained": 328000}, "done": false, "episodes_total": 21866, "training_iteration": 82, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-31-05", "timestamp": 1632519065, "time_this_iter_s": 14.334763288497925, "time_total_s": 1230.2177941799164, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1230.2177941799164, "timesteps_since_restore": 0, "iterations_since_restore": 82, "perf": {"cpu_util_percent": 35.269999999999996, "ram_util_percent": 16.100000000000005}}
{"episode_reward_max": -20.1, "episode_reward_min": -64.10000000000002, "episode_reward_mean": -40.951503759398506, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-51.6, -64.10000000000002, -40.400000000000006, -35.900000000000006, -40.6, -26.4, -34.400000000000006, -42.300000000000004, -51.50000000000001, -39.6, -45.7, -53.5, -44.300000000000004, -46.1, -40.9, -35.3, -38.300000000000004, -36.699999999999996, -46.0, -40.800000000000004, -44.8, -48.7, -46.400000000000006, -41.199999999999996, -39.6, -49.10000000000001, -48.699999999999996, -27.0, -39.4, -35.0, -45.2, -29.900000000000002, -37.50000000000001, -41.6, -49.1, -39.300000000000004, -52.500000000000014, -41.900000000000006, -38.800000000000004, -48.30000000000001, -35.9, -31.1, -30.4, -28.600000000000005, -26.7, -56.80000000000001, -40.20000000000001, -40.9, -36.5, -40.1, -33.50000000000001, -45.199999999999996, -57.00000000000001, -36.6, -33.5, -47.40000000000001, -40.90000000000001, -56.900000000000006, -36.2, -52.80000000000001, -54.400000000000006, -44.70000000000002, -36.400000000000006, -34.900000000000006, -36.900000000000006, -41.10000000000001, -32.50000000000001, -32.7, -30.3, -34.10000000000001, -43.800000000000004, -29.0, -43.10000000000001, -43.1, -43.70000000000001, -33.8, -38.1, -37.800000000000004, -33.300000000000004, -45.4, -34.7, -35.30000000000001, -34.6, -37.4, -57.2, -42.80000000000001, -36.2, -35.400000000000006, -42.70000000000001, -53.00000000000001, -54.4, -36.400000000000006, -39.199999999999996, -45.9, -27.9, -37.800000000000004, -33.60000000000001, -59.800000000000004, -26.800000000000004, -51.400000000000006, -33.9, -42.00000000000001, -28.1, -36.9, -58.9, -41.6, -50.7, -39.7, -44.300000000000004, -42.400000000000006, -39.400000000000006, -45.300000000000004, -39.900000000000006, -33.800000000000004, -59.7, -42.900000000000006, -45.20000000000001, -54.50000000000001, -47.400000000000006, -39.699999999999996, -40.3, -38.400000000000006, -50.199999999999996, -37.199999999999996, -44.10000000000001, -45.20000000000001, -44.10000000000001, -43.30000000000001, -35.8, -46.6, -48.500000000000014, -29.800000000000004, -50.20000000000001, -36.7, -39.9, -22.3, -49.900000000000006, -35.2, -38.5, -39.5, -40.400000000000006, -24.9, -23.5, -52.6, -44.400000000000006, -37.00000000000001, -33.5, -57.1, -42.9, -45.7, -43.60000000000001, -37.0, -45.60000000000001, -56.2, -53.1, -29.900000000000002, -28.9, -40.900000000000006, -42.400000000000006, -49.7, -28.400000000000006, -46.900000000000006, -34.1, -45.800000000000004, -40.2, -29.1, -42.900000000000006, -32.400000000000006, -54.7, -40.7, -40.900000000000006, -30.800000000000004, -46.30000000000001, -45.800000000000004, -31.9, -46.70000000000001, -49.50000000000001, -31.900000000000002, -41.400000000000006, -31.800000000000004, -44.1, -46.10000000000001, -59.800000000000004, -48.7, -35.699999999999996, -36.7, -20.1, -29.200000000000003, -39.199999999999996, -58.3, -37.0, -44.5, -47.60000000000001, -48.50000000000001, -49.1, -49.2, -37.800000000000004, -44.900000000000006, -31.400000000000006, -41.400000000000006, -23.9, -32.6, -41.2, -43.7, -34.9, -56.199999999999996, -39.50000000000001, -34.4, -43.60000000000001, -30.600000000000005, -42.00000000000001, -32.300000000000004, -36.800000000000004, -42.70000000000001, -39.70000000000001, -57.8, -43.2, -37.0, -31.1, -46.8, -46.400000000000006, -27.7, -36.2, -29.400000000000002, -37.10000000000001, -34.50000000000001, -39.9, -43.6, -35.6, -54.900000000000006, -35.9, -48.7, -39.80000000000001, -51.00000000000001, -37.2, -48.60000000000001, -33.50000000000001, -31.900000000000006, -41.5, -36.4, -38.0, -41.400000000000006, -25.7, -34.2, -28.200000000000003, -48.099999999999994, -42.10000000000001, -47.00000000000001, -51.900000000000006, -30.5, -39.4, -37.800000000000004, -40.9, -37.300000000000004, -52.80000000000001, -49.500000000000014, -43.900000000000006, -46.30000000000001, -31.2, -37.6, -38.900000000000006, -44.1, -52.600000000000016, -36.4, -41.9, -45.6], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13900154898719194, "mean_inference_ms": 1.2534936910169636, "mean_action_processing_ms": 0.05623987081953539, "mean_env_wait_ms": 2.1569908138137293, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 332000, "agent_timesteps_total": 332000, "timers": {"sample_time_ms": 7176.129, "sample_throughput": 557.404, "load_time_ms": 0.047, "load_throughput": 84904939.271, "learn_time_ms": 7577.867, "learn_throughput": 527.853, "update_time_ms": 1.436}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.10000000000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 148.61672023650138, "policy_loss": -0.021821522072798784, "vf_loss": 148.6379197315503, "vf_explained_var": [0.07645979523658752], "kl": 0.006222387247026406, "entropy": 0.428416232171879, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 332000, "num_agent_steps_sampled": 332000, "num_steps_trained": 332000, "num_agent_steps_trained": 332000}, "done": false, "episodes_total": 22132, "training_iteration": 83, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-31-20", "timestamp": 1632519080, "time_this_iter_s": 14.249286413192749, "time_total_s": 1244.4670805931091, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1244.4670805931091, "timesteps_since_restore": 0, "iterations_since_restore": 83, "perf": {"cpu_util_percent": 34.07000000000001, "ram_util_percent": 16.100000000000005}}
{"episode_reward_max": -19.9, "episode_reward_min": -66.10000000000001, "episode_reward_mean": -40.05410447761194, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 268, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-41.9, -38.4, -43.7, -45.1, -26.2, -42.800000000000004, -32.9, -43.0, -30.900000000000006, -40.800000000000004, -45.39999999999999, -41.4, -41.9, -39.400000000000006, -48.10000000000001, -51.9, -33.1, -45.20000000000001, -52.50000000000001, -39.4, -44.5, -45.3, -49.6, -43.00000000000001, -53.60000000000001, -30.6, -39.0, -31.3, -36.99999999999999, -30.000000000000004, -43.5, -61.500000000000014, -41.2, -42.2, -51.10000000000001, -39.2, -39.300000000000004, -37.9, -32.5, -37.7, -44.400000000000006, -38.300000000000004, -51.80000000000001, -42.8, -52.80000000000001, -39.3, -33.400000000000006, -50.30000000000001, -42.30000000000001, -56.60000000000001, -43.2, -32.7, -31.6, -34.7, -40.0, -39.6, -34.099999999999994, -43.2, -42.2, -45.300000000000004, -47.90000000000001, -32.199999999999996, -37.400000000000006, -36.6, -50.300000000000004, -44.400000000000006, -39.6, -33.6, -33.10000000000001, -36.199999999999996, -20.2, -42.7, -42.900000000000006, -34.199999999999996, -21.599999999999998, -53.400000000000006, -49.80000000000001, -35.900000000000006, -19.9, -45.800000000000004, -42.0, -24.2, -23.900000000000002, -35.400000000000006, -38.0, -44.50000000000001, -26.1, -39.4, -36.7, -20.900000000000002, -48.70000000000001, -55.000000000000014, -26.700000000000003, -39.400000000000006, -44.6, -30.400000000000002, -29.3, -53.40000000000001, -43.7, -42.80000000000001, -33.10000000000001, -36.8, -32.4, -52.400000000000006, -27.0, -41.10000000000001, -37.2, -37.50000000000001, -41.400000000000006, -37.2, -37.60000000000001, -52.900000000000006, -41.5, -46.900000000000006, -38.5, -36.800000000000004, -39.00000000000001, -29.500000000000004, -38.0, -29.900000000000006, -41.50000000000001, -38.2, -36.0, -42.900000000000006, -53.300000000000004, -29.3, -34.699999999999996, -43.60000000000001, -42.5, -33.50000000000001, -46.50000000000001, -44.10000000000001, -49.20000000000002, -66.10000000000001, -38.900000000000006, -39.6, -38.800000000000004, -51.7, -35.00000000000001, -31.4, -33.5, -34.0, -36.199999999999996, -42.1, -29.600000000000005, -36.400000000000006, -47.70000000000001, -27.500000000000004, -31.6, -36.10000000000001, -31.700000000000006, -45.6, -35.2, -42.300000000000004, -39.4, -51.5, -33.39999999999999, -26.6, -44.8, -46.1, -46.9, -39.0, -36.50000000000001, -41.9, -27.0, -46.000000000000014, -48.199999999999996, -31.0, -37.900000000000006, -49.3, -41.2, -51.500000000000014, -52.900000000000006, -52.7, -50.1, -32.2, -29.499999999999996, -24.700000000000003, -38.0, -36.5, -32.6, -39.8, -42.300000000000004, -44.50000000000001, -49.900000000000006, -37.9, -33.1, -44.30000000000001, -38.1, -26.8, -42.9, -31.8, -32.0, -47.6, -35.6, -50.2, -46.6, -38.9, -34.00000000000001, -39.00000000000001, -28.6, -43.60000000000001, -41.800000000000004, -40.60000000000001, -32.900000000000006, -30.700000000000003, -35.7, -31.700000000000003, -33.800000000000004, -47.2, -56.80000000000001, -40.300000000000004, -37.00000000000001, -35.199999999999996, -47.10000000000001, -57.60000000000002, -39.599999999999994, -32.800000000000004, -35.300000000000004, -44.50000000000001, -29.800000000000008, -61.80000000000001, -32.300000000000004, -40.400000000000006, -39.400000000000006, -39.70000000000001, -37.0, -26.2, -51.300000000000004, -37.6, -42.70000000000001, -49.7, -43.800000000000004, -53.20000000000001, -45.00000000000001, -50.5, -56.900000000000006, -52.60000000000001, -52.300000000000004, -47.7, -39.900000000000006, -32.199999999999996, -37.2, -23.6, -32.9, -41.800000000000004, -36.1, -51.00000000000001, -36.8, -37.3, -43.10000000000001, -33.2, -56.400000000000006, -60.1, -50.099999999999994, -29.400000000000002, -37.20000000000001, -36.1, -46.400000000000006, -23.300000000000004, -34.300000000000004, -49.800000000000004, -47.2, -28.8, -40.3, -27.099999999999998, -43.900000000000006, -45.2], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13894496747789942, "mean_inference_ms": 1.252913655126726, "mean_action_processing_ms": 0.056219475891515464, "mean_env_wait_ms": 2.155305103170283, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 336000, "agent_timesteps_total": 336000, "timers": {"sample_time_ms": 7162.21, "sample_throughput": 558.487, "load_time_ms": 0.047, "load_throughput": 84947929.114, "learn_time_ms": 7574.856, "learn_throughput": 528.063, "update_time_ms": 1.473}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.10000000000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 144.05919438023722, "policy_loss": -0.01988838941399609, "vf_loss": 144.07848756031325, "vf_explained_var": [0.07656324654817581], "kl": 0.005952959101658244, "entropy": 0.42554748689615596, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 336000, "num_agent_steps_sampled": 336000, "num_steps_trained": 336000, "num_agent_steps_trained": 336000}, "done": false, "episodes_total": 22400, "training_iteration": 84, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-31-34", "timestamp": 1632519094, "time_this_iter_s": 14.284226655960083, "time_total_s": 1258.7513072490692, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1258.7513072490692, "timesteps_since_restore": 0, "iterations_since_restore": 84, "perf": {"cpu_util_percent": 34.63809523809524, "ram_util_percent": 16.100000000000005}}
{"episode_reward_max": -19.6, "episode_reward_min": -63.20000000000001, "episode_reward_mean": -39.809398496240604, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-43.70000000000001, -31.500000000000004, -42.7, -40.6, -38.99999999999999, -30.0, -32.7, -43.7, -38.0, -27.7, -52.6, -41.50000000000001, -34.6, -31.8, -35.99999999999999, -41.00000000000001, -35.6, -41.6, -27.099999999999998, -30.9, -41.400000000000006, -43.0, -28.1, -35.8, -48.400000000000006, -45.00000000000001, -32.800000000000004, -34.1, -32.0, -36.4, -33.50000000000001, -35.0, -37.8, -39.500000000000014, -30.0, -32.300000000000004, -42.60000000000001, -36.9, -55.70000000000001, -30.800000000000004, -43.40000000000001, -38.4, -34.300000000000004, -40.1, -32.800000000000004, -39.1, -35.5, -49.0, -53.6, -42.400000000000006, -43.5, -50.70000000000001, -31.999999999999996, -38.9, -37.50000000000001, -41.099999999999994, -38.4, -42.5, -31.400000000000006, -49.00000000000001, -55.70000000000001, -54.900000000000006, -42.6, -44.300000000000004, -51.50000000000001, -40.300000000000004, -35.1, -47.400000000000006, -36.0, -60.400000000000006, -22.900000000000002, -40.800000000000004, -35.2, -43.00000000000001, -42.400000000000006, -38.50000000000001, -42.0, -30.200000000000003, -42.400000000000006, -38.60000000000001, -63.20000000000001, -47.7, -33.900000000000006, -36.6, -46.30000000000001, -37.0, -47.10000000000001, -44.0, -37.20000000000001, -46.300000000000004, -39.3, -42.800000000000004, -58.800000000000004, -43.900000000000006, -33.0, -62.00000000000001, -42.6, -44.1, -32.50000000000001, -42.400000000000006, -30.6, -50.400000000000006, -49.2, -54.70000000000001, -33.2, -26.5, -37.00000000000001, -38.8, -51.500000000000014, -44.1, -27.200000000000003, -37.5, -45.80000000000001, -34.800000000000004, -22.299999999999997, -41.5, -52.70000000000001, -35.00000000000001, -47.0, -31.900000000000002, -33.4, -32.6, -46.00000000000001, -35.900000000000006, -32.00000000000001, -33.800000000000004, -31.699999999999996, -37.199999999999996, -40.6, -34.800000000000004, -34.1, -49.9, -39.4, -42.50000000000001, -42.2, -33.599999999999994, -53.099999999999994, -31.200000000000003, -61.199999999999996, -42.5, -53.00000000000001, -40.800000000000004, -40.3, -43.20000000000001, -45.4, -31.900000000000002, -28.8, -59.300000000000004, -31.7, -35.7, -36.199999999999996, -36.7, -38.699999999999996, -48.0, -41.4, -35.900000000000006, -38.1, -22.0, -34.6, -43.599999999999994, -38.7, -49.20000000000001, -53.900000000000006, -36.1, -39.1, -46.10000000000001, -27.700000000000003, -39.1, -29.1, -37.2, -38.900000000000006, -25.900000000000006, -39.599999999999994, -39.699999999999996, -19.6, -39.6, -33.50000000000001, -52.1, -50.800000000000004, -36.300000000000004, -34.6, -48.2, -30.4, -48.00000000000001, -26.3, -33.9, -46.400000000000006, -28.200000000000003, -51.7, -33.300000000000004, -43.8, -40.7, -47.80000000000001, -36.800000000000004, -40.5, -30.9, -42.7, -31.9, -36.2, -50.50000000000001, -48.300000000000004, -31.3, -47.70000000000001, -34.20000000000001, -32.300000000000004, -45.50000000000001, -28.2, -42.099999999999994, -32.2, -49.80000000000001, -60.500000000000014, -46.4, -35.8, -23.700000000000003, -37.3, -43.4, -37.4, -42.0, -24.5, -44.9, -56.10000000000001, -48.1, -36.0, -37.2, -61.5, -33.20000000000001, -40.1, -33.300000000000004, -48.800000000000004, -49.80000000000001, -33.7, -32.7, -37.8, -36.400000000000006, -39.50000000000001, -51.4, -36.400000000000006, -42.300000000000004, -36.7, -41.7, -28.1, -44.70000000000001, -55.0, -41.5, -42.6, -32.1, -29.499999999999996, -42.300000000000004, -36.5, -49.79999999999999, -48.900000000000006, -24.1, -30.6, -54.30000000000001, -32.0, -48.900000000000006, -42.2, -44.80000000000001, -29.300000000000004, -34.800000000000004, -24.9, -42.50000000000001, -45.8, -34.0, -43.1, -35.2], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13883626626308254, "mean_inference_ms": 1.2519386179150511, "mean_action_processing_ms": 0.05617546808440476, "mean_env_wait_ms": 2.153387165826344, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 340000, "agent_timesteps_total": 340000, "timers": {"sample_time_ms": 7164.611, "sample_throughput": 558.3, "load_time_ms": 0.047, "load_throughput": 84265273.732, "learn_time_ms": 7461.985, "learn_throughput": 536.05, "update_time_ms": 1.431}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.10000000000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 141.78071440830027, "policy_loss": -0.023132196801304017, "vf_loss": 141.8031013570806, "vf_explained_var": [0.07531681656837463], "kl": 0.007458738477143924, "entropy": 0.44797643384625835, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 340000, "num_agent_steps_sampled": 340000, "num_steps_trained": 340000, "num_agent_steps_trained": 340000}, "done": false, "episodes_total": 22666, "training_iteration": 85, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-31-49", "timestamp": 1632519109, "time_this_iter_s": 14.769346475601196, "time_total_s": 1273.5206537246704, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1273.5206537246704, "timesteps_since_restore": 0, "iterations_since_restore": 85, "perf": {"cpu_util_percent": 35.333333333333336, "ram_util_percent": 16.100000000000005}}
{"episode_reward_max": -17.299999999999997, "episode_reward_min": -88.59999999999997, "episode_reward_mean": -40.26992481203008, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-35.5, -53.6, -35.2, -34.2, -58.300000000000004, -42.39999999999999, -28.699999999999996, -52.000000000000014, -41.400000000000006, -48.0, -35.900000000000006, -51.2, -34.5, -36.60000000000001, -25.900000000000006, -33.5, -32.1, -42.60000000000001, -33.2, -45.599999999999994, -55.70000000000001, -44.800000000000004, -35.6, -41.800000000000004, -53.6, -39.400000000000006, -43.6, -41.6, -50.80000000000001, -29.6, -30.6, -45.400000000000006, -44.7, -36.900000000000006, -22.2, -38.7, -33.4, -39.8, -41.9, -41.0, -40.1, -35.7, -41.6, -46.7, -42.9, -44.2, -34.9, -34.400000000000006, -30.6, -50.6, -39.7, -50.20000000000002, -40.00000000000001, -23.8, -40.60000000000001, -30.8, -41.50000000000001, -35.2, -34.0, -38.800000000000004, -36.2, -45.60000000000001, -33.9, -46.00000000000001, -27.300000000000004, -55.6, -56.60000000000001, -46.10000000000001, -31.600000000000005, -35.1, -40.300000000000004, -44.900000000000006, -35.6, -34.49999999999999, -39.9, -48.500000000000014, -54.800000000000004, -29.800000000000004, -52.2, -48.500000000000014, -45.49999999999999, -37.900000000000006, -47.70000000000001, -38.6, -45.8, -36.7, -30.800000000000004, -39.1, -50.599999999999994, -43.1, -34.50000000000001, -47.7, -35.6, -46.00000000000001, -31.200000000000003, -34.6, -41.20000000000001, -42.9, -37.300000000000004, -35.0, -36.7, -42.3, -24.8, -33.7, -43.50000000000001, -33.800000000000004, -29.2, -40.50000000000001, -45.400000000000006, -41.7, -39.5, -39.400000000000006, -41.99999999999999, -26.2, -49.50000000000001, -39.5, -36.7, -28.200000000000003, -27.0, -40.4, -36.1, -39.300000000000004, -34.7, -56.2, -48.7, -38.4, -48.60000000000001, -32.1, -27.200000000000003, -41.60000000000001, -53.00000000000001, -41.400000000000006, -29.000000000000004, -44.50000000000001, -55.60000000000001, -45.30000000000001, -25.4, -48.3, -42.6, -36.20000000000001, -28.400000000000002, -33.800000000000004, -41.800000000000004, -38.2, -48.6, -34.199999999999996, -39.1, -48.9, -28.400000000000006, -42.7, -45.1, -31.200000000000003, -17.299999999999997, -39.8, -35.900000000000006, -46.400000000000006, -37.50000000000001, -43.400000000000006, -34.6, -46.00000000000001, -31.000000000000004, -36.8, -27.900000000000002, -34.7, -42.50000000000001, -27.400000000000002, -46.60000000000001, -42.900000000000006, -38.6, -28.200000000000003, -23.3, -52.0, -46.8, -41.400000000000006, -31.9, -40.1, -41.400000000000006, -41.900000000000006, -30.9, -47.1, -44.2, -38.7, -45.2, -37.3, -32.50000000000001, -46.8, -30.200000000000003, -42.1, -48.2, -47.000000000000014, -40.400000000000006, -36.2, -48.6, -33.2, -43.400000000000006, -30.800000000000004, -53.70000000000001, -29.8, -42.400000000000006, -37.7, -43.29999999999999, -47.0, -53.9, -46.7, -38.9, -42.8, -48.5, -35.1, -51.99999999999999, -30.2, -49.800000000000004, -46.900000000000006, -26.400000000000002, -39.7, -40.0, -48.2, -30.000000000000004, -49.900000000000006, -28.1, -41.6, -52.400000000000006, -49.400000000000006, -38.60000000000001, -38.8, -45.5, -28.799999999999997, -38.0, -43.7, -40.400000000000006, -43.7, -55.10000000000001, -32.6, -32.900000000000006, -50.2, -39.5, -32.900000000000006, -28.700000000000003, -88.59999999999997, -47.300000000000004, -33.2, -63.20000000000001, -52.70000000000002, -34.6, -28.3, -31.299999999999997, -46.50000000000001, -33.5, -55.70000000000001, -39.7, -47.60000000000001, -39.1, -45.5, -40.300000000000004, -41.5, -23.299999999999997, -37.800000000000004, -41.099999999999994, -31.3, -38.10000000000001, -41.400000000000006, -41.50000000000001, -53.600000000000016, -61.3, -40.50000000000001, -49.0, -34.2], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1394197791552303, "mean_inference_ms": 1.2572855042335325, "mean_action_processing_ms": 0.05639431430170971, "mean_env_wait_ms": 2.157103546070454, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 344000, "agent_timesteps_total": 344000, "timers": {"sample_time_ms": 7131.437, "sample_throughput": 560.897, "load_time_ms": 0.048, "load_throughput": 82646384.236, "learn_time_ms": 7592.867, "learn_throughput": 526.81, "update_time_ms": 1.524}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.10000000000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 146.52090101344612, "policy_loss": -0.020592910150987326, "vf_loss": 146.54081774475753, "vf_explained_var": [0.06590542197227478], "kl": 0.006762994583962799, "entropy": 0.45685001695027916, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 344000, "num_agent_steps_sampled": 344000, "num_steps_trained": 344000, "num_agent_steps_trained": 344000}, "done": false, "episodes_total": 22932, "training_iteration": 86, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-32-07", "timestamp": 1632519127, "time_this_iter_s": 18.04247236251831, "time_total_s": 1291.5631260871887, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1291.5631260871887, "timesteps_since_restore": 0, "iterations_since_restore": 86, "perf": {"cpu_util_percent": 35.223076923076924, "ram_util_percent": 16.1}}
{"episode_reward_max": -19.8, "episode_reward_min": -63.8, "episode_reward_mean": -40.06231343283582, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 268, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-35.800000000000004, -34.5, -35.9, -44.3, -49.9, -42.7, -41.60000000000001, -38.5, -45.8, -30.799999999999997, -29.700000000000003, -42.30000000000001, -32.1, -48.10000000000001, -24.000000000000004, -47.2, -50.400000000000006, -44.1, -35.599999999999994, -49.60000000000001, -27.200000000000003, -35.50000000000001, -48.5, -44.900000000000006, -30.9, -38.1, -39.80000000000001, -37.800000000000004, -30.900000000000002, -35.400000000000006, -29.5, -45.8, -33.800000000000004, -40.2, -48.10000000000001, -39.0, -50.10000000000001, -43.099999999999994, -37.0, -59.10000000000001, -40.400000000000006, -33.7, -32.0, -40.9, -38.2, -54.20000000000001, -30.4, -26.9, -40.400000000000006, -37.3, -33.800000000000004, -20.8, -51.600000000000016, -29.3, -38.400000000000006, -46.80000000000001, -34.50000000000001, -34.400000000000006, -34.10000000000001, -41.300000000000004, -50.50000000000001, -45.800000000000004, -32.400000000000006, -41.800000000000004, -53.6, -40.2, -46.7, -46.900000000000006, -31.9, -37.5, -47.0, -42.900000000000006, -40.6, -42.80000000000001, -41.7, -35.80000000000001, -45.1, -34.300000000000004, -38.5, -39.300000000000004, -44.99999999999999, -29.5, -41.50000000000001, -48.2, -30.900000000000002, -25.799999999999997, -36.9, -28.800000000000004, -46.10000000000001, -43.2, -34.7, -36.300000000000004, -47.500000000000014, -39.4, -42.9, -46.7, -35.300000000000004, -39.800000000000004, -51.00000000000001, -32.1, -40.3, -52.7, -44.70000000000001, -26.200000000000003, -42.300000000000004, -33.400000000000006, -34.800000000000004, -34.5, -49.599999999999994, -31.300000000000004, -57.900000000000006, -46.800000000000004, -26.500000000000004, -36.1, -43.7, -35.4, -36.5, -44.60000000000001, -38.7, -41.3, -32.0, -50.40000000000001, -46.60000000000001, -26.1, -31.6, -36.800000000000004, -30.900000000000002, -41.5, -46.20000000000002, -38.6, -30.900000000000006, -35.6, -42.5, -38.70000000000001, -46.2, -49.70000000000001, -49.50000000000001, -40.7, -34.7, -31.4, -49.70000000000001, -38.099999999999994, -42.2, -34.00000000000001, -49.7, -35.7, -41.5, -31.900000000000006, -42.300000000000004, -23.8, -63.8, -41.800000000000004, -43.79999999999999, -45.00000000000001, -36.400000000000006, -33.400000000000006, -19.8, -35.60000000000001, -40.4, -34.0, -59.80000000000001, -42.300000000000004, -43.6, -43.00000000000001, -37.9, -30.900000000000002, -48.20000000000001, -41.7, -32.5, -37.4, -47.0, -43.10000000000001, -39.800000000000004, -35.5, -22.5, -49.1, -55.10000000000001, -48.9, -36.0, -47.300000000000004, -32.5, -38.0, -40.699999999999996, -34.300000000000004, -27.0, -40.2, -51.10000000000001, -23.099999999999998, -26.0, -51.10000000000001, -38.9, -35.2, -35.1, -46.1, -44.2, -45.70000000000001, -36.400000000000006, -45.50000000000001, -55.400000000000006, -53.599999999999994, -34.900000000000006, -39.7, -47.8, -46.00000000000001, -53.1, -45.20000000000001, -41.0, -25.2, -42.8, -48.500000000000014, -30.0, -51.9, -36.1, -44.70000000000001, -54.5, -49.900000000000006, -37.800000000000004, -35.0, -60.49999999999999, -38.1, -49.00000000000001, -33.800000000000004, -43.7, -41.300000000000004, -42.60000000000001, -33.4, -41.300000000000004, -48.60000000000001, -49.30000000000001, -48.199999999999996, -49.9, -46.30000000000001, -34.1, -42.300000000000004, -51.90000000000001, -44.70000000000001, -50.50000000000001, -45.50000000000001, -33.7, -40.5, -26.400000000000002, -36.4, -34.199999999999996, -47.900000000000006, -21.9, -44.10000000000001, -37.9, -50.20000000000001, -29.000000000000004, -33.5, -38.8, -32.7, -37.1, -41.300000000000004, -40.6, -46.900000000000006, -45.800000000000004, -34.2, -34.4, -31.900000000000002, -40.4, -40.00000000000001, -36.1, -40.5, -47.7, -28.2, -45.000000000000014, -23.9], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1395071934892122, "mean_inference_ms": 1.258602447261373, "mean_action_processing_ms": 0.056443586100711284, "mean_env_wait_ms": 2.1574785166488684, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 348000, "agent_timesteps_total": 348000, "timers": {"sample_time_ms": 7219.466, "sample_throughput": 554.058, "load_time_ms": 0.048, "load_throughput": 83137839.445, "learn_time_ms": 7601.142, "learn_throughput": 526.237, "update_time_ms": 1.518}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.10000000000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 141.13934212961504, "policy_loss": -0.01691648430761791, "vf_loss": 141.15550230292862, "vf_explained_var": [0.06836158037185669], "kl": 0.007561118719348586, "entropy": 0.45700922672466565, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 348000, "num_agent_steps_sampled": 348000, "num_steps_trained": 348000, "num_agent_steps_trained": 348000}, "done": false, "episodes_total": 23200, "training_iteration": 87, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-32-22", "timestamp": 1632519142, "time_this_iter_s": 15.032700061798096, "time_total_s": 1306.5958261489868, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1306.5958261489868, "timesteps_since_restore": 0, "iterations_since_restore": 87, "perf": {"cpu_util_percent": 33.50000000000001, "ram_util_percent": 16.100000000000005}}
{"episode_reward_max": -20.600000000000005, "episode_reward_min": -68.0, "episode_reward_mean": -40.15601503759399, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-46.10000000000001, -45.70000000000001, -42.6, -24.0, -31.800000000000004, -46.00000000000001, -34.6, -28.700000000000003, -34.599999999999994, -41.5, -39.5, -32.50000000000001, -30.400000000000002, -30.6, -42.50000000000001, -52.60000000000001, -50.900000000000006, -31.200000000000003, -26.500000000000004, -36.5, -34.2, -43.00000000000001, -49.7, -31.6, -32.8, -50.5, -40.800000000000004, -36.00000000000001, -37.400000000000006, -43.9, -39.8, -52.2, -54.00000000000001, -50.10000000000001, -35.0, -35.400000000000006, -44.20000000000001, -36.2, -37.800000000000004, -44.7, -61.30000000000001, -32.00000000000001, -36.0, -37.400000000000006, -68.0, -42.500000000000014, -54.60000000000001, -38.8, -38.60000000000001, -46.900000000000006, -44.5, -42.8, -55.80000000000002, -45.80000000000001, -35.6, -43.800000000000004, -34.0, -52.300000000000004, -33.5, -24.9, -49.2, -51.20000000000001, -30.200000000000003, -29.900000000000002, -42.900000000000006, -30.200000000000003, -48.20000000000001, -40.80000000000001, -36.10000000000001, -45.7, -31.900000000000002, -46.7, -43.00000000000001, -31.8, -38.800000000000004, -44.60000000000001, -43.900000000000006, -28.5, -42.1, -33.10000000000001, -39.9, -37.800000000000004, -42.6, -35.7, -36.5, -35.7, -46.0, -44.8, -28.3, -44.199999999999996, -33.7, -34.900000000000006, -42.70000000000002, -35.400000000000006, -38.7, -55.30000000000001, -41.6, -39.0, -31.3, -57.10000000000001, -57.49999999999999, -36.300000000000004, -56.1, -39.9, -32.7, -41.900000000000006, -24.1, -39.199999999999996, -30.299999999999997, -39.5, -46.5, -43.800000000000004, -49.1, -43.4, -41.0, -42.50000000000001, -36.6, -38.10000000000001, -38.0, -29.2, -43.9, -38.40000000000001, -33.1, -32.800000000000004, -40.9, -34.9, -44.5, -47.900000000000006, -40.0, -33.1, -32.8, -53.3, -35.6, -42.50000000000001, -37.30000000000001, -42.8, -35.2, -20.600000000000005, -46.7, -30.900000000000006, -36.0, -45.10000000000001, -37.400000000000006, -33.8, -32.900000000000006, -44.10000000000001, -27.800000000000004, -61.90000000000001, -54.0, -22.6, -34.2, -39.0, -33.4, -25.1, -51.70000000000001, -27.6, -52.900000000000006, -47.400000000000006, -40.7, -38.2, -39.9, -38.0, -39.8, -24.9, -37.2, -40.0, -37.0, -28.900000000000006, -38.9, -61.80000000000001, -44.2, -32.1, -43.20000000000001, -38.400000000000006, -43.0, -35.6, -42.20000000000001, -31.799999999999997, -43.800000000000004, -41.7, -47.49999999999999, -47.00000000000001, -25.400000000000002, -44.5, -23.200000000000003, -31.200000000000003, -49.000000000000014, -36.800000000000004, -55.599999999999994, -41.5, -29.700000000000003, -27.9, -37.8, -46.800000000000004, -41.6, -42.00000000000001, -57.1, -54.800000000000004, -42.600000000000016, -42.70000000000001, -33.300000000000004, -47.50000000000001, -41.2, -35.8, -49.20000000000002, -42.8, -44.300000000000004, -38.2, -62.500000000000014, -42.300000000000004, -37.300000000000004, -44.30000000000001, -46.10000000000001, -33.699999999999996, -40.50000000000001, -45.800000000000004, -34.9, -34.8, -53.60000000000001, -33.5, -39.39999999999999, -47.100000000000016, -42.1, -48.2, -41.8, -49.30000000000001, -37.699999999999996, -42.20000000000001, -50.0, -48.300000000000004, -29.0, -27.099999999999998, -35.6, -38.300000000000004, -37.7, -34.2, -44.900000000000006, -39.3, -36.00000000000001, -43.00000000000001, -42.2, -38.7, -31.800000000000004, -43.80000000000001, -44.2, -51.80000000000001, -37.900000000000006, -37.9, -35.1, -38.1, -41.7, -42.3, -30.700000000000003, -49.60000000000001, -39.300000000000004, -48.2, -43.1, -30.5, -39.30000000000001, -32.900000000000006, -35.6, -37.80000000000001, -42.7, -45.199999999999996, -29.900000000000006, -35.400000000000006], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13938310862247236, "mean_inference_ms": 1.2574985483408092, "mean_action_processing_ms": 0.05639716570098606, "mean_env_wait_ms": 2.15555297712782, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 352000, "agent_timesteps_total": 352000, "timers": {"sample_time_ms": 7199.843, "sample_throughput": 555.568, "load_time_ms": 0.047, "load_throughput": 85948852.459, "learn_time_ms": 7562.918, "learn_throughput": 528.896, "update_time_ms": 1.487}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.10000000000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 140.54448700771536, "policy_loss": -0.021051723489497777, "vf_loss": 140.56479755524666, "vf_explained_var": [0.07624568045139313], "kl": 0.00740726695233235, "entropy": 0.42180796608489046, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 352000, "num_agent_steps_sampled": 352000, "num_steps_trained": 352000, "num_agent_steps_trained": 352000}, "done": false, "episodes_total": 23466, "training_iteration": 88, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-32-36", "timestamp": 1632519156, "time_this_iter_s": 13.915377616882324, "time_total_s": 1320.5112037658691, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1320.5112037658691, "timesteps_since_restore": 0, "iterations_since_restore": 88, "perf": {"cpu_util_percent": 35.25, "ram_util_percent": 16.100000000000005}}
{"episode_reward_max": -21.999999999999996, "episode_reward_min": -73.7, "episode_reward_mean": -40.383834586466165, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-41.900000000000006, -49.4, -36.0, -33.10000000000001, -37.9, -41.9, -44.20000000000001, -50.90000000000001, -34.8, -39.00000000000001, -41.800000000000004, -30.6, -51.1, -39.6, -34.7, -40.5, -34.00000000000001, -24.500000000000004, -43.400000000000006, -42.60000000000001, -24.6, -43.60000000000001, -49.7, -73.7, -52.10000000000001, -38.50000000000001, -21.999999999999996, -38.800000000000004, -39.900000000000006, -46.60000000000001, -59.400000000000006, -46.6, -49.20000000000001, -31.6, -36.0, -34.300000000000004, -43.6, -47.900000000000006, -25.000000000000004, -51.2, -37.0, -45.50000000000001, -38.2, -46.40000000000001, -27.9, -44.400000000000006, -47.4, -40.8, -49.000000000000014, -47.7, -55.60000000000001, -49.400000000000006, -37.199999999999996, -32.6, -36.8, -52.900000000000006, -35.2, -48.800000000000004, -34.50000000000001, -45.40000000000001, -47.900000000000006, -44.0, -43.6, -46.0, -50.60000000000001, -52.50000000000001, -35.9, -38.300000000000004, -41.7, -49.6, -33.00000000000001, -33.1, -44.5, -36.099999999999994, -47.89999999999999, -27.1, -37.800000000000004, -38.80000000000001, -45.2, -34.5, -36.900000000000006, -58.4, -53.00000000000001, -41.400000000000006, -37.00000000000001, -33.9, -50.5, -29.2, -48.300000000000004, -35.300000000000004, -49.800000000000004, -53.7, -31.700000000000003, -37.900000000000006, -40.7, -40.0, -34.5, -53.7, -43.800000000000004, -27.200000000000003, -42.20000000000001, -30.900000000000002, -32.699999999999996, -43.300000000000004, -43.400000000000006, -30.0, -25.4, -49.30000000000001, -43.3, -37.900000000000006, -36.5, -37.900000000000006, -34.900000000000006, -26.8, -41.900000000000006, -29.200000000000003, -39.300000000000004, -37.7, -44.7, -33.0, -32.8, -35.900000000000006, -47.30000000000001, -39.199999999999996, -46.400000000000006, -46.7, -39.2, -30.3, -39.2, -45.300000000000004, -46.80000000000001, -43.70000000000001, -47.10000000000001, -32.6, -37.7, -48.5, -40.7, -43.400000000000006, -42.00000000000001, -24.700000000000003, -41.10000000000001, -38.900000000000006, -34.800000000000004, -41.800000000000004, -37.5, -35.800000000000004, -37.0, -37.4, -30.200000000000003, -36.5, -37.2, -33.0, -33.6, -52.70000000000001, -38.800000000000004, -32.4, -31.3, -45.60000000000001, -52.6, -42.0, -39.900000000000006, -52.80000000000001, -35.1, -38.80000000000001, -40.6, -27.799999999999997, -47.7, -30.700000000000003, -25.4, -32.7, -41.1, -35.60000000000001, -50.900000000000006, -37.7, -42.900000000000006, -48.20000000000001, -33.7, -33.0, -32.6, -47.800000000000004, -52.199999999999996, -38.099999999999994, -47.900000000000006, -49.0, -52.400000000000006, -38.1, -42.400000000000006, -28.900000000000002, -41.199999999999996, -46.300000000000004, -43.300000000000004, -33.1, -43.6, -38.7, -39.60000000000001, -31.900000000000002, -45.9, -27.200000000000003, -48.9, -39.80000000000001, -40.8, -31.7, -32.800000000000004, -28.900000000000002, -42.300000000000004, -61.2, -30.200000000000003, -41.9, -44.800000000000004, -32.6, -56.40000000000001, -29.799999999999997, -38.800000000000004, -51.400000000000006, -50.7, -42.4, -27.900000000000002, -40.0, -39.5, -35.8, -34.0, -44.50000000000001, -32.2, -54.90000000000001, -53.400000000000006, -38.400000000000006, -50.400000000000006, -33.7, -35.900000000000006, -33.300000000000004, -32.6, -28.0, -51.00000000000001, -62.00000000000001, -48.599999999999994, -42.1, -41.60000000000001, -39.800000000000004, -40.800000000000004, -35.599999999999994, -46.50000000000001, -35.3, -38.0, -46.6, -41.1, -38.500000000000014, -37.5, -28.2, -43.900000000000006, -41.1, -40.9, -34.300000000000004, -31.700000000000003, -37.6, -45.900000000000006, -59.39999999999999, -43.0, -36.5, -36.9, -42.800000000000004, -31.3, -39.00000000000001, -43.800000000000004, -22.7, -33.7, -45.80000000000001], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13929537273908055, "mean_inference_ms": 1.2566661923922349, "mean_action_processing_ms": 0.056361072658859625, "mean_env_wait_ms": 2.1541202462989757, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 356000, "agent_timesteps_total": 356000, "timers": {"sample_time_ms": 7208.739, "sample_throughput": 554.882, "load_time_ms": 0.046, "load_throughput": 87472450.469, "learn_time_ms": 7604.126, "learn_throughput": 526.03, "update_time_ms": 1.576}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.10000000000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 141.46019021311113, "policy_loss": -0.02241336169392271, "vf_loss": 141.48190438055224, "vf_explained_var": [0.07649807631969452], "kl": 0.006991561306090635, "entropy": 0.4210605744392641, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 356000, "num_agent_steps_sampled": 356000, "num_steps_trained": 356000, "num_agent_steps_trained": 356000}, "done": false, "episodes_total": 23732, "training_iteration": 89, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-32-51", "timestamp": 1632519171, "time_this_iter_s": 14.699771881103516, "time_total_s": 1335.2109756469727, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1335.2109756469727, "timesteps_since_restore": 0, "iterations_since_restore": 89, "perf": {"cpu_util_percent": 35.38095238095239, "ram_util_percent": 16.100000000000005}}
{"episode_reward_max": -20.2, "episode_reward_min": -72.30000000000001, "episode_reward_mean": -39.77985074626866, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 268, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-37.2, -43.400000000000006, -40.6, -38.300000000000004, -59.900000000000006, -35.800000000000004, -38.7, -27.1, -43.4, -42.2, -31.7, -41.7, -30.999999999999996, -20.2, -45.6, -40.300000000000004, -35.1, -36.2, -72.30000000000001, -34.1, -49.90000000000001, -34.4, -34.6, -48.4, -44.00000000000001, -30.4, -35.7, -35.6, -45.5, -39.6, -42.80000000000001, -32.50000000000001, -33.3, -37.1, -40.8, -35.400000000000006, -43.6, -33.300000000000004, -45.60000000000001, -36.7, -34.0, -33.4, -34.2, -38.1, -35.0, -32.0, -41.20000000000001, -49.199999999999996, -39.900000000000006, -46.10000000000001, -35.7, -53.40000000000002, -34.900000000000006, -31.6, -39.400000000000006, -30.100000000000005, -58.2, -46.900000000000006, -39.00000000000001, -44.400000000000006, -40.1, -25.7, -38.300000000000004, -51.80000000000001, -39.6, -40.300000000000004, -37.9, -47.20000000000001, -67.19999999999999, -37.900000000000006, -51.70000000000001, -42.10000000000001, -35.900000000000006, -34.2, -46.50000000000001, -31.6, -36.800000000000004, -33.4, -40.2, -34.3, -50.00000000000001, -55.100000000000016, -20.7, -28.799999999999997, -46.10000000000001, -39.50000000000001, -37.400000000000006, -37.900000000000006, -37.00000000000001, -30.099999999999998, -50.5, -26.4, -47.4, -43.5, -48.900000000000006, -30.200000000000003, -33.7, -36.199999999999996, -62.800000000000004, -31.900000000000006, -55.4, -37.6, -43.9, -52.20000000000001, -37.10000000000001, -59.90000000000001, -25.900000000000006, -46.20000000000001, -42.00000000000001, -23.200000000000003, -48.900000000000006, -43.2, -44.400000000000006, -51.40000000000001, -41.3, -32.1, -45.9, -41.0, -44.20000000000001, -33.3, -40.30000000000001, -42.9, -45.7, -52.1, -37.8, -48.6, -56.1, -26.4, -34.900000000000006, -58.90000000000001, -40.300000000000004, -33.800000000000004, -33.800000000000004, -36.2, -27.700000000000003, -45.900000000000006, -45.50000000000001, -45.2, -33.800000000000004, -28.400000000000002, -24.500000000000004, -35.9, -37.7, -36.10000000000001, -33.5, -36.0, -48.5, -38.0, -38.4, -35.2, -35.5, -56.00000000000001, -28.5, -47.6, -39.6, -37.2, -40.0, -44.30000000000001, -46.400000000000006, -31.900000000000006, -40.5, -42.00000000000001, -35.10000000000001, -48.60000000000001, -28.199999999999996, -36.0, -30.9, -36.6, -45.800000000000004, -44.3, -32.4, -45.800000000000004, -41.0, -55.60000000000001, -30.000000000000007, -38.7, -34.2, -33.2, -46.5, -48.00000000000001, -39.99999999999999, -39.20000000000001, -45.10000000000001, -37.1, -51.50000000000001, -42.900000000000006, -37.4, -50.90000000000001, -29.2, -38.00000000000001, -39.8, -43.50000000000001, -44.3, -32.300000000000004, -39.8, -24.8, -22.799999999999997, -33.8, -41.900000000000006, -49.100000000000016, -35.2, -37.3, -46.80000000000001, -39.900000000000006, -40.5, -56.10000000000001, -37.7, -34.7, -38.300000000000004, -34.7, -46.699999999999996, -28.200000000000003, -39.6, -47.5, -37.1, -40.00000000000001, -40.4, -32.7, -41.4, -29.9, -48.70000000000001, -47.70000000000001, -43.5, -26.999999999999996, -38.000000000000014, -63.6, -34.5, -34.50000000000001, -37.2, -37.10000000000001, -37.2, -37.199999999999996, -37.8, -54.10000000000001, -50.2, -29.200000000000003, -42.0, -46.2, -51.10000000000001, -26.099999999999998, -37.699999999999996, -56.70000000000002, -43.2, -31.8, -20.7, -33.800000000000004, -31.700000000000003, -37.300000000000004, -21.8, -49.6, -33.00000000000001, -31.9, -31.200000000000003, -43.60000000000001, -35.900000000000006, -46.70000000000001, -39.8, -26.6, -44.9, -36.8, -27.100000000000005, -58.800000000000004, -28.600000000000005, -46.80000000000001, -40.099999999999994, -41.50000000000001, -42.6, -44.70000000000001], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1395612937046522, "mean_inference_ms": 1.25894046243162, "mean_action_processing_ms": 0.056457047597540014, "mean_env_wait_ms": 2.154616029243164, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 360000, "agent_timesteps_total": 360000, "timers": {"sample_time_ms": 7303.089, "sample_throughput": 547.713, "load_time_ms": 0.046, "load_throughput": 87335845.914, "learn_time_ms": 7583.861, "learn_throughput": 527.436, "update_time_ms": 1.571}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.10000000000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 140.97926261655746, "policy_loss": -0.021291550069106043, "vf_loss": 140.99993119598716, "vf_explained_var": [0.07772509753704071], "kl": 0.00623407133787092, "entropy": 0.40656803577176986, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 360000, "num_agent_steps_sampled": 360000, "num_steps_trained": 360000, "num_agent_steps_trained": 360000}, "done": false, "episodes_total": 24000, "training_iteration": 90, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-33-06", "timestamp": 1632519186, "time_this_iter_s": 15.28617525100708, "time_total_s": 1350.4971508979797, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1350.4971508979797, "timesteps_since_restore": 0, "iterations_since_restore": 90, "perf": {"cpu_util_percent": 34.127272727272725, "ram_util_percent": 16.10000000000001}}
{"episode_reward_max": -16.700000000000003, "episode_reward_min": -64.10000000000001, "episode_reward_mean": -40.569924812030074, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-35.300000000000004, -43.80000000000001, -44.800000000000004, -50.400000000000006, -36.3, -55.300000000000004, -49.900000000000006, -34.1, -45.2, -33.50000000000001, -46.2, -39.7, -64.10000000000001, -57.900000000000006, -44.300000000000004, -32.0, -47.0, -47.80000000000001, -39.9, -45.1, -47.600000000000016, -40.8, -42.50000000000001, -55.3, -49.800000000000004, -38.60000000000001, -43.70000000000001, -32.2, -39.0, -39.1, -52.1, -38.50000000000001, -58.0, -46.400000000000006, -38.7, -55.10000000000001, -47.699999999999996, -38.7, -26.0, -41.99999999999999, -42.00000000000001, -24.1, -47.5, -44.7, -42.50000000000001, -41.400000000000006, -40.00000000000001, -42.4, -57.400000000000006, -27.200000000000003, -37.300000000000004, -47.1, -38.900000000000006, -36.900000000000006, -36.3, -41.1, -54.400000000000006, -41.2, -34.3, -37.9, -35.1, -45.599999999999994, -34.3, -47.70000000000001, -34.0, -32.9, -38.6, -42.1, -33.0, -36.4, -42.800000000000004, -32.900000000000006, -48.900000000000006, -38.60000000000001, -34.800000000000004, -41.7, -30.1, -41.300000000000004, -32.0, -36.00000000000001, -50.60000000000001, -32.7, -38.400000000000006, -31.500000000000004, -39.400000000000006, -38.2, -51.90000000000001, -46.5, -35.7, -43.60000000000001, -40.9, -39.2, -33.8, -59.20000000000002, -40.7, -31.900000000000002, -51.40000000000001, -32.300000000000004, -37.800000000000004, -47.5, -33.9, -48.80000000000001, -30.500000000000004, -42.400000000000006, -55.90000000000002, -28.400000000000006, -28.800000000000004, -45.8, -44.2, -43.5, -16.700000000000003, -21.5, -50.8, -42.6, -41.7, -41.10000000000001, -54.900000000000006, -30.700000000000003, -47.5, -34.0, -34.800000000000004, -53.10000000000001, -31.300000000000004, -46.400000000000006, -56.699999999999996, -38.4, -31.700000000000006, -42.300000000000004, -41.80000000000001, -36.70000000000001, -40.800000000000004, -39.699999999999996, -42.5, -36.2, -32.8, -36.2, -43.2, -38.300000000000004, -30.6, -30.000000000000004, -53.4, -33.6, -42.300000000000004, -45.5, -31.100000000000005, -43.2, -34.1, -43.2, -37.89999999999999, -50.90000000000001, -26.5, -58.1, -44.60000000000001, -43.900000000000006, -34.800000000000004, -46.400000000000006, -36.3, -44.900000000000006, -42.0, -39.300000000000004, -34.9, -26.0, -50.400000000000006, -47.20000000000002, -38.4, -49.0, -25.200000000000003, -46.00000000000001, -34.1, -41.5, -36.699999999999996, -37.900000000000006, -22.600000000000005, -37.7, -42.70000000000001, -31.9, -35.5, -51.5, -40.3, -40.2, -49.7, -47.60000000000001, -29.200000000000003, -62.30000000000002, -29.500000000000004, -45.1, -40.6, -34.2, -36.900000000000006, -36.800000000000004, -50.10000000000001, -33.5, -34.099999999999994, -28.300000000000004, -41.800000000000004, -44.7, -56.00000000000001, -42.5, -41.900000000000006, -37.9, -35.50000000000001, -55.70000000000001, -42.900000000000006, -34.0, -44.20000000000001, -51.2, -44.0, -36.1, -35.3, -58.300000000000004, -48.199999999999996, -37.800000000000004, -37.8, -34.099999999999994, -36.099999999999994, -39.1, -44.2, -31.700000000000003, -37.6, -30.0, -41.3, -58.10000000000001, -26.5, -44.2, -39.7, -40.2, -41.2, -47.300000000000004, -40.0, -32.300000000000004, -17.900000000000002, -46.4, -47.800000000000004, -37.7, -37.099999999999994, -35.400000000000006, -45.9, -37.900000000000006, -53.00000000000001, -33.199999999999996, -42.50000000000001, -36.7, -23.7, -48.800000000000004, -26.900000000000006, -37.60000000000001, -30.900000000000002, -37.0, -37.0, -55.6, -55.100000000000016, -33.4, -35.30000000000001, -33.900000000000006, -40.60000000000001, -35.1, -42.2, -39.5, -38.699999999999996, -41.6, -54.00000000000001, -38.0, -40.900000000000006, -35.1, -28.7, -53.30000000000001], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13944663990775366, "mean_inference_ms": 1.2579223878974402, "mean_action_processing_ms": 0.0564130444926768, "mean_env_wait_ms": 2.1530705243253285, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 364000, "agent_timesteps_total": 364000, "timers": {"sample_time_ms": 7276.284, "sample_throughput": 549.731, "load_time_ms": 0.047, "load_throughput": 85120324.708, "learn_time_ms": 7595.552, "learn_throughput": 526.624, "update_time_ms": 1.562}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.10000000000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 147.2152082545783, "policy_loss": -0.01960918319071092, "vf_loss": 147.23417713616485, "vf_explained_var": [0.06933633238077164], "kl": 0.006405854035086172, "entropy": 0.43148886558189187, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 364000, "num_agent_steps_sampled": 364000, "num_steps_trained": 364000, "num_agent_steps_trained": 364000}, "done": false, "episodes_total": 24266, "training_iteration": 91, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-33-20", "timestamp": 1632519200, "time_this_iter_s": 14.215090990066528, "time_total_s": 1364.7122418880463, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1364.7122418880463, "timesteps_since_restore": 0, "iterations_since_restore": 91, "perf": {"cpu_util_percent": 35.53809523809524, "ram_util_percent": 16.100000000000005}}
{"episode_reward_max": -20.599999999999998, "episode_reward_min": -62.00000000000001, "episode_reward_mean": -40.2093984962406, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-38.6, -37.7, -35.199999999999996, -39.900000000000006, -30.8, -35.60000000000001, -32.7, -40.800000000000004, -33.2, -38.0, -37.2, -50.9, -31.1, -35.7, -36.9, -44.50000000000001, -45.20000000000001, -38.400000000000006, -31.6, -31.1, -36.50000000000001, -46.0, -56.10000000000001, -43.400000000000006, -40.400000000000006, -38.900000000000006, -49.60000000000001, -50.60000000000001, -35.300000000000004, -34.50000000000001, -42.2, -34.0, -44.3, -52.099999999999994, -32.300000000000004, -51.000000000000014, -50.4, -50.50000000000001, -40.599999999999994, -36.199999999999996, -36.50000000000001, -36.1, -42.900000000000006, -24.3, -43.60000000000001, -31.700000000000006, -27.1, -40.400000000000006, -31.800000000000004, -42.50000000000001, -39.800000000000004, -38.50000000000001, -42.800000000000004, -31.9, -47.7, -36.400000000000006, -35.0, -31.700000000000003, -35.199999999999996, -31.200000000000003, -37.1, -44.9, -43.3, -53.6, -36.7, -57.9, -31.0, -45.6, -46.5, -34.20000000000001, -46.5, -33.1, -41.7, -48.8, -46.00000000000001, -37.599999999999994, -36.5, -46.5, -40.599999999999994, -36.5, -33.699999999999996, -47.40000000000001, -46.900000000000006, -45.900000000000006, -28.4, -55.89999999999999, -46.2, -44.49999999999999, -43.8, -45.1, -48.500000000000014, -42.1, -36.1, -42.7, -54.7, -47.300000000000004, -37.0, -45.2, -25.300000000000004, -42.2, -26.9, -32.6, -34.400000000000006, -37.9, -51.40000000000001, -45.7, -31.6, -47.6, -42.60000000000001, -55.20000000000001, -46.2, -44.699999999999996, -24.7, -30.2, -38.7, -39.6, -41.70000000000001, -34.2, -40.10000000000001, -36.400000000000006, -44.7, -31.600000000000005, -20.599999999999998, -45.800000000000004, -44.6, -62.00000000000001, -24.900000000000002, -40.400000000000006, -33.6, -37.300000000000004, -35.40000000000001, -45.599999999999994, -44.000000000000014, -46.20000000000002, -38.00000000000001, -28.9, -47.90000000000001, -29.3, -50.70000000000001, -47.1, -47.199999999999996, -37.30000000000001, -47.20000000000001, -46.00000000000001, -49.50000000000001, -47.80000000000001, -44.0, -50.0, -41.7, -32.800000000000004, -37.0, -32.8, -44.1, -38.7, -43.300000000000004, -47.80000000000001, -51.400000000000006, -25.099999999999998, -30.800000000000004, -41.400000000000006, -41.0, -43.800000000000004, -38.7, -37.30000000000001, -38.900000000000006, -30.60000000000001, -42.8, -37.1, -37.400000000000006, -33.0, -42.800000000000004, -30.400000000000006, -43.80000000000001, -34.7, -54.4, -25.5, -36.1, -32.300000000000004, -25.800000000000004, -32.7, -38.7, -39.2, -44.900000000000006, -30.9, -31.800000000000004, -45.099999999999994, -51.50000000000001, -53.900000000000006, -42.2, -46.3, -34.50000000000001, -47.0, -37.400000000000006, -42.90000000000001, -36.0, -41.0, -41.60000000000001, -34.900000000000006, -52.900000000000006, -30.1, -34.7, -30.099999999999998, -33.5, -40.0, -38.5, -38.2, -32.9, -53.300000000000004, -44.8, -36.00000000000001, -40.0, -50.900000000000006, -27.600000000000005, -44.0, -47.80000000000001, -34.4, -35.4, -40.800000000000004, -54.300000000000004, -45.300000000000004, -36.6, -26.300000000000004, -31.200000000000003, -44.400000000000006, -41.4, -37.0, -54.7, -41.2, -42.00000000000001, -42.7, -39.300000000000004, -53.5, -44.2, -39.7, -32.300000000000004, -40.900000000000006, -44.1, -43.7, -58.30000000000001, -34.6, -35.900000000000006, -44.6, -43.300000000000004, -55.1, -30.1, -49.699999999999996, -32.1, -43.900000000000006, -46.900000000000006, -35.4, -41.30000000000001, -33.0, -45.0, -39.49999999999999, -31.1, -44.800000000000004, -31.8, -36.7, -35.0, -28.799999999999997, -44.70000000000001, -54.7, -39.2, -37.599999999999994, -43.9, -41.6], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.13942594010573592, "mean_inference_ms": 1.2576750865816468, "mean_action_processing_ms": 0.056403589541755006, "mean_env_wait_ms": 2.152245825175003, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 368000, "agent_timesteps_total": 368000, "timers": {"sample_time_ms": 7286.469, "sample_throughput": 548.963, "load_time_ms": 0.048, "load_throughput": 84054188.377, "learn_time_ms": 7613.403, "learn_throughput": 525.389, "update_time_ms": 1.613}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.10000000000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 138.29920185868457, "policy_loss": -0.019308429644993876, "vf_loss": 138.31793012721565, "vf_explained_var": [0.07435642182826996], "kl": 0.005800031945591466, "entropy": 0.41906543377266137, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 368000, "num_agent_steps_sampled": 368000, "num_steps_trained": 368000, "num_agent_steps_trained": 368000}, "done": false, "episodes_total": 24532, "training_iteration": 92, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-33-35", "timestamp": 1632519215, "time_this_iter_s": 14.6168692111969, "time_total_s": 1379.3291110992432, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1379.3291110992432, "timesteps_since_restore": 0, "iterations_since_restore": 92, "perf": {"cpu_util_percent": 33.605000000000004, "ram_util_percent": 16.100000000000005}}
{"episode_reward_max": -17.6, "episode_reward_min": -66.10000000000001, "episode_reward_mean": -39.747014925373136, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 268, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-35.7, -50.3, -25.900000000000002, -41.400000000000006, -46.30000000000001, -23.3, -44.6, -35.3, -43.5, -45.10000000000001, -37.6, -38.400000000000006, -42.300000000000004, -39.70000000000001, -31.5, -43.50000000000001, -41.9, -49.1, -32.400000000000006, -49.2, -33.8, -33.7, -29.6, -37.2, -49.4, -39.00000000000001, -45.5, -43.300000000000004, -32.00000000000001, -36.800000000000004, -34.8, -51.1, -34.9, -52.300000000000004, -33.699999999999996, -35.6, -40.70000000000001, -44.1, -32.800000000000004, -25.799999999999997, -34.3, -38.800000000000004, -53.2, -34.8, -38.70000000000001, -41.7, -38.70000000000001, -37.1, -20.0, -37.9, -38.1, -25.700000000000003, -43.3, -30.700000000000003, -30.2, -37.400000000000006, -31.299999999999997, -42.00000000000001, -54.2, -36.7, -39.400000000000006, -44.60000000000001, -40.900000000000006, -43.2, -31.4, -34.4, -43.20000000000001, -34.3, -39.1, -36.7, -35.2, -33.50000000000001, -30.000000000000004, -46.900000000000006, -37.300000000000004, -43.9, -54.89999999999999, -42.900000000000006, -32.9, -53.9, -41.800000000000004, -35.00000000000001, -46.2, -34.1, -52.599999999999994, -36.8, -45.8, -35.3, -32.4, -47.9, -42.900000000000006, -47.7, -62.5, -32.300000000000004, -41.00000000000001, -37.1, -30.900000000000002, -44.20000000000001, -51.400000000000006, -39.50000000000001, -40.7, -54.0, -42.6, -33.699999999999996, -43.6, -50.0, -34.900000000000006, -47.00000000000001, -43.9, -36.1, -42.300000000000004, -46.400000000000006, -37.900000000000006, -32.1, -44.50000000000001, -31.5, -42.5, -42.3, -48.699999999999996, -35.2, -40.699999999999996, -40.00000000000001, -53.8, -35.4, -50.49999999999999, -26.1, -32.2, -41.89999999999999, -27.8, -36.5, -44.7, -29.200000000000003, -38.3, -49.6, -39.0, -36.800000000000004, -32.5, -50.50000000000001, -30.000000000000004, -47.800000000000004, -42.300000000000004, -33.400000000000006, -37.6, -26.900000000000006, -39.3, -51.60000000000001, -34.2, -36.7, -38.300000000000004, -26.0, -35.9, -45.70000000000001, -35.800000000000004, -41.400000000000006, -34.7, -39.30000000000001, -46.9, -46.099999999999994, -63.5, -28.800000000000004, -40.900000000000006, -49.400000000000006, -43.10000000000001, -34.5, -35.800000000000004, -36.699999999999996, -19.700000000000003, -41.099999999999994, -55.2, -35.199999999999996, -29.2, -58.70000000000001, -17.6, -34.800000000000004, -44.400000000000006, -25.9, -34.9, -43.99999999999999, -52.900000000000006, -24.900000000000002, -35.7, -36.400000000000006, -44.0, -43.400000000000006, -44.6, -40.5, -32.0, -32.50000000000001, -35.10000000000001, -35.9, -48.400000000000006, -39.5, -41.3, -37.50000000000001, -30.1, -37.9, -50.800000000000004, -39.800000000000004, -37.0, -34.7, -47.60000000000001, -47.599999999999994, -27.900000000000002, -48.300000000000004, -35.900000000000006, -45.10000000000001, -28.6, -53.900000000000006, -41.8, -42.60000000000001, -45.20000000000001, -32.800000000000004, -40.60000000000001, -54.5, -47.70000000000001, -45.90000000000001, -39.00000000000001, -40.6, -43.300000000000004, -33.3, -39.1, -31.900000000000002, -38.2, -46.50000000000001, -26.900000000000002, -42.7, -49.7, -33.7, -36.9, -31.1, -47.400000000000006, -30.699999999999996, -32.400000000000006, -32.9, -46.400000000000006, -45.4, -34.099999999999994, -40.5, -50.70000000000001, -35.2, -32.800000000000004, -47.400000000000006, -50.900000000000006, -54.60000000000001, -48.10000000000001, -45.60000000000001, -30.7, -34.7, -61.800000000000004, -39.1, -40.7, -66.10000000000001, -27.000000000000004, -38.7, -38.60000000000001, -38.10000000000001, -36.800000000000004, -35.4, -25.200000000000003, -43.5, -34.70000000000001, -35.400000000000006, -52.4, -40.5, -38.900000000000006, -47.7, -35.800000000000004, -38.900000000000006], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1397651431156758, "mean_inference_ms": 1.2605662061349283, "mean_action_processing_ms": 0.05652237057428848, "mean_env_wait_ms": 2.1532066064456687, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 372000, "agent_timesteps_total": 372000, "timers": {"sample_time_ms": 7412.903, "sample_throughput": 539.6, "load_time_ms": 0.048, "load_throughput": 82687116.806, "learn_time_ms": 7848.701, "learn_throughput": 509.638, "update_time_ms": 1.604}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.10000000000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 134.40596127253707, "policy_loss": -0.017653442837137687, "vf_loss": 134.42300265732632, "vf_explained_var": [0.09064610302448273], "kl": 0.006128219840195111, "entropy": 0.42387639245679304, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 372000, "num_agent_steps_sampled": 372000, "num_steps_trained": 372000, "num_agent_steps_trained": 372000}, "done": false, "episodes_total": 24800, "training_iteration": 93, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-33-53", "timestamp": 1632519233, "time_this_iter_s": 17.86851453781128, "time_total_s": 1397.1976256370544, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1397.1976256370544, "timesteps_since_restore": 0, "iterations_since_restore": 93, "perf": {"cpu_util_percent": 35.62307692307692, "ram_util_percent": 16.1}}
{"episode_reward_max": -21.2, "episode_reward_min": -64.7, "episode_reward_mean": -40.203007518796994, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-45.300000000000004, -24.3, -38.1, -51.800000000000004, -32.6, -41.900000000000006, -41.900000000000006, -29.300000000000004, -30.700000000000003, -39.3, -46.30000000000001, -47.900000000000006, -47.5, -52.900000000000006, -45.90000000000001, -31.900000000000002, -47.5, -42.400000000000006, -33.0, -39.9, -27.9, -41.900000000000006, -41.400000000000006, -35.6, -40.7, -33.400000000000006, -28.4, -39.2, -32.50000000000001, -51.900000000000006, -40.0, -38.60000000000001, -40.10000000000001, -46.300000000000004, -41.7, -24.299999999999997, -44.300000000000004, -34.0, -43.7, -36.2, -37.300000000000004, -24.700000000000003, -39.20000000000001, -44.80000000000001, -47.900000000000006, -28.599999999999998, -25.7, -22.6, -30.300000000000004, -48.0, -62.000000000000014, -47.50000000000001, -41.50000000000001, -34.6, -39.300000000000004, -40.00000000000001, -29.099999999999998, -39.0, -29.3, -45.2, -41.300000000000004, -42.1, -38.900000000000006, -32.900000000000006, -32.900000000000006, -35.2, -52.4, -42.80000000000001, -47.900000000000006, -47.0, -51.1, -42.8, -34.2, -27.7, -44.6, -39.800000000000004, -56.00000000000001, -38.5, -39.0, -36.800000000000004, -38.400000000000006, -28.5, -37.1, -37.400000000000006, -42.60000000000001, -41.800000000000004, -35.60000000000001, -47.300000000000004, -46.00000000000001, -41.400000000000006, -46.900000000000006, -40.5, -32.0, -40.50000000000001, -39.5, -37.0, -37.599999999999994, -46.800000000000004, -39.9, -33.9, -35.6, -35.50000000000001, -57.1, -37.0, -57.1, -49.800000000000004, -34.7, -31.0, -21.2, -48.10000000000001, -46.1, -40.00000000000001, -31.700000000000003, -48.7, -33.2, -40.599999999999994, -45.9, -37.300000000000004, -39.19999999999999, -32.699999999999996, -29.400000000000002, -42.20000000000001, -38.7, -46.300000000000004, -48.400000000000006, -31.7, -39.3, -29.800000000000004, -39.7, -31.400000000000002, -43.6, -46.800000000000004, -42.9, -32.400000000000006, -45.4, -41.8, -34.900000000000006, -46.1, -32.5, -35.300000000000004, -62.000000000000014, -31.000000000000004, -36.5, -51.5, -47.7, -39.10000000000001, -51.800000000000004, -48.099999999999994, -33.7, -41.1, -36.2, -40.0, -60.60000000000001, -25.900000000000002, -41.0, -39.50000000000001, -51.7, -41.9, -29.7, -48.699999999999996, -34.800000000000004, -51.30000000000001, -35.3, -46.300000000000004, -40.60000000000001, -50.6, -41.50000000000001, -43.89999999999999, -40.0, -41.7, -44.10000000000001, -33.6, -40.7, -26.800000000000004, -33.4, -50.7, -45.0, -38.699999999999996, -29.700000000000003, -41.6, -36.7, -47.3, -39.10000000000001, -30.700000000000003, -29.300000000000004, -49.7, -45.7, -45.0, -27.6, -47.70000000000001, -24.900000000000002, -52.4, -27.900000000000002, -37.1, -53.7, -40.599999999999994, -32.50000000000001, -41.300000000000004, -40.0, -43.400000000000006, -48.10000000000001, -27.7, -39.50000000000001, -41.7, -34.0, -35.0, -47.5, -30.600000000000005, -42.900000000000006, -43.2, -44.7, -45.100000000000016, -38.7, -37.2, -53.80000000000002, -37.2, -55.0, -34.300000000000004, -50.900000000000006, -43.30000000000001, -40.400000000000006, -48.60000000000001, -43.60000000000001, -36.5, -36.300000000000004, -46.7, -39.00000000000001, -41.400000000000006, -34.00000000000001, -39.9, -48.9, -39.599999999999994, -37.00000000000001, -40.1, -29.0, -53.500000000000014, -37.400000000000006, -36.3, -45.699999999999996, -64.7, -40.6, -46.0, -23.400000000000002, -51.300000000000004, -40.900000000000006, -57.0, -37.900000000000006, -36.3, -42.7, -29.6, -56.400000000000006, -43.50000000000001, -52.90000000000001, -30.600000000000005, -26.8, -48.400000000000006, -33.50000000000001, -36.2, -37.60000000000001, -33.599999999999994, -56.7, -29.1, -27.900000000000002, -41.7, -36.2, -42.800000000000004], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14006544874440868, "mean_inference_ms": 1.2630425956850213, "mean_action_processing_ms": 0.05663124927982957, "mean_env_wait_ms": 2.154027973529955, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 376000, "agent_timesteps_total": 376000, "timers": {"sample_time_ms": 7519.055, "sample_throughput": 531.982, "load_time_ms": 0.048, "load_throughput": 82973372.898, "learn_time_ms": 7923.875, "learn_throughput": 504.803, "update_time_ms": 1.607}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.10000000000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 138.3076452439831, "policy_loss": -0.01914766144948781, "vf_loss": 138.32611443304248, "vf_explained_var": [0.07676224410533905], "kl": 0.00678444885841579, "entropy": 0.3919223128467478, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 376000, "num_agent_steps_sampled": 376000, "num_steps_trained": 376000, "num_agent_steps_trained": 376000}, "done": false, "episodes_total": 25066, "training_iteration": 94, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-34-09", "timestamp": 1632519249, "time_this_iter_s": 16.09834098815918, "time_total_s": 1413.2959666252136, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1413.2959666252136, "timesteps_since_restore": 0, "iterations_since_restore": 94, "perf": {"cpu_util_percent": 35.05217391304348, "ram_util_percent": 16.10000000000001}}
{"episode_reward_max": -21.4, "episode_reward_min": -60.90000000000001, "episode_reward_mean": -38.90601503759399, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-45.2, -35.099999999999994, -39.4, -38.6, -46.800000000000004, -26.5, -41.900000000000006, -41.900000000000006, -45.6, -42.60000000000001, -38.4, -52.2, -34.2, -44.400000000000006, -34.6, -32.699999999999996, -27.8, -36.10000000000001, -48.10000000000001, -51.0, -32.1, -37.89999999999999, -31.1, -49.300000000000004, -33.1, -32.2, -28.800000000000004, -35.900000000000006, -46.0, -45.30000000000001, -34.0, -36.7, -41.1, -47.60000000000001, -38.1, -40.70000000000001, -42.1, -30.500000000000004, -38.3, -35.00000000000001, -43.90000000000001, -44.4, -45.900000000000006, -26.4, -45.300000000000004, -46.0, -33.7, -24.700000000000003, -35.20000000000001, -34.3, -21.4, -25.400000000000002, -54.10000000000001, -55.8, -44.90000000000002, -32.6, -46.800000000000004, -59.00000000000001, -33.099999999999994, -37.50000000000001, -53.900000000000006, -39.2, -45.60000000000001, -48.30000000000001, -28.5, -44.10000000000001, -39.5, -43.2, -43.5, -39.20000000000001, -47.8, -37.00000000000001, -44.9, -35.800000000000004, -28.1, -58.00000000000001, -42.60000000000001, -27.400000000000002, -40.900000000000006, -40.5, -31.400000000000006, -30.100000000000005, -40.50000000000001, -42.7, -35.900000000000006, -48.50000000000001, -21.5, -39.20000000000001, -32.5, -42.60000000000001, -26.6, -41.199999999999996, -35.6, -44.50000000000001, -37.5, -40.1, -42.4, -47.60000000000001, -26.200000000000003, -49.1, -45.7, -52.10000000000001, -37.1, -41.5, -40.4, -33.0, -28.2, -33.900000000000006, -43.199999999999996, -41.20000000000001, -44.60000000000001, -49.20000000000001, -33.60000000000001, -41.4, -30.1, -40.400000000000006, -35.900000000000006, -26.200000000000003, -38.3, -39.1, -39.00000000000001, -34.1, -51.300000000000004, -39.70000000000001, -32.7, -47.50000000000001, -41.49999999999999, -40.6, -34.4, -36.300000000000004, -44.00000000000001, -36.800000000000004, -33.1, -31.900000000000002, -40.1, -42.300000000000004, -34.7, -26.5, -35.900000000000006, -28.799999999999997, -38.9, -41.49999999999999, -27.6, -40.8, -42.599999999999994, -28.2, -39.50000000000001, -43.3, -32.8, -48.30000000000001, -43.10000000000001, -51.5, -29.700000000000003, -40.800000000000004, -32.7, -44.800000000000004, -41.00000000000001, -31.9, -37.900000000000006, -32.8, -22.6, -48.80000000000001, -31.0, -53.400000000000006, -34.5, -29.900000000000002, -35.19999999999999, -32.6, -44.2, -31.299999999999997, -39.2, -31.0, -44.100000000000016, -32.9, -38.900000000000006, -43.6, -43.400000000000006, -29.400000000000002, -22.700000000000003, -41.10000000000001, -50.00000000000001, -34.2, -40.20000000000001, -41.2, -49.900000000000006, -34.300000000000004, -56.500000000000014, -41.1, -35.400000000000006, -37.0, -33.6, -38.800000000000004, -23.500000000000004, -37.2, -53.900000000000006, -25.299999999999997, -38.900000000000006, -48.30000000000001, -37.7, -29.900000000000002, -32.300000000000004, -46.6, -25.0, -34.0, -30.6, -40.60000000000001, -31.400000000000006, -49.50000000000001, -35.2, -37.9, -36.7, -31.000000000000004, -36.1, -39.8, -40.50000000000001, -45.70000000000001, -56.60000000000001, -48.800000000000004, -38.2, -37.900000000000006, -32.599999999999994, -35.8, -35.1, -30.5, -25.700000000000003, -29.400000000000006, -25.400000000000002, -43.6, -34.900000000000006, -35.1, -44.60000000000001, -27.400000000000002, -53.20000000000001, -42.900000000000006, -35.0, -43.10000000000001, -39.4, -40.699999999999996, -56.20000000000002, -52.900000000000006, -42.5, -40.49999999999999, -56.2, -43.800000000000004, -46.1, -38.50000000000001, -30.3, -30.900000000000002, -60.90000000000001, -36.80000000000001, -31.800000000000004, -51.6, -43.6, -47.5, -42.300000000000004, -35.6, -33.1, -50.7, -37.3, -41.900000000000006, -32.900000000000006, -46.9, -40.5, -28.799999999999997, -33.0, -41.39999999999999], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14036969353880743, "mean_inference_ms": 1.2655710224231902, "mean_action_processing_ms": 0.056725020882980454, "mean_env_wait_ms": 2.154304377270414, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 380000, "agent_timesteps_total": 380000, "timers": {"sample_time_ms": 7639.785, "sample_throughput": 523.575, "load_time_ms": 0.048, "load_throughput": 83179058.007, "learn_time_ms": 7908.554, "learn_throughput": 505.781, "update_time_ms": 1.586}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.10000000000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 130.15853893321048, "policy_loss": -0.02424866999549571, "vf_loss": 130.1820600776262, "vf_explained_var": [0.0734802857041359], "kl": 0.007276427422144914, "entropy": 0.38673702494431567, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 380000, "num_agent_steps_sampled": 380000, "num_steps_trained": 380000, "num_agent_steps_trained": 380000}, "done": false, "episodes_total": 25332, "training_iteration": 95, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-34-25", "timestamp": 1632519265, "time_this_iter_s": 15.821749210357666, "time_total_s": 1429.1177158355713, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1429.1177158355713, "timesteps_since_restore": 0, "iterations_since_restore": 95, "perf": {"cpu_util_percent": 34.8304347826087, "ram_util_percent": 16.10000000000001}}
{"episode_reward_max": -17.599999999999998, "episode_reward_min": -66.0, "episode_reward_mean": -39.827238805970154, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 268, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-32.6, -31.300000000000004, -43.6, -31.7, -40.4, -36.9, -35.5, -37.1, -28.900000000000002, -51.7, -28.900000000000002, -62.300000000000004, -44.2, -50.1, -45.400000000000006, -43.4, -41.3, -36.0, -34.900000000000006, -43.5, -40.1, -28.2, -37.2, -32.00000000000001, -27.100000000000005, -51.900000000000006, -35.7, -23.000000000000004, -30.200000000000003, -38.0, -43.60000000000001, -42.3, -27.1, -37.300000000000004, -66.0, -35.400000000000006, -44.00000000000001, -50.10000000000001, -34.2, -36.9, -42.50000000000001, -52.2, -31.6, -44.699999999999996, -46.3, -34.3, -48.5, -51.900000000000006, -39.800000000000004, -42.300000000000004, -47.400000000000006, -38.60000000000001, -34.300000000000004, -28.500000000000004, -31.799999999999997, -41.300000000000004, -56.50000000000001, -25.6, -41.10000000000001, -37.50000000000001, -31.6, -41.000000000000014, -44.00000000000001, -39.8, -39.900000000000006, -37.300000000000004, -35.3, -39.3, -40.80000000000001, -43.6, -42.40000000000001, -54.7, -44.40000000000001, -41.70000000000001, -55.40000000000002, -43.10000000000001, -35.800000000000004, -38.300000000000004, -36.800000000000004, -41.0, -39.099999999999994, -29.9, -31.2, -37.1, -47.9, -29.8, -38.10000000000001, -39.5, -41.50000000000001, -41.10000000000001, -38.900000000000006, -42.80000000000001, -37.60000000000001, -51.900000000000006, -39.4, -43.70000000000001, -54.50000000000001, -41.00000000000001, -39.400000000000006, -48.20000000000001, -31.3, -21.5, -44.50000000000001, -44.00000000000001, -51.10000000000001, -43.7, -40.400000000000006, -36.7, -37.2, -40.300000000000004, -46.5, -31.600000000000005, -33.1, -17.599999999999998, -41.60000000000001, -32.6, -34.2, -29.6, -50.400000000000006, -26.3, -43.50000000000001, -34.5, -54.80000000000001, -40.50000000000001, -38.300000000000004, -44.5, -50.1, -32.9, -44.10000000000001, -43.6, -36.900000000000006, -39.3, -33.70000000000001, -31.400000000000002, -52.1, -48.500000000000014, -43.300000000000004, -49.20000000000001, -48.400000000000006, -40.7, -29.400000000000002, -43.300000000000004, -41.2, -37.6, -38.300000000000004, -27.5, -47.400000000000006, -30.400000000000006, -43.7, -39.6, -44.8, -34.3, -37.400000000000006, -45.7, -37.50000000000001, -44.800000000000004, -43.7, -46.89999999999999, -44.900000000000006, -39.50000000000001, -37.80000000000001, -39.8, -48.7, -51.0, -49.1, -34.6, -44.400000000000006, -35.5, -30.300000000000004, -46.7, -30.1, -33.800000000000004, -33.1, -38.3, -40.99999999999999, -37.30000000000001, -46.2, -49.2, -28.2, -37.9, -34.8, -36.39999999999999, -37.199999999999996, -38.300000000000004, -37.7, -38.400000000000006, -48.80000000000001, -43.0, -28.299999999999997, -42.0, -54.50000000000001, -37.300000000000004, -42.6, -30.8, -52.4, -42.7, -45.00000000000001, -43.699999999999996, -27.299999999999997, -47.800000000000004, -48.000000000000014, -49.5, -41.400000000000006, -42.8, -41.0, -27.899999999999995, -32.400000000000006, -30.999999999999996, -44.10000000000001, -50.600000000000016, -35.2, -50.2, -57.300000000000004, -21.200000000000003, -40.4, -46.7, -27.699999999999996, -44.699999999999996, -41.1, -35.5, -36.5, -38.800000000000004, -24.7, -46.900000000000006, -40.6, -32.1, -39.50000000000001, -52.0, -50.10000000000001, -44.4, -39.9, -44.10000000000001, -42.3, -53.9, -42.00000000000001, -45.2, -32.50000000000001, -34.800000000000004, -26.800000000000004, -32.2, -29.8, -37.900000000000006, -34.900000000000006, -27.800000000000004, -44.10000000000001, -38.800000000000004, -30.6, -54.900000000000006, -26.800000000000004, -40.0, -41.80000000000001, -41.70000000000001, -43.9, -35.9, -38.1, -27.5, -61.600000000000016, -45.60000000000001, -34.199999999999996, -39.6, -32.400000000000006, -18.8, -35.900000000000006, -54.4, -31.900000000000006, -38.10000000000001, -37.9, -40.900000000000006], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1404088202649399, "mean_inference_ms": 1.2655060528254767, "mean_action_processing_ms": 0.05672192584847351, "mean_env_wait_ms": 2.1532810131520446, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 384000, "agent_timesteps_total": 384000, "timers": {"sample_time_ms": 7453.356, "sample_throughput": 536.671, "load_time_ms": 0.049, "load_throughput": 80854053.012, "learn_time_ms": 7785.273, "learn_throughput": 513.791, "update_time_ms": 1.52}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.10000000000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 140.64723736342563, "policy_loss": -0.022813956226192176, "vf_loss": 140.66926208003875, "vf_explained_var": [0.0680239275097847], "kl": 0.007894626424669789, "entropy": 0.3804976548558922, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 384000, "num_agent_steps_sampled": 384000, "num_steps_trained": 384000, "num_agent_steps_trained": 384000}, "done": false, "episodes_total": 25600, "training_iteration": 96, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-34-40", "timestamp": 1632519280, "time_this_iter_s": 14.941379070281982, "time_total_s": 1444.0590949058533, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1444.0590949058533, "timesteps_since_restore": 0, "iterations_since_restore": 96, "perf": {"cpu_util_percent": 34.642857142857146, "ram_util_percent": 16.100000000000005}}
{"episode_reward_max": -16.6, "episode_reward_min": -64.9, "episode_reward_mean": -40.0639097744361, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-23.9, -48.000000000000014, -35.4, -44.10000000000001, -36.80000000000001, -49.10000000000001, -43.400000000000006, -39.900000000000006, -49.50000000000001, -47.8, -44.00000000000001, -35.6, -44.80000000000001, -42.3, -37.7, -38.0, -30.6, -29.700000000000006, -37.4, -35.9, -32.0, -26.000000000000004, -33.5, -33.6, -32.1, -16.6, -39.8, -48.400000000000006, -29.800000000000004, -32.3, -45.300000000000004, -35.099999999999994, -42.0, -39.400000000000006, -34.400000000000006, -36.5, -46.60000000000001, -52.60000000000001, -31.1, -44.70000000000001, -41.7, -38.10000000000001, -40.2, -29.000000000000007, -34.4, -35.2, -48.20000000000001, -47.30000000000001, -38.00000000000001, -46.0, -45.5, -21.799999999999997, -38.400000000000006, -40.50000000000001, -43.900000000000006, -37.599999999999994, -33.00000000000001, -36.9, -46.400000000000006, -35.60000000000001, -38.00000000000001, -44.4, -26.000000000000004, -27.999999999999996, -38.6, -55.2, -52.5, -37.599999999999994, -29.9, -47.400000000000006, -59.3, -44.2, -46.1, -46.30000000000001, -50.6, -45.300000000000004, -35.99999999999999, -39.2, -36.00000000000001, -38.0, -34.8, -46.0, -57.70000000000002, -32.300000000000004, -46.80000000000001, -50.6, -36.70000000000001, -40.800000000000004, -28.400000000000002, -44.6, -34.300000000000004, -41.8, -54.50000000000001, -33.400000000000006, -33.70000000000001, -43.6, -42.7, -44.4, -63.90000000000001, -38.60000000000001, -45.60000000000001, -38.199999999999996, -32.900000000000006, -60.30000000000002, -52.300000000000004, -42.60000000000001, -41.400000000000006, -42.800000000000004, -40.49999999999999, -31.499999999999996, -33.5, -21.7, -35.7, -34.8, -41.70000000000001, -42.50000000000001, -34.7, -48.10000000000001, -51.00000000000001, -41.599999999999994, -30.3, -44.9, -53.7, -36.400000000000006, -40.9, -37.699999999999996, -40.7, -31.700000000000003, -41.1, -37.800000000000004, -44.2, -40.7, -30.5, -33.800000000000004, -42.800000000000004, -32.8, -32.6, -39.300000000000004, -32.50000000000001, -56.2, -37.1, -41.1, -53.199999999999996, -35.1, -27.9, -39.00000000000001, -33.6, -53.8, -44.20000000000001, -36.6, -35.400000000000006, -28.100000000000005, -48.40000000000001, -30.5, -51.900000000000006, -40.0, -38.2, -39.400000000000006, -45.400000000000006, -42.0, -49.300000000000004, -42.400000000000006, -41.30000000000001, -36.900000000000006, -46.10000000000001, -40.6, -27.299999999999997, -36.2, -48.4, -34.099999999999994, -54.400000000000006, -34.3, -29.799999999999997, -44.0, -49.400000000000006, -36.1, -37.2, -61.300000000000004, -49.3, -41.300000000000004, -36.5, -49.900000000000006, -35.699999999999996, -48.3, -45.300000000000004, -53.20000000000001, -40.099999999999994, -30.4, -29.999999999999996, -32.5, -27.3, -40.300000000000004, -56.10000000000001, -29.400000000000002, -42.3, -46.9, -47.3, -43.199999999999996, -35.1, -37.900000000000006, -50.500000000000014, -37.9, -37.10000000000001, -31.7, -49.60000000000001, -23.1, -38.8, -36.6, -27.1, -38.00000000000001, -42.70000000000001, -36.6, -45.199999999999996, -40.10000000000001, -32.300000000000004, -40.2, -45.300000000000004, -39.900000000000006, -41.00000000000001, -47.1, -44.7, -64.9, -36.4, -45.900000000000006, -32.6, -25.9, -31.5, -41.0, -45.7, -33.50000000000001, -47.400000000000006, -35.5, -41.900000000000006, -42.2, -39.300000000000004, -43.00000000000001, -48.199999999999996, -50.00000000000001, -36.6, -37.2, -40.0, -39.0, -54.6, -43.300000000000004, -31.600000000000005, -41.10000000000001, -38.400000000000006, -50.60000000000001, -38.60000000000001, -46.5, -29.700000000000003, -38.2, -29.800000000000004, -37.0, -33.1, -43.1, -49.4, -23.6, -32.9, -24.7, -49.10000000000001, -40.60000000000001, -46.20000000000001, -31.300000000000004, -50.30000000000001, -36.199999999999996], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14044027900053796, "mean_inference_ms": 1.2653294701226496, "mean_action_processing_ms": 0.056721850266550675, "mean_env_wait_ms": 2.1522391467423017, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 388000, "agent_timesteps_total": 388000, "timers": {"sample_time_ms": 7399.936, "sample_throughput": 540.545, "load_time_ms": 0.05, "load_throughput": 80737324.35, "learn_time_ms": 7830.993, "learn_throughput": 510.791, "update_time_ms": 1.606}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.10000000000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 140.88039855957032, "policy_loss": -0.02175248473612291, "vf_loss": 140.90139841879568, "vf_explained_var": [0.07450974732637405], "kl": 0.007532375973972411, "entropy": 0.36826419798276755, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 388000, "num_agent_steps_sampled": 388000, "num_steps_trained": 388000, "num_agent_steps_trained": 388000}, "done": false, "episodes_total": 25866, "training_iteration": 97, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-34-55", "timestamp": 1632519295, "time_this_iter_s": 14.956469058990479, "time_total_s": 1459.0155639648438, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1459.0155639648438, "timesteps_since_restore": 0, "iterations_since_restore": 97, "perf": {"cpu_util_percent": 34.44761904761905, "ram_util_percent": 16.100000000000005}}
{"episode_reward_max": -20.200000000000003, "episode_reward_min": -67.60000000000001, "episode_reward_mean": -40.05037593984963, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-27.500000000000007, -54.5, -31.600000000000005, -46.4, -50.400000000000006, -46.90000000000001, -41.60000000000001, -44.60000000000001, -44.300000000000004, -49.60000000000001, -44.1, -41.2, -51.900000000000006, -43.3, -32.7, -35.0, -37.20000000000001, -34.4, -34.3, -50.0, -31.9, -40.00000000000001, -26.0, -40.50000000000001, -44.800000000000004, -50.20000000000001, -46.10000000000001, -44.099999999999994, -38.7, -40.7, -35.7, -40.900000000000006, -45.900000000000006, -25.500000000000004, -34.599999999999994, -39.6, -46.99999999999999, -34.1, -27.800000000000004, -28.8, -47.7, -43.2, -43.900000000000006, -35.400000000000006, -37.5, -42.50000000000001, -27.800000000000004, -35.9, -25.0, -37.7, -43.500000000000014, -44.10000000000001, -33.900000000000006, -22.0, -31.3, -35.9, -46.10000000000001, -66.69999999999997, -67.60000000000001, -39.3, -29.700000000000006, -36.5, -48.80000000000001, -40.800000000000004, -53.2, -33.3, -49.000000000000014, -48.7, -31.8, -42.800000000000004, -47.600000000000016, -45.5, -44.00000000000001, -27.400000000000002, -52.900000000000006, -38.7, -35.400000000000006, -36.0, -42.400000000000006, -47.3, -35.8, -32.3, -44.300000000000004, -53.90000000000001, -40.5, -36.2, -31.300000000000004, -31.6, -42.099999999999994, -34.1, -29.600000000000005, -42.5, -35.099999999999994, -35.00000000000001, -39.60000000000001, -35.0, -54.1, -31.700000000000003, -39.1, -43.400000000000006, -40.6, -40.5, -38.400000000000006, -42.00000000000001, -51.50000000000001, -35.3, -36.60000000000001, -38.400000000000006, -45.300000000000004, -35.50000000000001, -39.4, -50.6, -45.50000000000001, -48.29999999999999, -35.6, -46.099999999999994, -42.300000000000004, -48.40000000000001, -36.10000000000001, -42.900000000000006, -36.400000000000006, -23.6, -20.200000000000003, -39.2, -36.0, -40.2, -33.3, -35.800000000000004, -27.700000000000003, -42.6, -38.50000000000001, -32.800000000000004, -52.20000000000001, -39.00000000000001, -32.7, -34.0, -48.6, -50.300000000000004, -36.89999999999999, -43.400000000000006, -59.70000000000002, -26.400000000000002, -42.50000000000001, -55.7, -37.50000000000001, -38.60000000000001, -53.20000000000001, -37.9, -25.599999999999998, -47.400000000000006, -36.6, -40.0, -37.1, -42.4, -37.2, -50.099999999999994, -38.5, -33.9, -47.0, -27.0, -43.800000000000004, -29.500000000000004, -39.8, -39.5, -53.400000000000006, -41.5, -44.400000000000006, -40.8, -24.3, -54.900000000000006, -33.1, -49.00000000000001, -34.800000000000004, -37.900000000000006, -39.10000000000001, -44.900000000000006, -45.300000000000004, -28.299999999999997, -50.9, -37.00000000000001, -47.400000000000006, -24.6, -53.80000000000001, -40.7, -40.50000000000001, -45.2, -45.4, -36.300000000000004, -37.5, -58.2, -37.099999999999994, -37.0, -32.300000000000004, -46.400000000000006, -34.6, -37.6, -31.900000000000006, -46.900000000000006, -51.4, -33.4, -22.700000000000006, -44.50000000000001, -38.3, -40.60000000000001, -30.5, -34.2, -46.6, -38.900000000000006, -48.10000000000001, -29.2, -47.300000000000004, -54.2, -40.300000000000004, -36.4, -32.6, -39.6, -31.3, -36.0, -51.60000000000001, -30.700000000000003, -29.7, -38.0, -54.400000000000006, -49.8, -40.0, -64.30000000000001, -49.400000000000006, -37.7, -45.4, -32.0, -37.0, -34.1, -33.5, -30.7, -40.50000000000001, -40.400000000000006, -32.1, -42.3, -31.3, -25.800000000000004, -44.400000000000006, -35.6, -31.8, -34.800000000000004, -28.799999999999997, -42.400000000000006, -41.699999999999996, -39.7, -42.0, -42.800000000000004, -56.500000000000014, -53.80000000000001, -49.8, -33.4, -49.40000000000001, -59.60000000000001, -45.5, -39.50000000000001, -31.900000000000006, -33.5, -39.300000000000004, -42.1, -32.300000000000004, -26.0, -38.6, -38.400000000000006], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.14050943956167797, "mean_inference_ms": 1.265622015019485, "mean_action_processing_ms": 0.056732040337854846, "mean_env_wait_ms": 2.151721501260266, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 392000, "agent_timesteps_total": 392000, "timers": {"sample_time_ms": 7456.317, "sample_throughput": 536.458, "load_time_ms": 0.05, "load_throughput": 80466263.789, "learn_time_ms": 7902.33, "learn_throughput": 506.18, "update_time_ms": 1.635}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.10000000000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 141.56837528187742, "policy_loss": -0.021478201511756626, "vf_loss": 141.58904477191228, "vf_explained_var": [0.07925604283809662], "kl": 0.008085025572326333, "entropy": 0.3824117612774654, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 392000, "num_agent_steps_sampled": 392000, "num_steps_trained": 392000, "num_agent_steps_trained": 392000}, "done": false, "episodes_total": 26132, "training_iteration": 98, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-35-10", "timestamp": 1632519310, "time_this_iter_s": 15.193093538284302, "time_total_s": 1474.208657503128, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1474.208657503128, "timesteps_since_restore": 0, "iterations_since_restore": 98, "perf": {"cpu_util_percent": 35.38636363636363, "ram_util_percent": 16.10000000000001}}
{"episode_reward_max": -20.7, "episode_reward_min": -60.100000000000016, "episode_reward_mean": -39.76044776119404, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 268, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-39.0, -47.300000000000004, -29.5, -48.89999999999999, -37.7, -38.3, -34.2, -38.0, -39.60000000000001, -46.2, -47.2, -33.3, -48.9, -39.099999999999994, -27.099999999999998, -41.60000000000001, -32.9, -43.099999999999994, -37.6, -42.300000000000004, -47.4, -46.50000000000001, -43.2, -46.3, -45.20000000000001, -33.0, -44.900000000000006, -55.400000000000006, -31.8, -31.599999999999998, -45.300000000000004, -41.00000000000001, -33.400000000000006, -43.900000000000006, -53.100000000000016, -38.9, -47.7, -34.0, -40.900000000000006, -36.4, -38.4, -42.4, -31.700000000000003, -35.800000000000004, -38.2, -52.10000000000001, -39.6, -27.3, -25.800000000000004, -31.599999999999998, -54.5, -37.5, -35.2, -42.400000000000006, -50.1, -42.7, -40.300000000000004, -34.4, -37.7, -44.5, -40.2, -45.50000000000001, -52.0, -29.300000000000004, -28.8, -39.0, -36.0, -56.30000000000001, -52.10000000000001, -44.00000000000001, -43.2, -38.800000000000004, -26.4, -39.900000000000006, -51.30000000000001, -46.70000000000001, -41.10000000000001, -42.60000000000001, -34.2, -36.00000000000001, -38.2, -37.6, -29.0, -29.9, -40.2, -43.1, -30.4, -39.99999999999999, -25.799999999999997, -28.700000000000003, -34.3, -38.6, -25.299999999999997, -56.300000000000004, -31.200000000000006, -33.5, -43.0, -44.60000000000001, -31.1, -45.7, -48.00000000000001, -43.10000000000001, -46.50000000000001, -34.6, -39.10000000000001, -46.70000000000001, -38.7, -35.1, -45.80000000000001, -40.900000000000006, -44.400000000000006, -33.9, -49.2, -42.60000000000001, -55.50000000000001, -30.200000000000003, -25.699999999999996, -39.0, -41.10000000000001, -54.50000000000001, -31.2, -43.70000000000001, -27.1, -43.4, -25.5, -44.7, -34.2, -37.1, -41.50000000000001, -45.5, -49.300000000000004, -43.6, -34.6, -49.50000000000001, -34.6, -41.500000000000014, -43.900000000000006, -30.7, -51.6, -37.70000000000001, -34.60000000000001, -35.00000000000001, -44.10000000000001, -34.400000000000006, -45.099999999999994, -40.8, -47.3, -25.0, -34.800000000000004, -40.80000000000001, -36.5, -32.5, -35.2, -45.199999999999996, -40.5, -38.900000000000006, -44.900000000000006, -33.800000000000004, -56.10000000000001, -23.5, -39.60000000000001, -52.10000000000001, -27.4, -43.20000000000001, -42.6, -43.900000000000006, -49.1, -44.9, -46.800000000000004, -45.60000000000001, -43.60000000000001, -34.7, -42.900000000000006, -30.8, -50.30000000000001, -40.6, -46.500000000000014, -43.3, -27.000000000000004, -40.5, -36.7, -57.60000000000001, -27.5, -40.7, -39.300000000000004, -49.8, -50.000000000000014, -31.300000000000004, -52.300000000000004, -25.5, -42.60000000000001, -25.6, -25.099999999999998, -46.8, -35.300000000000004, -33.4, -31.900000000000002, -59.9, -32.6, -49.5, -42.6, -44.0, -41.2, -40.7, -31.6, -45.90000000000001, -36.6, -43.50000000000001, -48.70000000000001, -36.2, -49.70000000000001, -46.30000000000001, -40.2, -43.400000000000006, -29.200000000000003, -53.00000000000001, -53.400000000000006, -43.1, -34.400000000000006, -51.90000000000001, -54.80000000000001, -49.90000000000001, -60.100000000000016, -35.7, -31.200000000000003, -40.900000000000006, -42.30000000000001, -40.300000000000004, -30.9, -38.1, -30.900000000000002, -44.00000000000001, -33.1, -42.3, -46.7, -28.600000000000005, -36.10000000000001, -56.40000000000001, -33.4, -38.099999999999994, -33.2, -36.599999999999994, -38.800000000000004, -37.7, -33.70000000000001, -26.499999999999996, -34.9, -42.300000000000004, -35.4, -33.1, -33.9, -29.1, -30.200000000000003, -48.00000000000001, -35.7, -36.50000000000001, -40.5, -34.7, -48.300000000000004, -40.60000000000001, -31.700000000000003, -20.7, -37.7, -48.80000000000001, -30.5, -30.200000000000003, -41.2, -28.800000000000004], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1405566569080879, "mean_inference_ms": 1.2657863454472758, "mean_action_processing_ms": 0.05673361612325601, "mean_env_wait_ms": 2.1508389069910834, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 396000, "agent_timesteps_total": 396000, "timers": {"sample_time_ms": 7485.981, "sample_throughput": 534.332, "load_time_ms": 0.05, "load_throughput": 80043969.466, "learn_time_ms": 7886.105, "learn_throughput": 507.221, "update_time_ms": 1.569}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.10000000000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 138.07328754548104, "policy_loss": -0.018816936124236353, "vf_loss": 138.09141524120042, "vf_explained_var": [0.07024826854467392], "kl": 0.006894981440751265, "entropy": 0.3552579871108455, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 396000, "num_agent_steps_sampled": 396000, "num_steps_trained": 396000, "num_agent_steps_trained": 396000}, "done": false, "episodes_total": 26400, "training_iteration": 99, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-35-25", "timestamp": 1632519325, "time_this_iter_s": 14.832992315292358, "time_total_s": 1489.0416498184204, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1489.0416498184204, "timesteps_since_restore": 0, "iterations_since_restore": 99, "perf": {"cpu_util_percent": 34.68571428571428, "ram_util_percent": 16.100000000000005}}
{"episode_reward_max": -18.7, "episode_reward_min": -71.30000000000001, "episode_reward_mean": -39.2421052631579, "episode_len_mean": 15.0, "episode_media": {}, "episodes_this_iter": 266, "policy_reward_min": {}, "policy_reward_max": {}, "policy_reward_mean": {}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.900000000000006, -38.5, -56.20000000000001, -37.6, -37.800000000000004, -43.6, -38.5, -48.1, -28.1, -52.6, -55.900000000000006, -31.8, -21.6, -38.800000000000004, -29.099999999999998, -46.80000000000001, -33.7, -31.099999999999998, -20.8, -30.700000000000003, -42.1, -44.4, -39.7, -20.199999999999996, -40.599999999999994, -28.799999999999997, -38.400000000000006, -32.7, -44.1, -56.0, -35.0, -42.300000000000004, -33.2, -45.1, -41.00000000000001, -46.7, -30.6, -35.1, -47.300000000000004, -42.7, -43.10000000000001, -34.5, -43.9, -28.7, -40.6, -36.2, -33.0, -38.300000000000004, -25.899999999999995, -40.60000000000001, -36.1, -36.4, -35.60000000000001, -48.2, -47.2, -33.3, -46.2, -40.60000000000001, -29.2, -47.6, -35.9, -49.50000000000001, -35.8, -38.400000000000006, -41.3, -42.600000000000016, -45.0, -31.9, -30.2, -25.0, -48.8, -45.400000000000006, -35.1, -36.6, -31.200000000000003, -28.6, -28.9, -40.9, -41.7, -34.7, -47.8, -44.900000000000006, -45.6, -43.9, -36.199999999999996, -44.5, -36.5, -60.40000000000002, -34.4, -49.2, -42.9, -41.00000000000001, -39.5, -31.7, -42.50000000000001, -29.4, -27.6, -29.200000000000003, -26.599999999999998, -50.49999999999999, -34.300000000000004, -36.1, -37.5, -44.0, -34.7, -40.50000000000001, -19.099999999999998, -33.9, -27.599999999999998, -34.2, -39.7, -30.0, -41.3, -50.1, -37.50000000000001, -40.1, -39.800000000000004, -53.7, -47.2, -38.4, -40.50000000000001, -32.400000000000006, -29.599999999999998, -42.900000000000006, -29.700000000000003, -41.1, -36.7, -36.4, -45.3, -53.1, -43.50000000000001, -61.400000000000006, -33.1, -53.60000000000001, -23.3, -31.0, -42.5, -36.5, -71.30000000000001, -36.70000000000001, -34.800000000000004, -39.400000000000006, -44.699999999999996, -29.6, -47.900000000000006, -31.3, -35.800000000000004, -39.00000000000001, -46.199999999999996, -53.50000000000001, -31.200000000000003, -50.20000000000001, -41.50000000000001, -29.1, -41.3, -49.60000000000001, -37.2, -45.0, -41.400000000000006, -24.4, -31.1, -36.6, -30.000000000000004, -55.1, -35.6, -39.9, -39.3, -26.6, -42.5, -48.7, -37.400000000000006, -54.800000000000004, -46.7, -48.80000000000001, -31.800000000000004, -53.900000000000006, -27.499999999999996, -23.500000000000004, -37.800000000000004, -52.6, -39.5, -25.200000000000003, -29.0, -46.300000000000004, -51.10000000000001, -40.80000000000001, -31.900000000000006, -30.2, -34.9, -48.0, -43.300000000000004, -39.900000000000006, -61.6, -40.1, -31.900000000000006, -42.7, -29.099999999999998, -39.8, -29.600000000000005, -27.6, -27.800000000000004, -21.1, -56.70000000000002, -48.100000000000016, -40.5, -37.7, -43.00000000000001, -31.400000000000002, -40.9, -47.300000000000004, -32.900000000000006, -52.800000000000004, -34.300000000000004, -46.9, -55.00000000000001, -41.0, -35.400000000000006, -49.10000000000001, -59.1, -42.6, -41.300000000000004, -40.800000000000004, -41.2, -35.8, -50.8, -34.9, -34.7, -29.600000000000005, -46.80000000000001, -34.5, -48.000000000000014, -46.5, -18.7, -31.300000000000004, -47.7, -23.900000000000002, -37.0, -46.5, -45.4, -45.20000000000001, -32.5, -25.1, -28.4, -31.5, -39.3, -33.9, -39.900000000000006, -31.400000000000002, -40.300000000000004, -50.8, -35.0, -26.800000000000004, -48.900000000000006, -26.4, -42.00000000000001, -49.1, -42.2, -56.300000000000004, -48.900000000000006, -62.900000000000006, -47.2, -32.900000000000006, -35.50000000000001, -23.900000000000002, -36.2, -45.60000000000001], "episode_lengths": [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.140649433819672, "mean_inference_ms": 1.2664955627114718, "mean_action_processing_ms": 0.05675878397989908, "mean_env_wait_ms": 2.1501208177085562, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 2, "timesteps_total": 400000, "agent_timesteps_total": 400000, "timers": {"sample_time_ms": 7428.144, "sample_throughput": 538.493, "load_time_ms": 0.05, "load_throughput": 79362421.949, "learn_time_ms": 7908.58, "learn_throughput": 505.78, "update_time_ms": 1.557}, "info": {"learner": {"default_policy": {"learner_stats": {"allreduce_latency": 0.0, "cur_kl_coeff": 0.10000000000000002, "cur_lr": 5.0000000000000016e-05, "total_loss": 140.11919947798535, "policy_loss": -0.020349531820023893, "vf_loss": 140.13895846131027, "vf_explained_var": [0.07745473831892014], "kl": 0.005908451404961889, "entropy": 0.3583543725872553, "entropy_coeff": 0.0}, "model": {}, "custom_metrics": {}}}, "num_steps_sampled": 400000, "num_agent_steps_sampled": 400000, "num_steps_trained": 400000, "num_agent_steps_trained": 400000}, "done": false, "episodes_total": 26666, "training_iteration": 100, "experiment_id": "c4de101e84274de8b6978899867c4328", "date": "2021-09-24_14-35-40", "timestamp": 1632519340, "time_this_iter_s": 14.933469295501709, "time_total_s": 1503.9751191139221, "pid": 6590, "hostname": "3a5e13a3c200", "node_ip": "172.17.0.2", "config": {"num_workers": 2, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 200, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 4000, "model": {"_use_default_native_models": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "num_framestacks": "auto", "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1, "framestack": true}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "oaas-v0", "observation_space": null, "action_space": null, "env_config": {}, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "torch", "eager_tracing": false, "explore": true, "exploration_config": {"type": "StochasticSampling"}, "evaluation_interval": null, "evaluation_num_episodes": 10, "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "collect_metrics_timeout": 180, "metrics_smoothing_episodes": 100, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "min_iter_time_s": 0, "timesteps_per_iteration": 0, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"default_policy": ["<class 'ray.rllib.policy.policy_template.PPOTorchPolicy'>", null, null, {}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": null, "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "simple_optimizer": false, "monitor": -1, "use_critic": true, "use_gae": true, "lambda": 1.0, "kl_coeff": 0.2, "sgd_minibatch_size": 128, "shuffle_sequences": true, "num_sgd_iter": 30, "lr_schedule": null, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 15.0, "grad_clip": null, "kl_target": 0.01, "vf_share_layers": -1}, "time_since_restore": 1503.9751191139221, "timesteps_since_restore": 0, "iterations_since_restore": 100, "perf": {"cpu_util_percent": 35.07727272727272, "ram_util_percent": 16.104545454545462}}
